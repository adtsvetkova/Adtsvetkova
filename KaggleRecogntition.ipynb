{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соревнование на Kaggle\n",
    "**Ссылка**: https://www.kaggle.com/c/quickdraw-doodle-recognition/overview\n",
    "\n",
    "Score: 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-t7HSSx4RQz2"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:08:15.388798Z",
     "start_time": "2018-11-07T16:08:15.081241Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jRfFivfYRQz7",
    "outputId": "14a92b15-892a-4aee-e04d-5bf1f320c3c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from keras.layers.advanced_activations import LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:43.935122Z",
     "start_time": "2018-11-07T16:09:43.339804Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xztQGciKRQ1H"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLSiP2cn_Opr"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, GlobalAveragePooling2D, \\\n",
    "    BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uT6jLiXRQ0I"
   },
   "source": [
    "# Download data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "colab_type": "code",
    "id": "25f-d07sRQ0M",
    "outputId": "c72aa398-9c2b-4ca7-caef-07221ca703e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/9b/ac57e15fbb239c6793c8d0b7dfd1a4c4a025eaa9f791b5388a7afb515aed/kaggle-1.5.0.tar.gz (53kB)\n",
      "\r",
      "\u001b[K    19% |██████▏                         | 10kB 13.4MB/s eta 0:00:01\r",
      "\u001b[K    38% |████████████▎                   | 20kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K    57% |██████████████████▌             | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K    77% |████████████████████████▋       | 40kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K    96% |██████████████████████████████▉ | 51kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.10.15)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/ad/c778a6df614b6217c30fe80045b365bfa08b5dd3cb02e8b37a6d25126781/python-slugify-1.2.6.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
      "\r",
      "\u001b[K    4% |█▍                              | 10kB 13.2MB/s eta 0:00:01\r",
      "\u001b[K    8% |██▉                             | 20kB 6.4MB/s eta 0:00:01\r",
      "\u001b[K    13% |████▏                           | 30kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K    17% |█████▋                          | 40kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K    21% |███████                         | 51kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K    26% |████████▍                       | 61kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K    30% |█████████▊                      | 71kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K    34% |███████████▏                    | 81kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K    39% |████████████▌                   | 92kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K    43% |██████████████                  | 102kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K    47% |███████████████▎                | 112kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K    52% |████████████████▊               | 122kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K    56% |██████████████████              | 133kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K    60% |███████████████████▌            | 143kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K    65% |████████████████████▉           | 153kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K    69% |██████████████████████▎         | 163kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K    73% |███████████████████████▋        | 174kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K    78% |█████████████████████████       | 184kB 5.4MB/s eta 0:00:01\r",
      "\u001b[K    82% |██████████████████████████▌     | 194kB 5.4MB/s eta 0:00:01\r",
      "\u001b[K    86% |███████████████████████████▉    | 204kB 5.4MB/s eta 0:00:01\r",
      "\u001b[K    91% |█████████████████████████████▎  | 215kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K    95% |██████████████████████████████▋ | 225kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K    100% |████████████████████████████████| 235kB 5.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
      "  Running setup.py bdist_wheel for kaggle ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8b/21/3b/a0076243c6ae12a6215b2da515fe06b539aee7217b406e510e\n",
      "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e3/65/da/2045deea3098ed7471eca0e2460cfbd3fdfe8c1d6fa6fcac92\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: Unidecode, python-slugify, kaggle\n",
      "Successfully installed Unidecode-1.0.22 kaggle-1.5.0 python-slugify-1.2.6\n"
     ]
    }
   ],
   "source": [
    "# we need to use python 3 version of Kaggle!\n",
    "# remove python 2 version with `pip uninstall kaggle`\n",
    "! pip3 install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T15:29:19.895974Z",
     "start_time": "2018-11-06T15:26:21.334564Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "BK3CyGyaRQ0V",
    "outputId": "474a7b29-a20a-45f3-ef78-71eb67e9d98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_simplified.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# get <token> from https://www.kaggle.com/<user>/account, click \"Create New API Token\", open json file\n",
    "! KAGGLE_USERNAME=adtsvetkova KAGGLE_KEY=711dab66e0f54e09951120830972f100 kaggle competitions download -c quickdraw-doodle-recognition -f train_simplified.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:08:31.048432Z",
     "start_time": "2018-11-07T16:08:31.004128Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yrjZpeO4RQ0k"
   },
   "outputs": [],
   "source": [
    "# open zip file, will read everything from it\n",
    "zf = zipfile.ZipFile(\"train_simplified.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5RRT_JpRQ0o"
   },
   "source": [
    "# Data generators from disk (no need to store in RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:00.917240Z",
     "start_time": "2018-11-07T16:09:00.906369Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SgE-ZehpRQ0q",
    "outputId": "7694f4b4-b3cf-4900-acda-28d360d1ef23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 151,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:01.213496Z",
     "start_time": "2018-11-07T16:09:01.203670Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_ay84avwRQ0y"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:01.651230Z",
     "start_time": "2018-11-07T16:09:01.642356Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "giOUUXxRRQ03"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F355xsEwRQ07"
   },
   "source": [
    "# Images generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:04.267262Z",
     "start_time": "2018-11-07T16:09:04.251004Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "V4gvfZjyRQ08"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "IMG_SIZE = 64\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    image = Image.new(\"P\", (256, 256), color=255)\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0])-1):\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=0, width=5)\n",
    "    image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    return np.array(image, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:07.131184Z",
     "start_time": "2018-11-07T16:09:07.120659Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GlgBjSS5RQ1A"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:31.235828Z",
     "start_time": "2018-11-07T16:09:31.078072Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "hUF8OYnaRQ1D",
    "outputId": "9e8c84b2-66b2-4c6f-8f4e-bfa356d96d0b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAEHCAYAAACHl1tOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCUBBFwlAQRcJQEEXCUBBFwngfwEfUl2OdLTf3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0fe05c8610>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = images_and_labels_generator(32).next()\n",
    "plt.imshow(b[0][10, :, :])\n",
    "plt.title(b[1][10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DQguMI22X1d"
   },
   "source": [
    "#Эксперименты с архитектурой CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBhJjHELOtE4"
   },
   "source": [
    "# Эксперимент №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "212-oNsoGLZV"
   },
   "source": [
    "Простая CNN c повторяющимися сверточными слоями и батч нормализацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x21pk5duGmXh"
   },
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "NvjU7_nJGmbd",
    "outputId": "65f05684-415c-43f6-b52b-3a80d628c60e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qjatqrKGmhr"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5YaZdhHGV_W"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "   \n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(32, (3,3),padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(Conv2D(32, (3,3),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same'))\n",
    "    model.add(Conv2D(64, (3,3),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    " \n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='elu'))\n",
    "\n",
    "    model.add(Dense(64, activation='elu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "ulUvjy__GWE8",
    "outputId": "9915198c-8346-4445-90e7-b70d6191eec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               16777472  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 340)               22100     \n",
      "=================================================================\n",
      "Total params: 16,881,396\n",
      "Trainable params: 16,881,204\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvG-AsjLGWKN"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BD94M4lYGWUG"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "STEPS_PER_EPOCH = 500\n",
    "EPOCHS = 100\n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q84rrFLEGWXz"
   },
   "outputs": [],
   "source": [
    "# for saving the model after every epoch\n",
    "from keras.models import save_model\n",
    "\n",
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_filename = self.file_name.format(epoch)\n",
    "        save_model(self.model, model_filename)\n",
    "        print(\"Model saved in {}\".format(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26mecmJfJax5"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5117
    },
    "colab_type": "code",
    "id": "wxHUa_zEGWR-",
    "outputId": "814d6a09-c367-4d37-f215-981f656ffbe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 5.0476 - categorical_accuracy: 0.0550 - top_3_accuracy: 0.1199\n",
      "Model saved in model_0\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 3.6879 - categorical_accuracy: 0.2133 - top_3_accuracy: 0.3797\n",
      "Model saved in model_1\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 3.1920 - categorical_accuracy: 0.2980 - top_3_accuracy: 0.4910\n",
      "Model saved in model_2\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 2.9714 - categorical_accuracy: 0.3404 - top_3_accuracy: 0.5365\n",
      "Model saved in model_3\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.8308 - categorical_accuracy: 0.3640 - top_3_accuracy: 0.5658\n",
      "Model saved in model_4\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.7345 - categorical_accuracy: 0.3834 - top_3_accuracy: 0.5874\n",
      "Model saved in model_5\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.6348 - categorical_accuracy: 0.4005 - top_3_accuracy: 0.6075\n",
      "Model saved in model_6\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.5846 - categorical_accuracy: 0.4127 - top_3_accuracy: 0.6166\n",
      "Model saved in model_7\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.5244 - categorical_accuracy: 0.4247 - top_3_accuracy: 0.6295\n",
      "Model saved in model_8\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 2.4597 - categorical_accuracy: 0.4353 - top_3_accuracy: 0.6430\n",
      "Model saved in model_9\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.4090 - categorical_accuracy: 0.4463 - top_3_accuracy: 0.6503\n",
      "Model saved in model_10\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 2.3821 - categorical_accuracy: 0.4541 - top_3_accuracy: 0.6579\n",
      "Model saved in model_11\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.3335 - categorical_accuracy: 0.4598 - top_3_accuracy: 0.6685\n",
      "Model saved in model_12\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 2.3046 - categorical_accuracy: 0.4694 - top_3_accuracy: 0.6741\n",
      "Model saved in model_13\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 2.2736 - categorical_accuracy: 0.4721 - top_3_accuracy: 0.6785\n",
      "Model saved in model_14\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.2270 - categorical_accuracy: 0.4820 - top_3_accuracy: 0.6873\n",
      "Model saved in model_15\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.2115 - categorical_accuracy: 0.4867 - top_3_accuracy: 0.6885\n",
      "Model saved in model_16\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.1874 - categorical_accuracy: 0.4923 - top_3_accuracy: 0.6927\n",
      "Model saved in model_17\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.1693 - categorical_accuracy: 0.4958 - top_3_accuracy: 0.7000\n",
      "Model saved in model_18\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.1293 - categorical_accuracy: 0.5030 - top_3_accuracy: 0.7046\n",
      "Model saved in model_19\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.0999 - categorical_accuracy: 0.5099 - top_3_accuracy: 0.7095\n",
      "Model saved in model_20\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.1073 - categorical_accuracy: 0.5058 - top_3_accuracy: 0.7085\n",
      "Model saved in model_21\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.0838 - categorical_accuracy: 0.5146 - top_3_accuracy: 0.7128\n",
      "Model saved in model_22\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 2.0626 - categorical_accuracy: 0.5166 - top_3_accuracy: 0.7154\n",
      "Model saved in model_23\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 2.0468 - categorical_accuracy: 0.5188 - top_3_accuracy: 0.7207\n",
      "Model saved in model_24\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 2.0305 - categorical_accuracy: 0.5218 - top_3_accuracy: 0.7241\n",
      "Model saved in model_25\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.0315 - categorical_accuracy: 0.5223 - top_3_accuracy: 0.7218\n",
      "Model saved in model_26\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 2.0060 - categorical_accuracy: 0.5280 - top_3_accuracy: 0.7296\n",
      "Model saved in model_27\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 2.0050 - categorical_accuracy: 0.5290 - top_3_accuracy: 0.7275\n",
      "Model saved in model_28\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.9943 - categorical_accuracy: 0.5291 - top_3_accuracy: 0.7284\n",
      "Model saved in model_29\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.9872 - categorical_accuracy: 0.5316 - top_3_accuracy: 0.7329\n",
      "Model saved in model_30\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.9851 - categorical_accuracy: 0.5319 - top_3_accuracy: 0.7311\n",
      "Model saved in model_31\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.9761 - categorical_accuracy: 0.5352 - top_3_accuracy: 0.7345\n",
      "Model saved in model_32\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.9756 - categorical_accuracy: 0.5357 - top_3_accuracy: 0.7330\n",
      "Model saved in model_33\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.9438 - categorical_accuracy: 0.5425 - top_3_accuracy: 0.7395\n",
      "Model saved in model_34\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.9541 - categorical_accuracy: 0.5399 - top_3_accuracy: 0.7369\n",
      "Model saved in model_35\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 1.9474 - categorical_accuracy: 0.5418 - top_3_accuracy: 0.7391\n",
      "Model saved in model_36\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.9264 - categorical_accuracy: 0.5456 - top_3_accuracy: 0.7421\n",
      "Model saved in model_37\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.9234 - categorical_accuracy: 0.5463 - top_3_accuracy: 0.7438\n",
      "Model saved in model_38\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.9030 - categorical_accuracy: 0.5484 - top_3_accuracy: 0.7453\n",
      "Model saved in model_39\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8988 - categorical_accuracy: 0.5493 - top_3_accuracy: 0.7469\n",
      "Model saved in model_40\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.9018 - categorical_accuracy: 0.5520 - top_3_accuracy: 0.7480\n",
      "Model saved in model_41\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 1.8913 - categorical_accuracy: 0.5512 - top_3_accuracy: 0.7479\n",
      "Model saved in model_42\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8983 - categorical_accuracy: 0.5493 - top_3_accuracy: 0.7455\n",
      "Model saved in model_43\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8928 - categorical_accuracy: 0.5514 - top_3_accuracy: 0.7475\n",
      "Model saved in model_44\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.8679 - categorical_accuracy: 0.5556 - top_3_accuracy: 0.7523\n",
      "Model saved in model_45\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8751 - categorical_accuracy: 0.5566 - top_3_accuracy: 0.7508\n",
      "Model saved in model_46\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8660 - categorical_accuracy: 0.5573 - top_3_accuracy: 0.7543\n",
      "Model saved in model_47\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 1.8498 - categorical_accuracy: 0.5613 - top_3_accuracy: 0.7557\n",
      "Model saved in model_48\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8515 - categorical_accuracy: 0.5612 - top_3_accuracy: 0.7556\n",
      "Model saved in model_49\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.8564 - categorical_accuracy: 0.5587 - top_3_accuracy: 0.7538\n",
      "Model saved in model_50\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.8536 - categorical_accuracy: 0.5618 - top_3_accuracy: 0.7561\n",
      "Model saved in model_51\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.8522 - categorical_accuracy: 0.5585 - top_3_accuracy: 0.7548\n",
      "Model saved in model_52\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.8401 - categorical_accuracy: 0.5658 - top_3_accuracy: 0.7581\n",
      "Model saved in model_53\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.8324 - categorical_accuracy: 0.5655 - top_3_accuracy: 0.7601\n",
      "Model saved in model_54\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 1.8260 - categorical_accuracy: 0.5666 - top_3_accuracy: 0.7598\n",
      "Model saved in model_55\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8267 - categorical_accuracy: 0.5696 - top_3_accuracy: 0.7611\n",
      "Model saved in model_56\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.8243 - categorical_accuracy: 0.5693 - top_3_accuracy: 0.7619\n",
      "Model saved in model_57\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.8346 - categorical_accuracy: 0.5649 - top_3_accuracy: 0.7588\n",
      "Model saved in model_58\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.8194 - categorical_accuracy: 0.5665 - top_3_accuracy: 0.7605\n",
      "Model saved in model_59\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.8211 - categorical_accuracy: 0.5714 - top_3_accuracy: 0.7607\n",
      "Model saved in model_60\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.8208 - categorical_accuracy: 0.5712 - top_3_accuracy: 0.7595\n",
      "Model saved in model_61\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.7993 - categorical_accuracy: 0.5718 - top_3_accuracy: 0.7638\n",
      "Model saved in model_62\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.7997 - categorical_accuracy: 0.5709 - top_3_accuracy: 0.7653\n",
      "Model saved in model_63\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.7946 - categorical_accuracy: 0.5753 - top_3_accuracy: 0.7668\n",
      "Model saved in model_64\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 1.7712 - categorical_accuracy: 0.5778 - top_3_accuracy: 0.7691\n",
      "Model saved in model_65\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7749 - categorical_accuracy: 0.5770 - top_3_accuracy: 0.7697\n",
      "Model saved in model_66\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7777 - categorical_accuracy: 0.5782 - top_3_accuracy: 0.7689\n",
      "Model saved in model_67\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7947 - categorical_accuracy: 0.5750 - top_3_accuracy: 0.7661\n",
      "Model saved in model_68\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7855 - categorical_accuracy: 0.5756 - top_3_accuracy: 0.7657\n",
      "Model saved in model_69\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7864 - categorical_accuracy: 0.5771 - top_3_accuracy: 0.7672\n",
      "Model saved in model_70\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7724 - categorical_accuracy: 0.5764 - top_3_accuracy: 0.7686\n",
      "Model saved in model_71\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.7671 - categorical_accuracy: 0.5778 - top_3_accuracy: 0.7717\n",
      "Model saved in model_72\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7713 - categorical_accuracy: 0.5790 - top_3_accuracy: 0.7694\n",
      "Model saved in model_73\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7632 - categorical_accuracy: 0.5812 - top_3_accuracy: 0.7725\n",
      "Model saved in model_74\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7581 - categorical_accuracy: 0.5797 - top_3_accuracy: 0.7698\n",
      "Model saved in model_75\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7418 - categorical_accuracy: 0.5856 - top_3_accuracy: 0.7744\n",
      "Model saved in model_76\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7571 - categorical_accuracy: 0.5822 - top_3_accuracy: 0.7730\n",
      "Model saved in model_77\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.7607 - categorical_accuracy: 0.5802 - top_3_accuracy: 0.7723\n",
      "Model saved in model_78\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7467 - categorical_accuracy: 0.5852 - top_3_accuracy: 0.7734\n",
      "Model saved in model_79\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7475 - categorical_accuracy: 0.5817 - top_3_accuracy: 0.7724\n",
      "Model saved in model_80\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7460 - categorical_accuracy: 0.5847 - top_3_accuracy: 0.7739\n",
      "Model saved in model_81\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7467 - categorical_accuracy: 0.5836 - top_3_accuracy: 0.7746\n",
      "Model saved in model_82\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 68s 135ms/step - loss: 1.7501 - categorical_accuracy: 0.5802 - top_3_accuracy: 0.7729\n",
      "Model saved in model_83\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.7248 - categorical_accuracy: 0.5897 - top_3_accuracy: 0.7775\n",
      "Model saved in model_84\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.7340 - categorical_accuracy: 0.5869 - top_3_accuracy: 0.7770\n",
      "Model saved in model_85\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.7262 - categorical_accuracy: 0.5877 - top_3_accuracy: 0.7791\n",
      "Model saved in model_86\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.7386 - categorical_accuracy: 0.5873 - top_3_accuracy: 0.7748\n",
      "Model saved in model_87\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.7292 - categorical_accuracy: 0.5879 - top_3_accuracy: 0.7770\n",
      "Model saved in model_88\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.7199 - categorical_accuracy: 0.5893 - top_3_accuracy: 0.7792\n",
      "Model saved in model_89\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7146 - categorical_accuracy: 0.5915 - top_3_accuracy: 0.7778\n",
      "Model saved in model_90\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7151 - categorical_accuracy: 0.5882 - top_3_accuracy: 0.7778\n",
      "Model saved in model_91\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 69s 137ms/step - loss: 1.7178 - categorical_accuracy: 0.5885 - top_3_accuracy: 0.7793\n",
      "Model saved in model_92\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.7154 - categorical_accuracy: 0.5917 - top_3_accuracy: 0.7809\n",
      "Model saved in model_93\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.7182 - categorical_accuracy: 0.5927 - top_3_accuracy: 0.7773\n",
      "Model saved in model_94\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.7077 - categorical_accuracy: 0.5903 - top_3_accuracy: 0.7796\n",
      "Model saved in model_95\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.7212 - categorical_accuracy: 0.5877 - top_3_accuracy: 0.7778\n",
      "Model saved in model_96\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.6947 - categorical_accuracy: 0.5945 - top_3_accuracy: 0.7836\n",
      "Model saved in model_97\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7165 - categorical_accuracy: 0.5915 - top_3_accuracy: 0.7789\n",
      "Model saved in model_98\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7158 - categorical_accuracy: 0.5914 - top_3_accuracy: 0.7778\n",
      "Model saved in model_99\n"
     ]
    }
   ],
   "source": [
    "CNN_batchnorm = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(\"model_{}\")],\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30mseBzB1ux9"
   },
   "source": [
    "**Вывод:** При проверке на тестовых данных на kaggle показывает низкий score (0.399), значит модель переобучается. Поэтому на следующем этапе добавлю больше слоев свертки для увеличения количества фильтров, добавлю DropOut после каждого слоя,  использую меньший размер батча, добавляю функцию EarlyStopping, использую большее количество параметров\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRdLCJsHupj0"
   },
   "source": [
    "#Эксперимент №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NhpvGjRk93Gp",
    "outputId": "cb99a649-13b8-49b7-e088-37a9263261d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlPocX4X9z2h"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4qf56na9zKn"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5l5CdZEjGWNy"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cASlu_S9lQX"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "VM68bWDS9o0g",
    "outputId": "e9e7d2fc-1167-4e31-d681-53b0602d655e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEHCAYAAABhvpAKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d48edef90>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = images_and_labels_generator(32).next()\n",
    "plt.imshow(b[0][10, :, :])\n",
    "plt.title(b[1][10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxsEdugT-8Vw"
   },
   "outputs": [],
   "source": [
    "# reset graph when you change architecture!\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "BH1sSg6R-QmL",
    "outputId": "8567adf1-1a21-4618-8e95-f83d87d18837"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 171,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lL-jNrRG_DIP"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oLsB91A6_DQd",
    "outputId": "e781e31d-8fca-4eae-b3ba-72ee273be684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1L7JF4jr_DXh"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(128, (3,3),padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "pfXPgqKUECB7",
    "outputId": "7afdc01c-39a0-4e4e-944a-3e2c1b4d39a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               16777472  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               87380     \n",
      "=================================================================\n",
      "Total params: 16,941,716\n",
      "Trainable params: 16,940,820\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIOD41Q7_DUH"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBT1oMisBmZN"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 250 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZAQiHNXJUNV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='top_3_accuracy', patience=15, min_delta=0.001, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n",
    "    ModelCheckpoint(\"./CNN_2_dropout.model\",monitor='top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Cr5e3QCBmjg"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0\n",
    "\n",
    "# you can continue from snapshot!!!\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 2\n",
    "# model = load_model(\"model_{}\".format(last_finished_epoch), \n",
    "#                    custom_objects={\"top_3_accuracy\": top_3_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7837
    },
    "colab_type": "code",
    "id": "503kCL2n_DL_",
    "outputId": "66a5374b-5d54-40c0-a90b-67eab3b848e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "100/100 [==============================] - 43s 427ms/step - loss: 5.4995 - categorical_accuracy: 0.0356 - top_3_accuracy: 0.0730\n",
      "\n",
      "Epoch 00001: top_3_accuracy improved from -inf to 0.07297, saving model to ./CNN_2_dropout.model\n",
      "Epoch 2/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 4.8949 - categorical_accuracy: 0.0789 - top_3_accuracy: 0.1592\n",
      "\n",
      "Epoch 00002: top_3_accuracy improved from 0.07297 to 0.15922, saving model to ./CNN_2_dropout.model\n",
      "Epoch 3/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 4.5455 - categorical_accuracy: 0.1147 - top_3_accuracy: 0.2284\n",
      "\n",
      "Epoch 00003: top_3_accuracy improved from 0.15922 to 0.22844, saving model to ./CNN_2_dropout.model\n",
      "Epoch 4/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 4.2365 - categorical_accuracy: 0.1622 - top_3_accuracy: 0.2992\n",
      "\n",
      "Epoch 00004: top_3_accuracy improved from 0.22844 to 0.29922, saving model to ./CNN_2_dropout.model\n",
      "Epoch 5/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 4.0176 - categorical_accuracy: 0.1920 - top_3_accuracy: 0.3361\n",
      "\n",
      "Epoch 00005: top_3_accuracy improved from 0.29922 to 0.33609, saving model to ./CNN_2_dropout.model\n",
      "Epoch 6/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 3.8742 - categorical_accuracy: 0.2089 - top_3_accuracy: 0.3678\n",
      "\n",
      "Epoch 00006: top_3_accuracy improved from 0.33609 to 0.36781, saving model to ./CNN_2_dropout.model\n",
      "Epoch 7/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.6848 - categorical_accuracy: 0.2392 - top_3_accuracy: 0.4056\n",
      "\n",
      "Epoch 00007: top_3_accuracy improved from 0.36781 to 0.40563, saving model to ./CNN_2_dropout.model\n",
      "Epoch 8/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.6051 - categorical_accuracy: 0.2514 - top_3_accuracy: 0.4222\n",
      "\n",
      "Epoch 00008: top_3_accuracy improved from 0.40563 to 0.42219, saving model to ./CNN_2_dropout.model\n",
      "Epoch 9/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 3.4900 - categorical_accuracy: 0.2670 - top_3_accuracy: 0.4400\n",
      "\n",
      "Epoch 00009: top_3_accuracy improved from 0.42219 to 0.44000, saving model to ./CNN_2_dropout.model\n",
      "Epoch 10/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 3.5043 - categorical_accuracy: 0.2697 - top_3_accuracy: 0.4427\n",
      "\n",
      "Epoch 00010: top_3_accuracy improved from 0.44000 to 0.44266, saving model to ./CNN_2_dropout.model\n",
      "Epoch 11/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.4602 - categorical_accuracy: 0.2730 - top_3_accuracy: 0.4469\n",
      "\n",
      "Epoch 00011: top_3_accuracy improved from 0.44266 to 0.44688, saving model to ./CNN_2_dropout.model\n",
      "Epoch 12/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.3513 - categorical_accuracy: 0.2880 - top_3_accuracy: 0.4700\n",
      "\n",
      "Epoch 00012: top_3_accuracy improved from 0.44688 to 0.47000, saving model to ./CNN_2_dropout.model\n",
      "Epoch 13/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.3637 - categorical_accuracy: 0.2827 - top_3_accuracy: 0.4573\n",
      "\n",
      "Epoch 00013: top_3_accuracy did not improve from 0.47000\n",
      "Epoch 14/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.2368 - categorical_accuracy: 0.2989 - top_3_accuracy: 0.4869\n",
      "\n",
      "Epoch 00014: top_3_accuracy improved from 0.47000 to 0.48688, saving model to ./CNN_2_dropout.model\n",
      "Epoch 15/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 3.2705 - categorical_accuracy: 0.2925 - top_3_accuracy: 0.4803\n",
      "\n",
      "Epoch 00015: top_3_accuracy did not improve from 0.48688\n",
      "Epoch 16/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.2082 - categorical_accuracy: 0.3075 - top_3_accuracy: 0.4948\n",
      "\n",
      "Epoch 00016: top_3_accuracy improved from 0.48688 to 0.49484, saving model to ./CNN_2_dropout.model\n",
      "Epoch 17/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 3.1529 - categorical_accuracy: 0.3252 - top_3_accuracy: 0.5022\n",
      "\n",
      "Epoch 00017: top_3_accuracy improved from 0.49484 to 0.50219, saving model to ./CNN_2_dropout.model\n",
      "Epoch 18/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.1872 - categorical_accuracy: 0.3098 - top_3_accuracy: 0.5025\n",
      "\n",
      "Epoch 00018: top_3_accuracy improved from 0.50219 to 0.50250, saving model to ./CNN_2_dropout.model\n",
      "Epoch 19/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.0989 - categorical_accuracy: 0.3277 - top_3_accuracy: 0.5153\n",
      "\n",
      "Epoch 00019: top_3_accuracy improved from 0.50250 to 0.51531, saving model to ./CNN_2_dropout.model\n",
      "Epoch 20/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.0393 - categorical_accuracy: 0.3400 - top_3_accuracy: 0.5283\n",
      "\n",
      "Epoch 00020: top_3_accuracy improved from 0.51531 to 0.52828, saving model to ./CNN_2_dropout.model\n",
      "Epoch 21/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 3.0754 - categorical_accuracy: 0.3387 - top_3_accuracy: 0.5245\n",
      "\n",
      "Epoch 00021: top_3_accuracy did not improve from 0.52828\n",
      "Epoch 22/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.0662 - categorical_accuracy: 0.3375 - top_3_accuracy: 0.5203\n",
      "\n",
      "Epoch 00022: top_3_accuracy did not improve from 0.52828\n",
      "Epoch 23/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 3.0789 - categorical_accuracy: 0.3336 - top_3_accuracy: 0.5214\n",
      "\n",
      "Epoch 00023: top_3_accuracy did not improve from 0.52828\n",
      "Epoch 24/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 3.0348 - categorical_accuracy: 0.3405 - top_3_accuracy: 0.5380\n",
      "\n",
      "Epoch 00024: top_3_accuracy improved from 0.52828 to 0.53797, saving model to ./CNN_2_dropout.model\n",
      "Epoch 25/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.9980 - categorical_accuracy: 0.3409 - top_3_accuracy: 0.5370\n",
      "\n",
      "Epoch 00025: top_3_accuracy did not improve from 0.53797\n",
      "Epoch 26/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 3.0028 - categorical_accuracy: 0.3425 - top_3_accuracy: 0.5327\n",
      "\n",
      "Epoch 00026: top_3_accuracy did not improve from 0.53797\n",
      "Epoch 27/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 3.0186 - categorical_accuracy: 0.3403 - top_3_accuracy: 0.5322\n",
      "\n",
      "Epoch 00027: top_3_accuracy did not improve from 0.53797\n",
      "Epoch 28/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.9582 - categorical_accuracy: 0.3534 - top_3_accuracy: 0.5497\n",
      "\n",
      "Epoch 00028: top_3_accuracy improved from 0.53797 to 0.54969, saving model to ./CNN_2_dropout.model\n",
      "Epoch 29/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.9632 - categorical_accuracy: 0.3505 - top_3_accuracy: 0.5356\n",
      "\n",
      "Epoch 00029: top_3_accuracy did not improve from 0.54969\n",
      "Epoch 30/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.9445 - categorical_accuracy: 0.3556 - top_3_accuracy: 0.5438\n",
      "\n",
      "Epoch 00030: top_3_accuracy did not improve from 0.54969\n",
      "Epoch 31/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.9543 - categorical_accuracy: 0.3586 - top_3_accuracy: 0.5475\n",
      "\n",
      "Epoch 00031: top_3_accuracy did not improve from 0.54969\n",
      "Epoch 32/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.9311 - categorical_accuracy: 0.3608 - top_3_accuracy: 0.5536\n",
      "\n",
      "Epoch 00032: top_3_accuracy improved from 0.54969 to 0.55359, saving model to ./CNN_2_dropout.model\n",
      "Epoch 33/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.9058 - categorical_accuracy: 0.3628 - top_3_accuracy: 0.5567\n",
      "\n",
      "Epoch 00033: top_3_accuracy improved from 0.55359 to 0.55672, saving model to ./CNN_2_dropout.model\n",
      "Epoch 34/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.9302 - categorical_accuracy: 0.3644 - top_3_accuracy: 0.5563\n",
      "\n",
      "Epoch 00034: top_3_accuracy did not improve from 0.55672\n",
      "Epoch 35/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.8556 - categorical_accuracy: 0.3783 - top_3_accuracy: 0.5720\n",
      "\n",
      "Epoch 00035: top_3_accuracy improved from 0.55672 to 0.57203, saving model to ./CNN_2_dropout.model\n",
      "Epoch 36/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.8427 - categorical_accuracy: 0.3713 - top_3_accuracy: 0.5656\n",
      "\n",
      "Epoch 00036: top_3_accuracy did not improve from 0.57203\n",
      "Epoch 37/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.8480 - categorical_accuracy: 0.3719 - top_3_accuracy: 0.5664\n",
      "\n",
      "Epoch 00037: top_3_accuracy did not improve from 0.57203\n",
      "Epoch 38/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.7981 - categorical_accuracy: 0.3803 - top_3_accuracy: 0.5800\n",
      "\n",
      "Epoch 00038: top_3_accuracy improved from 0.57203 to 0.58000, saving model to ./CNN_2_dropout.model\n",
      "Epoch 39/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.8217 - categorical_accuracy: 0.3912 - top_3_accuracy: 0.5727\n",
      "\n",
      "Epoch 00039: top_3_accuracy did not improve from 0.58000\n",
      "Epoch 40/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.8163 - categorical_accuracy: 0.3848 - top_3_accuracy: 0.5786\n",
      "\n",
      "Epoch 00040: top_3_accuracy did not improve from 0.58000\n",
      "Epoch 41/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.7804 - categorical_accuracy: 0.3777 - top_3_accuracy: 0.5742\n",
      "\n",
      "Epoch 00041: top_3_accuracy did not improve from 0.58000\n",
      "Epoch 42/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.8409 - categorical_accuracy: 0.3802 - top_3_accuracy: 0.5800\n",
      "\n",
      "Epoch 00042: top_3_accuracy did not improve from 0.58000\n",
      "Epoch 43/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.7782 - categorical_accuracy: 0.3895 - top_3_accuracy: 0.5875\n",
      "\n",
      "Epoch 00043: top_3_accuracy improved from 0.58000 to 0.58750, saving model to ./CNN_2_dropout.model\n",
      "Epoch 44/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.7588 - categorical_accuracy: 0.3870 - top_3_accuracy: 0.5892\n",
      "\n",
      "Epoch 00044: top_3_accuracy improved from 0.58750 to 0.58922, saving model to ./CNN_2_dropout.model\n",
      "Epoch 45/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.7527 - categorical_accuracy: 0.3898 - top_3_accuracy: 0.5855\n",
      "\n",
      "Epoch 00045: top_3_accuracy did not improve from 0.58922\n",
      "Epoch 46/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.7147 - categorical_accuracy: 0.3984 - top_3_accuracy: 0.5837\n",
      "\n",
      "Epoch 00046: top_3_accuracy did not improve from 0.58922\n",
      "Epoch 47/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.7819 - categorical_accuracy: 0.3916 - top_3_accuracy: 0.5787\n",
      "\n",
      "Epoch 00047: top_3_accuracy did not improve from 0.58922\n",
      "Epoch 48/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 2.7804 - categorical_accuracy: 0.3967 - top_3_accuracy: 0.5861\n",
      "\n",
      "Epoch 00048: top_3_accuracy did not improve from 0.58922\n",
      "Epoch 49/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.7510 - categorical_accuracy: 0.3916 - top_3_accuracy: 0.5906\n",
      "\n",
      "Epoch 00049: top_3_accuracy improved from 0.58922 to 0.59062, saving model to ./CNN_2_dropout.model\n",
      "Epoch 50/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.7283 - categorical_accuracy: 0.4098 - top_3_accuracy: 0.5941\n",
      "\n",
      "Epoch 00050: top_3_accuracy improved from 0.59062 to 0.59406, saving model to ./CNN_2_dropout.model\n",
      "Epoch 51/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.7328 - categorical_accuracy: 0.3964 - top_3_accuracy: 0.5908\n",
      "\n",
      "Epoch 00051: top_3_accuracy did not improve from 0.59406\n",
      "Epoch 52/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.6617 - categorical_accuracy: 0.4113 - top_3_accuracy: 0.6039\n",
      "\n",
      "Epoch 00052: top_3_accuracy improved from 0.59406 to 0.60391, saving model to ./CNN_2_dropout.model\n",
      "Epoch 53/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.6905 - categorical_accuracy: 0.4064 - top_3_accuracy: 0.5992\n",
      "\n",
      "Epoch 00053: top_3_accuracy did not improve from 0.60391\n",
      "Epoch 54/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.6905 - categorical_accuracy: 0.4080 - top_3_accuracy: 0.6017\n",
      "\n",
      "Epoch 00054: top_3_accuracy did not improve from 0.60391\n",
      "Epoch 55/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.6534 - categorical_accuracy: 0.4098 - top_3_accuracy: 0.6073\n",
      "\n",
      "Epoch 00055: top_3_accuracy improved from 0.60391 to 0.60734, saving model to ./CNN_2_dropout.model\n",
      "Epoch 56/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.6378 - categorical_accuracy: 0.4139 - top_3_accuracy: 0.6155\n",
      "\n",
      "Epoch 00056: top_3_accuracy improved from 0.60734 to 0.61547, saving model to ./CNN_2_dropout.model\n",
      "Epoch 57/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.6693 - categorical_accuracy: 0.4148 - top_3_accuracy: 0.6073\n",
      "\n",
      "Epoch 00057: top_3_accuracy did not improve from 0.61547\n",
      "Epoch 58/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.6374 - categorical_accuracy: 0.4159 - top_3_accuracy: 0.6144\n",
      "\n",
      "Epoch 00058: top_3_accuracy did not improve from 0.61547\n",
      "Epoch 59/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.6571 - categorical_accuracy: 0.4211 - top_3_accuracy: 0.6142\n",
      "\n",
      "Epoch 00059: top_3_accuracy did not improve from 0.61547\n",
      "Epoch 60/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.6968 - categorical_accuracy: 0.4067 - top_3_accuracy: 0.5975\n",
      "\n",
      "Epoch 00060: top_3_accuracy did not improve from 0.61547\n",
      "Epoch 61/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5691 - categorical_accuracy: 0.4272 - top_3_accuracy: 0.6250\n",
      "\n",
      "Epoch 00061: top_3_accuracy improved from 0.61547 to 0.62500, saving model to ./CNN_2_dropout.model\n",
      "Epoch 62/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5984 - categorical_accuracy: 0.4217 - top_3_accuracy: 0.6131\n",
      "\n",
      "Epoch 00062: top_3_accuracy did not improve from 0.62500\n",
      "Epoch 63/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5911 - categorical_accuracy: 0.4261 - top_3_accuracy: 0.6308\n",
      "\n",
      "Epoch 00063: top_3_accuracy improved from 0.62500 to 0.63078, saving model to ./CNN_2_dropout.model\n",
      "Epoch 64/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.6446 - categorical_accuracy: 0.4130 - top_3_accuracy: 0.6055\n",
      "\n",
      "Epoch 00064: top_3_accuracy did not improve from 0.63078\n",
      "Epoch 65/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.6664 - categorical_accuracy: 0.4164 - top_3_accuracy: 0.6133\n",
      "\n",
      "Epoch 00065: top_3_accuracy did not improve from 0.63078\n",
      "Epoch 66/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.6021 - categorical_accuracy: 0.4258 - top_3_accuracy: 0.6131\n",
      "\n",
      "Epoch 00066: top_3_accuracy did not improve from 0.63078\n",
      "Epoch 67/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5660 - categorical_accuracy: 0.4278 - top_3_accuracy: 0.6292\n",
      "\n",
      "Epoch 00067: top_3_accuracy did not improve from 0.63078\n",
      "Epoch 68/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.6063 - categorical_accuracy: 0.4272 - top_3_accuracy: 0.6173\n",
      "\n",
      "Epoch 00068: top_3_accuracy did not improve from 0.63078\n",
      "Epoch 69/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 2.5539 - categorical_accuracy: 0.4355 - top_3_accuracy: 0.6323\n",
      "\n",
      "Epoch 00069: top_3_accuracy improved from 0.63078 to 0.63234, saving model to ./CNN_2_dropout.model\n",
      "Epoch 70/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.6268 - categorical_accuracy: 0.4105 - top_3_accuracy: 0.6120\n",
      "\n",
      "Epoch 00070: top_3_accuracy did not improve from 0.63234\n",
      "Epoch 71/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5703 - categorical_accuracy: 0.4297 - top_3_accuracy: 0.6259\n",
      "\n",
      "Epoch 00071: top_3_accuracy did not improve from 0.63234\n",
      "Epoch 72/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5361 - categorical_accuracy: 0.4361 - top_3_accuracy: 0.6270\n",
      "\n",
      "Epoch 00072: top_3_accuracy did not improve from 0.63234\n",
      "Epoch 73/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5469 - categorical_accuracy: 0.4356 - top_3_accuracy: 0.6269\n",
      "\n",
      "Epoch 00073: top_3_accuracy did not improve from 0.63234\n",
      "Epoch 74/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5870 - categorical_accuracy: 0.4323 - top_3_accuracy: 0.6202\n",
      "\n",
      "Epoch 00074: top_3_accuracy did not improve from 0.63234\n",
      "Epoch 75/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5511 - categorical_accuracy: 0.4336 - top_3_accuracy: 0.6331\n",
      "\n",
      "Epoch 00075: top_3_accuracy improved from 0.63234 to 0.63313, saving model to ./CNN_2_dropout.model\n",
      "Epoch 76/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5893 - categorical_accuracy: 0.4353 - top_3_accuracy: 0.6272\n",
      "\n",
      "Epoch 00076: top_3_accuracy did not improve from 0.63313\n",
      "Epoch 77/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 2.5885 - categorical_accuracy: 0.4208 - top_3_accuracy: 0.6161\n",
      "\n",
      "Epoch 00077: top_3_accuracy did not improve from 0.63313\n",
      "Epoch 78/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 2.5604 - categorical_accuracy: 0.4314 - top_3_accuracy: 0.6275\n",
      "\n",
      "Epoch 00078: top_3_accuracy did not improve from 0.63313\n",
      "Epoch 79/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 2.5311 - categorical_accuracy: 0.4327 - top_3_accuracy: 0.6311\n",
      "\n",
      "Epoch 00079: top_3_accuracy did not improve from 0.63313\n",
      "Epoch 80/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.5437 - categorical_accuracy: 0.4425 - top_3_accuracy: 0.6336\n",
      "\n",
      "Epoch 00080: top_3_accuracy improved from 0.63313 to 0.63359, saving model to ./CNN_2_dropout.model\n",
      "Epoch 81/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5380 - categorical_accuracy: 0.4406 - top_3_accuracy: 0.6366\n",
      "\n",
      "Epoch 00081: top_3_accuracy improved from 0.63359 to 0.63656, saving model to ./CNN_2_dropout.model\n",
      "Epoch 82/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5429 - categorical_accuracy: 0.4317 - top_3_accuracy: 0.6323\n",
      "\n",
      "Epoch 00082: top_3_accuracy did not improve from 0.63656\n",
      "Epoch 83/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.5036 - categorical_accuracy: 0.4441 - top_3_accuracy: 0.6297\n",
      "\n",
      "Epoch 00083: top_3_accuracy did not improve from 0.63656\n",
      "Epoch 84/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5435 - categorical_accuracy: 0.4422 - top_3_accuracy: 0.6358\n",
      "\n",
      "Epoch 00084: top_3_accuracy did not improve from 0.63656\n",
      "Epoch 85/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5401 - categorical_accuracy: 0.4383 - top_3_accuracy: 0.6373\n",
      "\n",
      "Epoch 00085: top_3_accuracy improved from 0.63656 to 0.63734, saving model to ./CNN_2_dropout.model\n",
      "Epoch 86/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5737 - categorical_accuracy: 0.4334 - top_3_accuracy: 0.6278\n",
      "\n",
      "Epoch 00086: top_3_accuracy did not improve from 0.63734\n",
      "Epoch 87/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5456 - categorical_accuracy: 0.4364 - top_3_accuracy: 0.6316\n",
      "\n",
      "Epoch 00087: top_3_accuracy did not improve from 0.63734\n",
      "Epoch 88/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5439 - categorical_accuracy: 0.4402 - top_3_accuracy: 0.6373\n",
      "\n",
      "Epoch 00088: top_3_accuracy did not improve from 0.63734\n",
      "Epoch 89/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.5313 - categorical_accuracy: 0.4397 - top_3_accuracy: 0.6312\n",
      "\n",
      "Epoch 00089: top_3_accuracy did not improve from 0.63734\n",
      "Epoch 90/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.4787 - categorical_accuracy: 0.4536 - top_3_accuracy: 0.6484\n",
      "\n",
      "Epoch 00090: top_3_accuracy improved from 0.63734 to 0.64844, saving model to ./CNN_2_dropout.model\n",
      "Epoch 91/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.5380 - categorical_accuracy: 0.4353 - top_3_accuracy: 0.6280\n",
      "\n",
      "Epoch 00091: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 92/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.5135 - categorical_accuracy: 0.4398 - top_3_accuracy: 0.6339\n",
      "\n",
      "Epoch 00092: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 93/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 2.4862 - categorical_accuracy: 0.4492 - top_3_accuracy: 0.6386\n",
      "\n",
      "Epoch 00093: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 94/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5122 - categorical_accuracy: 0.4386 - top_3_accuracy: 0.6403\n",
      "\n",
      "Epoch 00094: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 95/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5959 - categorical_accuracy: 0.4355 - top_3_accuracy: 0.6213\n",
      "\n",
      "Epoch 00095: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 96/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5377 - categorical_accuracy: 0.4412 - top_3_accuracy: 0.6336\n",
      "\n",
      "Epoch 00096: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 97/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.5323 - categorical_accuracy: 0.4405 - top_3_accuracy: 0.6331\n",
      "\n",
      "Epoch 00097: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 98/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5274 - categorical_accuracy: 0.4305 - top_3_accuracy: 0.6314\n",
      "\n",
      "Epoch 00098: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 99/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5540 - categorical_accuracy: 0.4364 - top_3_accuracy: 0.6309\n",
      "\n",
      "Epoch 00099: top_3_accuracy did not improve from 0.64844\n",
      "Epoch 100/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.4429 - categorical_accuracy: 0.4480 - top_3_accuracy: 0.6552\n",
      "\n",
      "Epoch 00100: top_3_accuracy improved from 0.64844 to 0.65516, saving model to ./CNN_2_dropout.model\n",
      "Epoch 101/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5367 - categorical_accuracy: 0.4363 - top_3_accuracy: 0.6281\n",
      "\n",
      "Epoch 00101: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 102/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.4642 - categorical_accuracy: 0.4569 - top_3_accuracy: 0.6477\n",
      "\n",
      "Epoch 00102: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 103/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.5264 - categorical_accuracy: 0.4392 - top_3_accuracy: 0.6356\n",
      "\n",
      "Epoch 00103: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 104/250\n",
      "100/100 [==============================] - 41s 408ms/step - loss: 2.5124 - categorical_accuracy: 0.4308 - top_3_accuracy: 0.6359\n",
      "\n",
      "Epoch 00104: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 105/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5573 - categorical_accuracy: 0.4363 - top_3_accuracy: 0.6267\n",
      "\n",
      "Epoch 00105: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 106/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 2.5237 - categorical_accuracy: 0.4373 - top_3_accuracy: 0.6309\n",
      "\n",
      "Epoch 00106: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 107/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.4712 - categorical_accuracy: 0.4483 - top_3_accuracy: 0.6405\n",
      "\n",
      "Epoch 00107: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 108/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.4885 - categorical_accuracy: 0.4444 - top_3_accuracy: 0.6370\n",
      "\n",
      "Epoch 00108: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 109/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5400 - categorical_accuracy: 0.4370 - top_3_accuracy: 0.6356\n",
      "\n",
      "Epoch 00109: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 110/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5313 - categorical_accuracy: 0.4417 - top_3_accuracy: 0.6364\n",
      "\n",
      "Epoch 00110: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 111/250\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 2.5306 - categorical_accuracy: 0.4308 - top_3_accuracy: 0.6359\n",
      "\n",
      "Epoch 00111: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 112/250\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 2.5200 - categorical_accuracy: 0.4405 - top_3_accuracy: 0.6381\n",
      "\n",
      "Epoch 00112: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 113/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.5009 - categorical_accuracy: 0.4500 - top_3_accuracy: 0.6405\n",
      "\n",
      "Epoch 00113: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 114/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.4772 - categorical_accuracy: 0.4455 - top_3_accuracy: 0.6469\n",
      "\n",
      "Epoch 00114: top_3_accuracy did not improve from 0.65516\n",
      "Epoch 115/250\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 2.4968 - categorical_accuracy: 0.4448 - top_3_accuracy: 0.6391\n",
      "\n",
      "Epoch 00115: top_3_accuracy did not improve from 0.65516\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "CNN_2_dropout = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "5F7-0wimGWC2",
    "outputId": "a5817a35-26d2-4727-995e-7952e587c9e1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAFMCAYAAADr3OkGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgAgEFEAAIGIAgAIRBQAQCCiAACCBU1g0nkCDbyAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d499ca350>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.legend(loc='best')\n",
    "plt.title('MAP@3')\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(CNN_2_dropout.history['top_3_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7tIDsX5CVI5P"
   },
   "source": [
    "**Вывод:** На  тестовых данных  на kaggle выдает 0.574. Результат уже лучше по сравнению с первым экспериментом. Модель переобучается не так сильно\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKjp_OhUxjeV"
   },
   "source": [
    "#Эксперимент №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrmS0FXYHqjc"
   },
   "source": [
    "Построение модели с добавлением DropOut на полносвязном слое, чтобы избежать переобучения. Сильно увеличила batch_size, чтобы установить влияет ли он на переобучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "StgdFsWLuJFh",
    "outputId": "19d3466c-02be-45e9-f5e9-70f81b71538d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 208,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWSjHWucu1x5"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKEJmGzIu2CA"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLdIcRqvu2Ju"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7eWgZzdu2XZ"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "xoQFrv-_u2UW",
    "outputId": "e09f5b23-8a64-4026-ea13-b98ac60ad451"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEHCAYAAABhvpAKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wNy73LgoPSjOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d489af410>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = images_and_labels_generator(32).next()\n",
    "plt.imshow(b[0][10, :, :])\n",
    "plt.title(b[1][10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uAmqsciu2Rf"
   },
   "outputs": [],
   "source": [
    " def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "fmnGyAuLu2Ot",
    "outputId": "b74a7f1d-ab32-43c4-cfd2-7f6516233522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 247,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "leb_V4Dtu2G6"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OixfsiL3u1_J",
    "outputId": "d5f8079f-795f-4300-f5c1-1986467fce25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MttmWKEnu18Y"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(32, (3,3),padding='same', activation='elu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same', activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='elu'))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "  \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "6OJ26IIAu15g",
    "outputId": "dc5d7a2f-5757-468c-cd38-b5972f16da4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               16777472  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               87380     \n",
      "=================================================================\n",
      "Total params: 16,883,668\n",
      "Trainable params: 16,883,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Q4GlvtVu12q"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0M11UiPyIa8"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 250 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucQ-2vdHyIkQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='top_3_accuracy', patience=15, min_delta=0.001, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n",
    "    ModelCheckpoint(\"./CNN_3_dropout.model\",monitor='top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLndo8gEyIhm"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0\n",
    "\n",
    "# you can continue from snapshot!!!\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 2\n",
    "# model = load_model(\"model_{}\".format(last_finished_epoch), \n",
    "#                    custom_objects={\"top_3_accuracy\": top_3_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7633
    },
    "colab_type": "code",
    "id": "4SvqUuXgyRE7",
    "outputId": "4d027170-bc7f-48a3-bd78-d5cda2b6f635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 4.6047 - categorical_accuracy: 0.1294 - top_3_accuracy: 0.2335\n",
      "\n",
      "Epoch 00001: top_3_accuracy improved from -inf to 0.23348, saving model to ./CNN_3_dropout.model\n",
      "Epoch 2/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 3.6135 - categorical_accuracy: 0.2605 - top_3_accuracy: 0.4238\n",
      "\n",
      "Epoch 00002: top_3_accuracy improved from 0.23348 to 0.42377, saving model to ./CNN_3_dropout.model\n",
      "Epoch 3/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 3.2490 - categorical_accuracy: 0.3213 - top_3_accuracy: 0.4953\n",
      "\n",
      "Epoch 00003: top_3_accuracy improved from 0.42377 to 0.49529, saving model to ./CNN_3_dropout.model\n",
      "Epoch 4/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 3.0486 - categorical_accuracy: 0.3541 - top_3_accuracy: 0.5332\n",
      "\n",
      "Epoch 00004: top_3_accuracy improved from 0.49529 to 0.53324, saving model to ./CNN_3_dropout.model\n",
      "Epoch 5/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 2.8849 - categorical_accuracy: 0.3810 - top_3_accuracy: 0.5666\n",
      "\n",
      "Epoch 00005: top_3_accuracy improved from 0.53324 to 0.56658, saving model to ./CNN_3_dropout.model\n",
      "Epoch 6/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.7661 - categorical_accuracy: 0.4021 - top_3_accuracy: 0.5892\n",
      "\n",
      "Epoch 00006: top_3_accuracy improved from 0.56658 to 0.58920, saving model to ./CNN_3_dropout.model\n",
      "Epoch 7/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.6987 - categorical_accuracy: 0.4120 - top_3_accuracy: 0.6012\n",
      "\n",
      "Epoch 00007: top_3_accuracy improved from 0.58920 to 0.60125, saving model to ./CNN_3_dropout.model\n",
      "Epoch 8/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 2.5905 - categorical_accuracy: 0.4332 - top_3_accuracy: 0.6239\n",
      "\n",
      "Epoch 00008: top_3_accuracy improved from 0.60125 to 0.62395, saving model to ./CNN_3_dropout.model\n",
      "Epoch 9/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.5323 - categorical_accuracy: 0.4389 - top_3_accuracy: 0.6334\n",
      "\n",
      "Epoch 00009: top_3_accuracy improved from 0.62395 to 0.63338, saving model to ./CNN_3_dropout.model\n",
      "Epoch 10/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.5099 - categorical_accuracy: 0.4482 - top_3_accuracy: 0.6379\n",
      "\n",
      "Epoch 00010: top_3_accuracy improved from 0.63338 to 0.63785, saving model to ./CNN_3_dropout.model\n",
      "Epoch 11/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.4379 - categorical_accuracy: 0.4604 - top_3_accuracy: 0.6526\n",
      "\n",
      "Epoch 00011: top_3_accuracy improved from 0.63785 to 0.65260, saving model to ./CNN_3_dropout.model\n",
      "Epoch 12/250\n",
      "100/100 [==============================] - 54s 536ms/step - loss: 2.4075 - categorical_accuracy: 0.4606 - top_3_accuracy: 0.6576\n",
      "\n",
      "Epoch 00012: top_3_accuracy improved from 0.65260 to 0.65756, saving model to ./CNN_3_dropout.model\n",
      "Epoch 13/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 2.3476 - categorical_accuracy: 0.4754 - top_3_accuracy: 0.6700\n",
      "\n",
      "Epoch 00013: top_3_accuracy improved from 0.65756 to 0.67002, saving model to ./CNN_3_dropout.model\n",
      "Epoch 14/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 2.3391 - categorical_accuracy: 0.4768 - top_3_accuracy: 0.6698\n",
      "\n",
      "Epoch 00014: top_3_accuracy did not improve from 0.67002\n",
      "Epoch 15/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 2.3114 - categorical_accuracy: 0.4861 - top_3_accuracy: 0.6738\n",
      "\n",
      "Epoch 00015: top_3_accuracy improved from 0.67002 to 0.67381, saving model to ./CNN_3_dropout.model\n",
      "Epoch 16/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.2952 - categorical_accuracy: 0.4855 - top_3_accuracy: 0.6802\n",
      "\n",
      "Epoch 00016: top_3_accuracy improved from 0.67381 to 0.68023, saving model to ./CNN_3_dropout.model\n",
      "Epoch 17/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.2714 - categorical_accuracy: 0.4904 - top_3_accuracy: 0.6838\n",
      "\n",
      "Epoch 00017: top_3_accuracy improved from 0.68023 to 0.68383, saving model to ./CNN_3_dropout.model\n",
      "Epoch 18/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.2312 - categorical_accuracy: 0.4968 - top_3_accuracy: 0.6887\n",
      "\n",
      "Epoch 00018: top_3_accuracy improved from 0.68383 to 0.68875, saving model to ./CNN_3_dropout.model\n",
      "Epoch 19/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.2123 - categorical_accuracy: 0.5014 - top_3_accuracy: 0.6939\n",
      "\n",
      "Epoch 00019: top_3_accuracy improved from 0.68875 to 0.69389, saving model to ./CNN_3_dropout.model\n",
      "Epoch 20/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 2.1841 - categorical_accuracy: 0.5057 - top_3_accuracy: 0.6974\n",
      "\n",
      "Epoch 00020: top_3_accuracy improved from 0.69389 to 0.69738, saving model to ./CNN_3_dropout.model\n",
      "Epoch 21/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.1765 - categorical_accuracy: 0.5093 - top_3_accuracy: 0.6991\n",
      "\n",
      "Epoch 00021: top_3_accuracy improved from 0.69738 to 0.69906, saving model to ./CNN_3_dropout.model\n",
      "Epoch 22/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 2.1550 - categorical_accuracy: 0.5119 - top_3_accuracy: 0.7035\n",
      "\n",
      "Epoch 00022: top_3_accuracy improved from 0.69906 to 0.70348, saving model to ./CNN_3_dropout.model\n",
      "Epoch 23/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.1419 - categorical_accuracy: 0.5210 - top_3_accuracy: 0.7072\n",
      "\n",
      "Epoch 00023: top_3_accuracy improved from 0.70348 to 0.70717, saving model to ./CNN_3_dropout.model\n",
      "Epoch 24/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.1179 - categorical_accuracy: 0.5214 - top_3_accuracy: 0.7128\n",
      "\n",
      "Epoch 00024: top_3_accuracy improved from 0.70717 to 0.71275, saving model to ./CNN_3_dropout.model\n",
      "Epoch 25/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.0971 - categorical_accuracy: 0.5227 - top_3_accuracy: 0.7148\n",
      "\n",
      "Epoch 00025: top_3_accuracy improved from 0.71275 to 0.71479, saving model to ./CNN_3_dropout.model\n",
      "Epoch 26/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 2.0820 - categorical_accuracy: 0.5308 - top_3_accuracy: 0.7194\n",
      "\n",
      "Epoch 00026: top_3_accuracy improved from 0.71479 to 0.71941, saving model to ./CNN_3_dropout.model\n",
      "Epoch 27/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 2.0714 - categorical_accuracy: 0.5261 - top_3_accuracy: 0.7185\n",
      "\n",
      "Epoch 00027: top_3_accuracy did not improve from 0.71941\n",
      "Epoch 28/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 2.0862 - categorical_accuracy: 0.5293 - top_3_accuracy: 0.7144\n",
      "\n",
      "Epoch 00028: top_3_accuracy did not improve from 0.71941\n",
      "Epoch 29/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 2.0659 - categorical_accuracy: 0.5327 - top_3_accuracy: 0.7216\n",
      "\n",
      "Epoch 00029: top_3_accuracy improved from 0.71941 to 0.72162, saving model to ./CNN_3_dropout.model\n",
      "Epoch 30/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 2.0303 - categorical_accuracy: 0.5357 - top_3_accuracy: 0.7264\n",
      "\n",
      "Epoch 00030: top_3_accuracy improved from 0.72162 to 0.72639, saving model to ./CNN_3_dropout.model\n",
      "Epoch 31/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 2.0303 - categorical_accuracy: 0.5375 - top_3_accuracy: 0.7280\n",
      "\n",
      "Epoch 00031: top_3_accuracy improved from 0.72639 to 0.72805, saving model to ./CNN_3_dropout.model\n",
      "Epoch 32/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.0147 - categorical_accuracy: 0.5416 - top_3_accuracy: 0.7295\n",
      "\n",
      "Epoch 00032: top_3_accuracy improved from 0.72805 to 0.72951, saving model to ./CNN_3_dropout.model\n",
      "Epoch 33/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.0134 - categorical_accuracy: 0.5429 - top_3_accuracy: 0.7328\n",
      "\n",
      "Epoch 00033: top_3_accuracy improved from 0.72951 to 0.73277, saving model to ./CNN_3_dropout.model\n",
      "Epoch 34/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 2.0196 - categorical_accuracy: 0.5389 - top_3_accuracy: 0.7296\n",
      "\n",
      "Epoch 00034: top_3_accuracy did not improve from 0.73277\n",
      "Epoch 35/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.9945 - categorical_accuracy: 0.5456 - top_3_accuracy: 0.7328\n",
      "\n",
      "Epoch 00035: top_3_accuracy did not improve from 0.73277\n",
      "Epoch 36/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.9870 - categorical_accuracy: 0.5474 - top_3_accuracy: 0.7339\n",
      "\n",
      "Epoch 00036: top_3_accuracy improved from 0.73277 to 0.73387, saving model to ./CNN_3_dropout.model\n",
      "Epoch 37/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 2.0038 - categorical_accuracy: 0.5413 - top_3_accuracy: 0.7329\n",
      "\n",
      "Epoch 00037: top_3_accuracy did not improve from 0.73387\n",
      "Epoch 38/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.9971 - categorical_accuracy: 0.5447 - top_3_accuracy: 0.7335\n",
      "\n",
      "Epoch 00038: top_3_accuracy did not improve from 0.73387\n",
      "Epoch 39/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.9502 - categorical_accuracy: 0.5570 - top_3_accuracy: 0.7423\n",
      "\n",
      "Epoch 00039: top_3_accuracy improved from 0.73387 to 0.74227, saving model to ./CNN_3_dropout.model\n",
      "Epoch 40/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.9294 - categorical_accuracy: 0.5618 - top_3_accuracy: 0.7453\n",
      "\n",
      "Epoch 00040: top_3_accuracy improved from 0.74227 to 0.74531, saving model to ./CNN_3_dropout.model\n",
      "Epoch 41/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.9274 - categorical_accuracy: 0.5618 - top_3_accuracy: 0.7460\n",
      "\n",
      "Epoch 00041: top_3_accuracy improved from 0.74531 to 0.74598, saving model to ./CNN_3_dropout.model\n",
      "Epoch 42/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.8874 - categorical_accuracy: 0.5708 - top_3_accuracy: 0.7537\n",
      "\n",
      "Epoch 00042: top_3_accuracy improved from 0.74598 to 0.75371, saving model to ./CNN_3_dropout.model\n",
      "Epoch 43/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.9316 - categorical_accuracy: 0.5645 - top_3_accuracy: 0.7468\n",
      "\n",
      "Epoch 00043: top_3_accuracy did not improve from 0.75371\n",
      "Epoch 44/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.9130 - categorical_accuracy: 0.5642 - top_3_accuracy: 0.7496\n",
      "\n",
      "Epoch 00044: top_3_accuracy did not improve from 0.75371\n",
      "Epoch 45/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.8846 - categorical_accuracy: 0.5708 - top_3_accuracy: 0.7555\n",
      "\n",
      "Epoch 00045: top_3_accuracy improved from 0.75371 to 0.75549, saving model to ./CNN_3_dropout.model\n",
      "Epoch 46/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.9000 - categorical_accuracy: 0.5682 - top_3_accuracy: 0.7517\n",
      "\n",
      "Epoch 00046: top_3_accuracy did not improve from 0.75549\n",
      "Epoch 47/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.8860 - categorical_accuracy: 0.5663 - top_3_accuracy: 0.7531\n",
      "\n",
      "Epoch 00047: top_3_accuracy did not improve from 0.75549\n",
      "Epoch 48/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.8792 - categorical_accuracy: 0.5698 - top_3_accuracy: 0.7548\n",
      "\n",
      "Epoch 00048: top_3_accuracy did not improve from 0.75549\n",
      "Epoch 49/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.8454 - categorical_accuracy: 0.5815 - top_3_accuracy: 0.7618\n",
      "\n",
      "Epoch 00049: top_3_accuracy improved from 0.75549 to 0.76176, saving model to ./CNN_3_dropout.model\n",
      "Epoch 50/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.8478 - categorical_accuracy: 0.5776 - top_3_accuracy: 0.7588\n",
      "\n",
      "Epoch 00050: top_3_accuracy did not improve from 0.76176\n",
      "Epoch 51/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.8404 - categorical_accuracy: 0.5768 - top_3_accuracy: 0.7629\n",
      "\n",
      "Epoch 00051: top_3_accuracy improved from 0.76176 to 0.76295, saving model to ./CNN_3_dropout.model\n",
      "Epoch 52/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.8225 - categorical_accuracy: 0.5821 - top_3_accuracy: 0.7648\n",
      "\n",
      "Epoch 00052: top_3_accuracy improved from 0.76295 to 0.76482, saving model to ./CNN_3_dropout.model\n",
      "Epoch 53/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.8430 - categorical_accuracy: 0.5780 - top_3_accuracy: 0.7595\n",
      "\n",
      "Epoch 00053: top_3_accuracy did not improve from 0.76482\n",
      "Epoch 54/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.8232 - categorical_accuracy: 0.5849 - top_3_accuracy: 0.7654\n",
      "\n",
      "Epoch 00054: top_3_accuracy improved from 0.76482 to 0.76537, saving model to ./CNN_3_dropout.model\n",
      "Epoch 55/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.8076 - categorical_accuracy: 0.5850 - top_3_accuracy: 0.7665\n",
      "\n",
      "Epoch 00055: top_3_accuracy improved from 0.76537 to 0.76654, saving model to ./CNN_3_dropout.model\n",
      "Epoch 56/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.8024 - categorical_accuracy: 0.5881 - top_3_accuracy: 0.7681\n",
      "\n",
      "Epoch 00056: top_3_accuracy improved from 0.76654 to 0.76807, saving model to ./CNN_3_dropout.model\n",
      "Epoch 57/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.8010 - categorical_accuracy: 0.5915 - top_3_accuracy: 0.7697\n",
      "\n",
      "Epoch 00057: top_3_accuracy improved from 0.76807 to 0.76967, saving model to ./CNN_3_dropout.model\n",
      "Epoch 58/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.8113 - categorical_accuracy: 0.5881 - top_3_accuracy: 0.7682\n",
      "\n",
      "Epoch 00058: top_3_accuracy did not improve from 0.76967\n",
      "Epoch 59/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.8212 - categorical_accuracy: 0.5851 - top_3_accuracy: 0.7635\n",
      "\n",
      "Epoch 00059: top_3_accuracy did not improve from 0.76967\n",
      "Epoch 60/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.7976 - categorical_accuracy: 0.5882 - top_3_accuracy: 0.7674\n",
      "\n",
      "Epoch 00060: top_3_accuracy did not improve from 0.76967\n",
      "Epoch 61/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.8073 - categorical_accuracy: 0.5874 - top_3_accuracy: 0.7671\n",
      "\n",
      "Epoch 00061: top_3_accuracy did not improve from 0.76967\n",
      "Epoch 62/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7949 - categorical_accuracy: 0.5928 - top_3_accuracy: 0.7698\n",
      "\n",
      "Epoch 00062: top_3_accuracy improved from 0.76967 to 0.76977, saving model to ./CNN_3_dropout.model\n",
      "Epoch 63/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7893 - categorical_accuracy: 0.5893 - top_3_accuracy: 0.7688\n",
      "\n",
      "Epoch 00063: top_3_accuracy did not improve from 0.76977\n",
      "Epoch 64/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.7971 - categorical_accuracy: 0.5905 - top_3_accuracy: 0.7693\n",
      "\n",
      "Epoch 00064: top_3_accuracy did not improve from 0.76977\n",
      "Epoch 65/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.8009 - categorical_accuracy: 0.5916 - top_3_accuracy: 0.7682\n",
      "\n",
      "Epoch 00065: top_3_accuracy did not improve from 0.76977\n",
      "Epoch 66/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.8031 - categorical_accuracy: 0.5900 - top_3_accuracy: 0.7685\n",
      "\n",
      "Epoch 00066: top_3_accuracy did not improve from 0.76977\n",
      "Epoch 67/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7986 - categorical_accuracy: 0.5906 - top_3_accuracy: 0.7684\n",
      "\n",
      "Epoch 00067: top_3_accuracy did not improve from 0.76977\n",
      "Epoch 68/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7902 - categorical_accuracy: 0.5909 - top_3_accuracy: 0.7689\n",
      "\n",
      "Epoch 00068: top_3_accuracy did not improve from 0.76977\n",
      "Epoch 69/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7926 - categorical_accuracy: 0.5914 - top_3_accuracy: 0.7706\n",
      "\n",
      "Epoch 00069: top_3_accuracy improved from 0.76977 to 0.77061, saving model to ./CNN_3_dropout.model\n",
      "Epoch 70/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.7921 - categorical_accuracy: 0.5937 - top_3_accuracy: 0.7719\n",
      "\n",
      "Epoch 00070: top_3_accuracy improved from 0.77061 to 0.77193, saving model to ./CNN_3_dropout.model\n",
      "Epoch 71/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7874 - categorical_accuracy: 0.5922 - top_3_accuracy: 0.7714\n",
      "\n",
      "Epoch 00071: top_3_accuracy did not improve from 0.77193\n",
      "Epoch 72/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7974 - categorical_accuracy: 0.5920 - top_3_accuracy: 0.7694\n",
      "\n",
      "Epoch 00072: top_3_accuracy did not improve from 0.77193\n",
      "Epoch 73/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.7807 - categorical_accuracy: 0.5966 - top_3_accuracy: 0.7724\n",
      "\n",
      "Epoch 00073: top_3_accuracy improved from 0.77193 to 0.77240, saving model to ./CNN_3_dropout.model\n",
      "Epoch 74/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.8100 - categorical_accuracy: 0.5868 - top_3_accuracy: 0.7659\n",
      "\n",
      "Epoch 00074: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 75/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7907 - categorical_accuracy: 0.5905 - top_3_accuracy: 0.7696\n",
      "\n",
      "Epoch 00075: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 76/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.8031 - categorical_accuracy: 0.5916 - top_3_accuracy: 0.7694\n",
      "\n",
      "Epoch 00076: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 77/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.7843 - categorical_accuracy: 0.5934 - top_3_accuracy: 0.7713\n",
      "\n",
      "Epoch 00077: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 78/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.7859 - categorical_accuracy: 0.5947 - top_3_accuracy: 0.7709\n",
      "\n",
      "Epoch 00078: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 79/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.7795 - categorical_accuracy: 0.5971 - top_3_accuracy: 0.7712\n",
      "\n",
      "Epoch 00079: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 80/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7879 - categorical_accuracy: 0.5960 - top_3_accuracy: 0.7717\n",
      "\n",
      "Epoch 00080: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 81/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7735 - categorical_accuracy: 0.5958 - top_3_accuracy: 0.7713\n",
      "\n",
      "Epoch 00081: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 82/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7915 - categorical_accuracy: 0.5922 - top_3_accuracy: 0.7718\n",
      "\n",
      "Epoch 00082: top_3_accuracy did not improve from 0.77240\n",
      "Epoch 83/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7616 - categorical_accuracy: 0.5963 - top_3_accuracy: 0.7746\n",
      "\n",
      "Epoch 00083: top_3_accuracy improved from 0.77240 to 0.77463, saving model to ./CNN_3_dropout.model\n",
      "Epoch 84/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7705 - categorical_accuracy: 0.5943 - top_3_accuracy: 0.7732\n",
      "\n",
      "Epoch 00084: top_3_accuracy did not improve from 0.77463\n",
      "Epoch 85/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7658 - categorical_accuracy: 0.5965 - top_3_accuracy: 0.7732\n",
      "\n",
      "Epoch 00085: top_3_accuracy did not improve from 0.77463\n",
      "Epoch 86/250\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.7763 - categorical_accuracy: 0.5968 - top_3_accuracy: 0.7739\n",
      "\n",
      "Epoch 00086: top_3_accuracy did not improve from 0.77463\n",
      "Epoch 87/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.7868 - categorical_accuracy: 0.5908 - top_3_accuracy: 0.7700\n",
      "\n",
      "Epoch 00087: top_3_accuracy did not improve from 0.77463\n",
      "Epoch 88/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7850 - categorical_accuracy: 0.5916 - top_3_accuracy: 0.7709\n",
      "\n",
      "Epoch 00088: top_3_accuracy did not improve from 0.77463\n",
      "Epoch 89/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7784 - categorical_accuracy: 0.5941 - top_3_accuracy: 0.7723\n",
      "\n",
      "Epoch 00089: top_3_accuracy did not improve from 0.77463\n",
      "Epoch 90/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7868 - categorical_accuracy: 0.5928 - top_3_accuracy: 0.7690\n",
      "\n",
      "Epoch 00090: top_3_accuracy did not improve from 0.77463\n",
      "Epoch 91/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7705 - categorical_accuracy: 0.5982 - top_3_accuracy: 0.7741\n",
      "\n",
      "Epoch 00091: top_3_accuracy did not improve from 0.77463\n",
      "Epoch 92/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.7587 - categorical_accuracy: 0.5959 - top_3_accuracy: 0.7754\n",
      "\n",
      "Epoch 00092: top_3_accuracy improved from 0.77463 to 0.77539, saving model to ./CNN_3_dropout.model\n",
      "Epoch 93/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7938 - categorical_accuracy: 0.5897 - top_3_accuracy: 0.7700\n",
      "\n",
      "Epoch 00093: top_3_accuracy did not improve from 0.77539\n",
      "Epoch 94/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7729 - categorical_accuracy: 0.6000 - top_3_accuracy: 0.7744\n",
      "\n",
      "Epoch 00094: top_3_accuracy did not improve from 0.77539\n",
      "Epoch 95/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7675 - categorical_accuracy: 0.5954 - top_3_accuracy: 0.7726\n",
      "\n",
      "Epoch 00095: top_3_accuracy did not improve from 0.77539\n",
      "Epoch 96/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7641 - categorical_accuracy: 0.5970 - top_3_accuracy: 0.7734\n",
      "\n",
      "Epoch 00096: top_3_accuracy did not improve from 0.77539\n",
      "Epoch 97/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7742 - categorical_accuracy: 0.5944 - top_3_accuracy: 0.7757\n",
      "\n",
      "Epoch 00097: top_3_accuracy improved from 0.77539 to 0.77566, saving model to ./CNN_3_dropout.model\n",
      "Epoch 98/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7791 - categorical_accuracy: 0.5943 - top_3_accuracy: 0.7733\n",
      "\n",
      "Epoch 00098: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 99/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7666 - categorical_accuracy: 0.5949 - top_3_accuracy: 0.7724\n",
      "\n",
      "Epoch 00099: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 100/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7794 - categorical_accuracy: 0.5945 - top_3_accuracy: 0.7696\n",
      "\n",
      "Epoch 00100: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 101/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.7963 - categorical_accuracy: 0.5892 - top_3_accuracy: 0.7685\n",
      "\n",
      "Epoch 00101: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 102/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7744 - categorical_accuracy: 0.5927 - top_3_accuracy: 0.7720\n",
      "\n",
      "Epoch 00102: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 103/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7662 - categorical_accuracy: 0.5965 - top_3_accuracy: 0.7734\n",
      "\n",
      "Epoch 00103: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 104/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7843 - categorical_accuracy: 0.5927 - top_3_accuracy: 0.7715\n",
      "\n",
      "Epoch 00104: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 105/250\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.7802 - categorical_accuracy: 0.5960 - top_3_accuracy: 0.7706\n",
      "\n",
      "Epoch 00105: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 106/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7839 - categorical_accuracy: 0.5934 - top_3_accuracy: 0.7709\n",
      "\n",
      "Epoch 00106: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 107/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7758 - categorical_accuracy: 0.5971 - top_3_accuracy: 0.7723\n",
      "\n",
      "Epoch 00107: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 108/250\n",
      "100/100 [==============================] - 54s 536ms/step - loss: 1.7736 - categorical_accuracy: 0.5957 - top_3_accuracy: 0.7727\n",
      "\n",
      "Epoch 00108: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 109/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7949 - categorical_accuracy: 0.5940 - top_3_accuracy: 0.7726\n",
      "\n",
      "Epoch 00109: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 110/250\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 1.7801 - categorical_accuracy: 0.5939 - top_3_accuracy: 0.7711\n",
      "\n",
      "Epoch 00110: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 111/250\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.7715 - categorical_accuracy: 0.5943 - top_3_accuracy: 0.7732\n",
      "\n",
      "Epoch 00111: top_3_accuracy did not improve from 0.77566\n",
      "Epoch 112/250\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.7823 - categorical_accuracy: 0.5927 - top_3_accuracy: 0.7711\n",
      "\n",
      "Epoch 00112: top_3_accuracy did not improve from 0.77566\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "CNN_3_dropout = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgTeWbR1DcAT"
   },
   "source": [
    "**Вывод:** Итоговое качество на Kaggle 0.67. Без регуляризации простая CNN работает лучше, хотя скорее всего на повышение качество повлиял именно batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1tBvplLILjs"
   },
   "source": [
    "#Эксперимент №4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2p4nrYoIl-V"
   },
   "source": [
    "Так как простая CNN c двумя conv слоями дала хороший реузльтат (почти 0.7 на тестовых данных). В этом эксперименте добавлю еще несколько сверточных слоев для распознавания новых фильтров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bCVUtEQ6INE-",
    "outputId": "95ff3f40-5749-49db-9b63-be929566747f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ca5JXAU3Itag"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2yZ-zn_Itnu"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G63tEqEeItvw"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2lA9awPItso"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "Tvk-FQDWItkz",
    "outputId": "a0cec260-f364-45a7-df9b-06a2126a53f8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEHCAYAAABhvpAKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAGK1JREFUeJzt3XuwJGV5x/HvYY26LBFwCVlEg6j4\nrNaeMuUlirACHijkosQ5GKuyck+hnEUxBC+lIhfNYmkRvM0xUAgIaEjCWRWirmRPYryTLSTsITJP\nXC9o2EXQjbhYurIw+aO7d3vm9JyZ09PT3TP9+1RN7dmZOd3P6Zmn37ff9+33HWs2m4hI9exVdAAi\nUgwlv0hFKflFKkrJL1JRSn6RilLyi1SUkl8AMLMrzOwt4c/Hm9mfFB2TDNaY+vmlnZltAD7o7t8s\nOhYZHCX/iDKzJwF/D6wGlgCbgRuAv3P354XvORq41t2fZ2Y3AFuApwDvBrYC7wRuA64Ot/M74G/d\n/WYz2xu4HvhT4MnAjLtfFG73DcAl4X4fA97m7l8zs2cCnwIsDPMCd//KAA+DLEDV/tF1PHAosBI4\nDPhvYGe3X3L3i4EHgDXu/o/A3wBPdvdDgeOAT5rZM4DzgD8Mt/9i4EwzOzLczDRwkru/AJgCXhc+\n/xngv9z9+cCJwM1mtjyLP1YWT8k/uh4GXgi8Htg7TOquyZ/gROAWAHf/X+CZ7r7V3a8ETnH3prv/\nH8HJ5Tnh7zwEvMXMDnH3b7r7hWa2DDgGuCrc1hbgG8BJ6f9E6YeSf0S5+38Cbw0fD5rZ54D9Umzq\nAOBXse0+CmBmhwHrzewHZtYAXsqe79PrgBXAXWZ2t5kdBewLjAHfNrNG7HfSxCQZeFLRAcjguPut\nwK1m9nTgOoITwZLYW/bvYTO/IDgBABBet28H6sBdwJ+7++Nm9q3Yfn8InGVmewGnA58DDgEeB14a\nnUCkWCr5R5SZnWVmFwO4+3agAWwDDjKzA81sCbCmw68/xp4S+TbgdDMbM7MVwN0EJ4MDgbvDxD+O\noF1hHzP7IzP7VzN7mrs/AXwXaLr7LuBLQNSduLeZXWdmzxrE3y/dKflH1xeBl4TV8vsIrv/fRlAD\nuBv4JjDb4XdvBW4xswsJrtEfAu4HvgZc5O4/BT4IXGlm9wJHAZeFj+cDG4BNZvZ9gvaCc8Ltngcc\nFVb5vwf8yN1/lulfLT1TV59IRankF6koJb9IRWXe2m9mVwGvAJoEI7g2Zb0PEelfpiV/2J97mLsf\nTtDI8/Esty8i2cm65J8AvgDg7veZ2f5hl8+vk948NjbWnJubY3x8POMwFm/Y46jVagBMTEy0PD81\nNZVJXJHp6WkA1q5dm+l2Oxn2z6UMcTSbzbGk57NO/hUEAz8iD4fPJSb/3Nwcq1atoiw9Doqju+hk\nkvVJZSFlOR6jFsegR/glnnEi4+PjNJtNxsYWfFsuhjmORqOBmXV/YxfuDsDs7CxTU1O7/99p23nU\nAob5cylLHJ1OFpn285vZpcA2d786/P+PgBe5+47EnY+NNYf5oBYVR1TFn5mZ6bq9KEHjZmdnWb9+\nfc9x1Go11q1bBySfCKKTxHve8x6ArttejGH6XMoaR6dqf9ZdfXcApwKY2YuBrZ0SX0SKlfkIPzP7\nEPAq4Algrbvf03HnKvkXHUenKn7WpW+nOKJax7p16zpeDrg7K1eu7Gv/3eLI2zDHkVeDH+7+7qy3\nKSLZK3Rsv0r+7nH0cn0/PT2deaNbv20Pk5OTwOBqIHkb5jjyuuYXkSGhkj9Uxjjyur7vFsdificS\nxdjvtX8ZP5dhiyO3a37pX71eB5K71QZRxc9K1K04NTW1O/bo0mAQJyjpj6r9IhWlan+oTHEkjazL\nqgFtMXGkPR5ZVv/L9LkMaxxq8BORVs1ms7BHsPtmk+De/0IfZYojrl6vN+v1+lAdj1qtlvh3DPvn\nUnQMaePolH8q+UskaugbduvXr8fdd1f5Id+7AKU3Sn6RilJXX8mVtVuvm2gMQnz0X1SzGda/adSo\n5BepKHX1hcoQR/tnkeXdcWliyeJ4NBoNoLXbcjHbLcPnMuxxaIRfiUWj4NrNznZaUGd4qPpfXqr2\ni1SV+vmL78eN+vLb1Wq1kTkejUZj3t9X9s9lVOJQP7+ItFLJX/yZvdFopC4Zh+V4pB31V/RxGIU4\nVPKLSAt19YWKjKP9M8h7VZwkgzgeSd1+3e5W1Pej/zia6uorp1EZz9+LaMxC/GQXrQegyT7yp2q/\nSEWp5C+hUR/8oum+ykElv0hFqcEvVFQc8ePv7phZZY5H+98O86f7qvr3I4s4Mm/wM7MPA6vDbVwB\nbAJuApYA24DT3H1n2u1X0ezsbCar7Q6L6enp3ZN8VOnvLotU1X4zOwZY5e6HA68BPgpcDtTdfTWw\nBTg7syhFJHNpr/m/Drwh/PlXwDLgaOC28LnbgWP7iqwi4ktoT0xMFBiJVE2qar+7Pw78JvzvOcCX\ngeNj1fyHgIO6bWdubg6YP8ilKEXHEVV9i44jUkQcSfus8vFIklUcfbX2m9kpBMl/fttLPbVIjI+P\nB28eGyv8UVQc8ZJ/98GryPHo5W+v0vEYVBydpE5+MzseeC9wgrs/AjxqZkvDlw8GtqbddpUkTdhR\nq9U6TvAhkpW0DX77Ah8BTnb37eHTG4HJ8OdJYEP/4YnIoKTt6nsjcADwT7EumjOAa83szcD9wGf6\nD2/0JY1oixr+NNpNBiltg981wDUJLx3XXzgikheN7S+B9oU51eUnedDYfpGKUslfAlGLf1Tya6ir\n5EElfwnMzs527PIbZUm3LqubMz9KfpGKUvKXwPr16xfs8quSiYmJSv7dRVDyi1RUKRr8arXa7okc\nB93YlTSePNLPZJrRNXs/A3OiyTxE8lCKmXyq/KV3990njomJiXnHYaEbMwYpr5lruk1bPswz6JQl\njk4z+ajaL1JRhVb7oy6deGkXjXYb1PLU0bRRZWFmC9Z6opIxfrmSxSWGiEp+kYoqRYNfXPvsrVnr\nNCd+v9d0US1msd1USdf5SeI1lqTaS6ca06ivASDplaLBb3JysvAqbJkadKL16+InkiwuV5JOEJ0u\nIdTg12qY41CDn4i0KEXJP6xn1KLjiI9LiGoJWXSZRvPpR6Xw7OzswGpmKvkHH4dKfhFpoZI/NKpx\nJI1azKr9oN/GxXq9Pi+WqL0jqmmM6ueSZxwq+UWkhUr+UFXjSOqizHIg1EKDkxqNRtfhzFX9XLKM\no1PJX2jyu3vTzJieni68P3qYP9w84mi/fOh1fEKv2rsh1eCXXRyq9otIi0JLfmD3ztsbenIPZIjP\n7GWJY1CXEIsZnDQow/y5qOQXkRalKfnbB3fkHsgQn9mHJY6oZjCoiVvaJ2rJcnDSMH8uA2nwCxfm\nvBf4ADAL3AQsAbYBp8WW7O4Y17yARnzyCsXROqovqtK339AVNTDGRxoWOT5hmD+XQVX73wdEC3Ve\nDtTdfTWwBTi7z22LyAClLvnNbCVwBXAP8BPgEmClu+80s8OBi9x9coFNMD093Ww/m6vkH/044t+5\nbpd7neLIe3zCzMzM0H4umVf7zexLwPkEq/P+BPiwux8YvvZc4CZ3f+VC2/jlL3/ZXL58ear9i0jP\nEpM/1WQeZnY68B13/3GHRpueTk3nnnsuMzMzLc8V1fBXhRK36Dji1/GRbl28/cYxqMFJnWaBHvT3\nNmXJn/h82pl8TgKeY2YnA88EdgKPmtlSd/8tcDCwNeW2RSQHfXf1mdmlBNX+VwJfd/ebzezjwGZ3\nv3bBnYdj++M6tf4O2iiXuGWJo9FoAK1dfN32kcfxqNVq86ZfG9TgpH5rBqW45o/Ekv+rwI3AU4H7\ngbPc/bGFfjdK/mjyiLbX+oprsUY56coSR9LEHd2SoQzHo1arMTMz01LVz3rylLiFxidkmfx9T+Dp\n7pfG/ntcv9sTkZw0m83CHsHum81ardZsV6/Xm/V6vUkwEGjgj/D6o/DHqMbR6TMeteMRfW/r9Xqz\n0Wg0G43GvL87jUaj0azX66mOR6f809h+kYoqzWQe7XHk3fAXxVG0UY0jacquXrY/ascji8FJi82N\nZhkn84gnf1IfcPieXGIZtS9Z2eKIf88W8+Ud1ePRTS/jE3qNp1Pyq9ovUlWdGgPyeBBrSKnVaqkb\nhbJ4pGlIURy9P+INX4tpzB3V45E2hjS5oQY/EWlRmoU6Ow1qWOzCl1JOK1eu3N3YVfS6jBIoTfJH\nosagqHEj69lepDhK+v64e6b5oGq/SEWVLvlnZ2fnTbNUr9cTl50SqZL2vOj35qPSJb+I5KN01/zR\nXV5ZTskkIvOp5BepKCW/yJBov+aH4F6BqAt1sZT8IkMiqat0YmIi9VgYJb9IRZWuwS8SX6VFo/xE\nsqeSX6SiSlvyx2mIr8geWdWKhyL5RSRZPwWjqv0iFaXkF6koJb9IRemaX2TIJN3/Et31upjlwFIn\nv5mtAd4J7ALeD2wGbgKWANuA09x9Z9rti8hgpar2m9ly4BLgSOBk4BTgcqDu7quBLcDZWQUpItlL\ne81/LLDR3Xe4+zZ3Pxc4GrgtfP328D2prV27dl4Vpp+bGESkVapFO8zsXcALgKcD+wOXAv/g7geG\nrz8XuMndX7nQdu69997mqlWrFr1/EVmUTFfpHQOWA68HDgH+vW0HPS0lMj4+3nUllPjJKRrZ1O8a\n5532U8WVYRTH8MbRa250KuDTVvt/Dnzb3Xe5+w+BHcAOM1savn4wsDXltkUkB2mT/w7g1Wa2V9j4\ntw+wEZgMX58ENmQQn4gMSKrkd/cHgFuB7wJfAd5K0Pp/hpl9g6At4DNZBSki2Uvdz+/uVwNXtz19\nXH/hiEheNLxXpKKU/CIVpeQXqajSJ3/Ufwn9zVQqIq1Kn/wiMhhDdUuv5vITyY5KfpGKUvKLVJSS\nX6SilPwiVdVsNgt7BLtvNoGOj7hGo9FsNBoLvj/to1sceT0Uh+LoNY56vd5s1+F3EvNPJb9IRZW2\nqy9puq6k9clFJB2V/CIVVdqSP2kYr0p+kewMVfKvX7++gEhERpOq/SIVVdqSPz6O390LjERkNKnk\nF6mo0pX86uITyUfpkj+poW8Qi3SIVJ2q/SIVNRQlv4hkTyW/SEWVruRvn6orPoGniGQnVfKb2T7A\njQTLcz8FuAx4EPgUwW2Em939vKyCFJHspa32nwm4ux8DnAp8DPgocIG7HwHsa2YnLGaD9Xqder2e\nMhwRWay0yf8LYHn48/7AduBQd98UPnc7cGyfsQHq5hMZlFTVfne/xczONLMtBMn/WiBebD8EHNRt\nO3NzcwDRrD6JFnota3nuayGKo5XiaJVVvqS95n8T8FN3f42ZvQj4PPBI7C1jvWxnfHycZrPJ2NhY\nx6DHxnraVN+iOIqmOBRHr3HU63WmpqZaXk+KsVNupa32HwF8FcDd7wGWAgfEXj8Y2Jpy2yKSg7TJ\nvwV4OYCZHQLsAO4zsyPD12vAhn4Cm56eVjefyAKS7nmp1WqJ98ckSdvPfzVwnZn9R7iNtxB09V1t\nZnsBd7r7xl43plZ+kcVLmtwmGiHby8Q3aRv8HgX+IuGl1Wm2JyL5K90Iv4i6+EQGS2P7RSqqFCV/\nvLtCU3aJ5KMUyR+nWXtEehf1iEUF6GJuiVe1X6SiCi35k7r4VPKLpNd+S/xCVPKLVFShJb9W5REp\njkp+kYoqtOTXqjwixRkr+B7l3TuPuiyKGtlXxls2FYfi6DWO9jyenp7enUvNZjMxcFX7RSqqNIN8\n1MUnki+V/CIVVZqSX118IvkqRcmvGXtE+uPuLT1mvYzxL0Xyi0j+StPVV3Q3Stm7chSH4lgojug+\nmfjt8dH71NUnIi1K0+DXaDSA9F1+mvZLZHEKTX533z3Et/3fxWpfvCCNRqMx7+Sjk4qMKlX7RSqq\n0Aa/ycnJ5szMTEsNoMyirpR47SDrmkHZG5YURznjiBbqmJmZ2f3c5ORk9Jwa/ERkj0JL/rGxsWZW\nZ9R+V/2ZmprKpAbi7n21G5S9hFEc5Y4jns+xyT0Tf6GnBj8zWwV8EbjK3T9pZs8CbgKWANuA09x9\np5mtAd4OPAFc4+6f7mX7IpK/riW/mS0D/gX4AbA5TP7rgS+7+z+b2TrgZ8CNwPeAPwN+D2wCXuXu\n2zvuPMOSv1/dBk/AniGT/dQOurUblP14KI5yx5F1yb8TOBF4V+y5owkW5wS4HbgIcGCTuz8CYGbf\nIljK+/Ye9lFa3arsSZcbC3U7JnVptr8/acyDuhwla12T3913AbvaSrtl7r4z/Pkh4CBgBfBw7D3R\n8x3Nzc0B82chKUpZ4ujlBJGHshwPxdGq1zi6fWeyGOTTqQ7StY40Pj4+NNWpfkTdMPE7rbJI5vjd\nkFEtIatbo6vwuYxiHElj/DtJ29X3qJktDX8+GNgaPlbE3hM9LyIllLbk3whMAjeH/24A7gSuNbP9\ngF0E1/tvzyLIYReVxvFSOX4NH68ZTE1NzVt/rZP4653eO8jagQy3Xlr7XwJcCTwbeAx4AFgD3AA8\nFbgfOMvdHzOzU4F3ENyq+wl3/+yCOx+C1v6yxJH3pUPZj4fiSNah2p+utd/d7yJo3W93XMJ7bwVu\n7bZNESneyIzw69ewx5FUM4DyNyx2M+yfS95xJI3xp0PJr7H9IhWlkj9UhTjyaDeAoHagLsdi42jL\na5X8IrKHSv6Q4kjf5diLtO0G+lzSxdFLya/kDymO3uJIunTI4oanTpcOZT8eZY1D1X4R6Uglf0hx\nZBtH+92OExMThU+U0o9h+1wajUb8eKvkF5E9VPKHFEf+ceQ9UUo/yvC51Go1ZmZmFlzbssNxVIPf\nQhRH+eKo1+stvQ5ZXDpkYVALy2ZxAuxA1X4R2UMlf0hxDGccWV86DLukS59Oc/ip5BepKJX8IcUx\nmnH0u55DJI+2h6RSO252dpaZmZlFH49OS3Qr+UOKQ3GMahydkl/VfpGKUvKLVJSSX6SilPwiFaXk\nF6koJb9IRSn5RSpKyS9SUUp+kYrqaa0+M1sFfBG4yt0/aWbPAq4H/oBgCa83ufuDZraGYH2+J4Br\n3P3TA4pbRPrUteQ3s2XAJ4D4gOMPEiT3UcDngQvD970fOJZgea+/NrOnZx6xiGSil2r/TuBEWpfb\nngKi9YAeBpYDLwc2ufsj7v5b4FsEK/WKSAn1slDnLmBX/C4md/8NgJktAdYClwMrCE4EkYeAgxba\n9tzcHDBvmuHCKI5WiqPVqMXR0zV/kjDxbwL+zd1nzewv297S9daj8fHxob5bSnEojmGIo9PJop/W\n/uuBH7j7ZeH/txKU/pGDab1UEJESSVXyh636v3f3S2JP3wlca2b7AbsIrvff3n+IIjIIXSfzMLOX\nAFcCzybo1nsAOBD4HfDr8G3fd/cpMzsVeAfQBD7h7p9dcOeazENxKI6Bx6GZfLpQHIpjVOPQTD4i\n0kLJL1JRSn6RilLyi1SUkl+kopT8IhWl5BepqEL7+UWkOCr5RSpKyS9SUUp+kYpS8otUlJJfpKKU\n/CIVpeQXqajUc/j1y8yuAl5BMPHHBe6+Kef9fxhYTXAMrgA2EcxJuATYBpzm7jtziGMpcC/wAYLp\n0XOPIYxjDfBOglmY3g9szjsWM9sHuBHYH3gKcBnwIPApgu/JZnc/b4D7T1qfYt4xGPT6FHmtk1FI\nyW9mRwGHufvhwDnAx3Pe/zHAqnD/rwE+SjADcd3dVwNbgLNzCud9wPbw50JiMLPlwCXAkcDJwCkF\nxXIm4O5+DHAq8DGCz+YCdz8C2NfMThjEjjusTzHvGAx6fYo818koqto/AXwBwN3vA/Y3s6fluP+v\nA28If/4VsIzgAN4WPnc7wUEdKDNbCbwQ+FL4VO4xhI4FNrr7Dnff5u7nFhTLLwjWgICg9N8OHBqr\nFQ4yjqT1KY5m/jEY9PoUua2TUVS1fwVwV+z/D4fP/Tr57dly98eB34T/PQf4MnB8rFrbdc2BjFwJ\nnA+cEf5/WQExQDA/495mdhtB0l1aRCzufouZnWlmW8I4XgvUY28ZWBxJ61OQfAwWvT5Fv3FktU5G\nu7I0+BUyOZqZnUKQ/Oe3vTTweMzsdOA77v7jDm/J85iMEZQmNYKq9/Vt+88lFjN7E/BTd38e8Grg\n5ra3FDmJXqd953VsWtbJyCKOopK/fY7/ZxA0qOTGzI4H3guc4O6PAI+GjW+Qz5oDJwGnmNl3gb8C\nLi4ghsjPgW+7+y53/yGwA9hRQCxHAF8FcPd7gKXAAbHX814LIunzKGp9iszXySgq+e8gaNDBzF4M\nbHX3HXnt3Mz2BT4CnOzuUWPbRmAy/HkS2DDIGNz9je7+Mnd/BXAtQWt/rjHE3AG82sz2Chv/9iko\nli0E17KY2SEEJ6H7zOzI8PVaTnFEko7BncDLzGy/sHfiCOAbgwxigXUy+oqjsFt6zexDwKsIuinW\nhmf6vPZ9LsF17f/Enj6DIAmfCtwPnOXuj+UUz6XATwhKvRsLiuHNBJdAELQub8o7lvBLfB3wxwTt\nURcTdPVdTVBQ3enuFw5o30nrU6wBbqDtGCx2fYoM4shknYx2up9fpKLK0uAnIjlT8otUlJJfpKKU\n/CIVpeQXqSglv0hFKflFKur/AZC6GWi8ghTNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcab14e5fd0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = images_and_labels_generator(32).next()\n",
    "plt.imshow(b[0][10, :, :])\n",
    "plt.title(b[1][10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2onYoulOIth2"
   },
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-uog8D60JFT_",
    "outputId": "3eb13b85-c81b-4db0-fa17-64dc1ea8ca53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yORz9xucJFhv"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5xSu_SvDJFex",
    "outputId": "15aebf43-5597-4967-ccf8-7b729cef4ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwx3NNL1JFbr"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3),padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3),padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.2)) \n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(4098, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "  \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "Nf0PFRn2JFYl",
    "outputId": "1bb67d09-3a18-4de9-8128-1e5a8d8e9e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4098)              8396802   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               1393660   \n",
      "=================================================================\n",
      "Total params: 9,896,862\n",
      "Trainable params: 9,896,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZlVX84nIte5"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zun516LaJpbz"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 250 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnWdRaDNJpkB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='top_3_accuracy', patience=15, min_delta=0.001, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n",
    "    ModelCheckpoint(\"./CNN_3_dropout.model\",monitor='top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4VL83pJJpgz"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0\n",
    "\n",
    "# you can continue from snapshot!!!\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 2\n",
    "# model = load_model(\"model_{}\".format(last_finished_epoch), \n",
    "#                    custom_objects={\"top_3_accuracy\": top_3_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6633
    },
    "colab_type": "code",
    "id": "3Eeeu5Q-JpYn",
    "outputId": "829f381d-f5db-4780-f3c6-ca08e242b702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "100/100 [==============================] - 41s 413ms/step - loss: 4.6230 - categorical_accuracy: 0.1187 - top_3_accuracy: 0.2156\n",
      "\n",
      "Epoch 00001: top_3_accuracy improved from -inf to 0.21564, saving model to ./CNN_3_dropout.model\n",
      "Epoch 2/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 3.0583 - categorical_accuracy: 0.3304 - top_3_accuracy: 0.5207\n",
      "\n",
      "Epoch 00002: top_3_accuracy improved from 0.21564 to 0.52070, saving model to ./CNN_3_dropout.model\n",
      "Epoch 3/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 2.6246 - categorical_accuracy: 0.4065 - top_3_accuracy: 0.6072\n",
      "\n",
      "Epoch 00003: top_3_accuracy improved from 0.52070 to 0.60721, saving model to ./CNN_3_dropout.model\n",
      "Epoch 4/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 2.3854 - categorical_accuracy: 0.4527 - top_3_accuracy: 0.6540\n",
      "\n",
      "Epoch 00004: top_3_accuracy improved from 0.60721 to 0.65396, saving model to ./CNN_3_dropout.model\n",
      "Epoch 5/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 2.2144 - categorical_accuracy: 0.4854 - top_3_accuracy: 0.6887\n",
      "\n",
      "Epoch 00005: top_3_accuracy improved from 0.65396 to 0.68871, saving model to ./CNN_3_dropout.model\n",
      "Epoch 6/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 2.1119 - categorical_accuracy: 0.5077 - top_3_accuracy: 0.7089\n",
      "\n",
      "Epoch 00006: top_3_accuracy improved from 0.68871 to 0.70895, saving model to ./CNN_3_dropout.model\n",
      "Epoch 7/250\n",
      "100/100 [==============================] - 36s 355ms/step - loss: 2.0433 - categorical_accuracy: 0.5228 - top_3_accuracy: 0.7223\n",
      "\n",
      "Epoch 00007: top_3_accuracy improved from 0.70895 to 0.72234, saving model to ./CNN_3_dropout.model\n",
      "Epoch 8/250\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 1.9549 - categorical_accuracy: 0.5405 - top_3_accuracy: 0.7386\n",
      "\n",
      "Epoch 00008: top_3_accuracy improved from 0.72234 to 0.73857, saving model to ./CNN_3_dropout.model\n",
      "Epoch 9/250\n",
      "100/100 [==============================] - 36s 355ms/step - loss: 1.9091 - categorical_accuracy: 0.5501 - top_3_accuracy: 0.7468\n",
      "\n",
      "Epoch 00009: top_3_accuracy improved from 0.73857 to 0.74678, saving model to ./CNN_3_dropout.model\n",
      "Epoch 10/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.8520 - categorical_accuracy: 0.5615 - top_3_accuracy: 0.7566\n",
      "\n",
      "Epoch 00010: top_3_accuracy improved from 0.74678 to 0.75658, saving model to ./CNN_3_dropout.model\n",
      "Epoch 11/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.8371 - categorical_accuracy: 0.5639 - top_3_accuracy: 0.7594\n",
      "\n",
      "Epoch 00011: top_3_accuracy improved from 0.75658 to 0.75936, saving model to ./CNN_3_dropout.model\n",
      "Epoch 12/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.7811 - categorical_accuracy: 0.5749 - top_3_accuracy: 0.7700\n",
      "\n",
      "Epoch 00012: top_3_accuracy improved from 0.75936 to 0.77004, saving model to ./CNN_3_dropout.model\n",
      "Epoch 13/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.7601 - categorical_accuracy: 0.5790 - top_3_accuracy: 0.7727\n",
      "\n",
      "Epoch 00013: top_3_accuracy improved from 0.77004 to 0.77268, saving model to ./CNN_3_dropout.model\n",
      "Epoch 14/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.7523 - categorical_accuracy: 0.5836 - top_3_accuracy: 0.7725\n",
      "\n",
      "Epoch 00014: top_3_accuracy did not improve from 0.77268\n",
      "Epoch 15/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.7013 - categorical_accuracy: 0.5947 - top_3_accuracy: 0.7817\n",
      "\n",
      "Epoch 00015: top_3_accuracy improved from 0.77268 to 0.78174, saving model to ./CNN_3_dropout.model\n",
      "Epoch 16/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.7045 - categorical_accuracy: 0.5954 - top_3_accuracy: 0.7824\n",
      "\n",
      "Epoch 00016: top_3_accuracy improved from 0.78174 to 0.78242, saving model to ./CNN_3_dropout.model\n",
      "Epoch 17/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.6859 - categorical_accuracy: 0.5975 - top_3_accuracy: 0.7859\n",
      "\n",
      "Epoch 00017: top_3_accuracy improved from 0.78242 to 0.78592, saving model to ./CNN_3_dropout.model\n",
      "Epoch 18/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.6503 - categorical_accuracy: 0.6030 - top_3_accuracy: 0.7914\n",
      "\n",
      "Epoch 00018: top_3_accuracy improved from 0.78592 to 0.79141, saving model to ./CNN_3_dropout.model\n",
      "Epoch 19/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.6395 - categorical_accuracy: 0.6063 - top_3_accuracy: 0.7947\n",
      "\n",
      "Epoch 00019: top_3_accuracy improved from 0.79141 to 0.79475, saving model to ./CNN_3_dropout.model\n",
      "Epoch 20/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.6303 - categorical_accuracy: 0.6087 - top_3_accuracy: 0.7949\n",
      "\n",
      "Epoch 00020: top_3_accuracy improved from 0.79475 to 0.79486, saving model to ./CNN_3_dropout.model\n",
      "Epoch 21/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.6012 - categorical_accuracy: 0.6137 - top_3_accuracy: 0.8006\n",
      "\n",
      "Epoch 00021: top_3_accuracy improved from 0.79486 to 0.80057, saving model to ./CNN_3_dropout.model\n",
      "Epoch 22/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.6005 - categorical_accuracy: 0.6149 - top_3_accuracy: 0.8004\n",
      "\n",
      "Epoch 00022: top_3_accuracy did not improve from 0.80057\n",
      "Epoch 23/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.5847 - categorical_accuracy: 0.6201 - top_3_accuracy: 0.8008\n",
      "\n",
      "Epoch 00023: top_3_accuracy improved from 0.80057 to 0.80076, saving model to ./CNN_3_dropout.model\n",
      "Epoch 24/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.5564 - categorical_accuracy: 0.6251 - top_3_accuracy: 0.8077\n",
      "\n",
      "Epoch 00024: top_3_accuracy improved from 0.80076 to 0.80770, saving model to ./CNN_3_dropout.model\n",
      "Epoch 25/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.5516 - categorical_accuracy: 0.6233 - top_3_accuracy: 0.8104\n",
      "\n",
      "Epoch 00025: top_3_accuracy improved from 0.80770 to 0.81045, saving model to ./CNN_3_dropout.model\n",
      "Epoch 26/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.5368 - categorical_accuracy: 0.6311 - top_3_accuracy: 0.8109\n",
      "\n",
      "Epoch 00026: top_3_accuracy improved from 0.81045 to 0.81090, saving model to ./CNN_3_dropout.model\n",
      "Epoch 27/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.5303 - categorical_accuracy: 0.6290 - top_3_accuracy: 0.8125\n",
      "\n",
      "Epoch 00027: top_3_accuracy improved from 0.81090 to 0.81252, saving model to ./CNN_3_dropout.model\n",
      "Epoch 28/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.5326 - categorical_accuracy: 0.6278 - top_3_accuracy: 0.8108\n",
      "\n",
      "Epoch 00028: top_3_accuracy did not improve from 0.81252\n",
      "Epoch 29/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.5073 - categorical_accuracy: 0.6352 - top_3_accuracy: 0.8143\n",
      "\n",
      "Epoch 00029: top_3_accuracy improved from 0.81252 to 0.81430, saving model to ./CNN_3_dropout.model\n",
      "Epoch 30/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.5113 - categorical_accuracy: 0.6342 - top_3_accuracy: 0.8136\n",
      "\n",
      "Epoch 00030: top_3_accuracy did not improve from 0.81430\n",
      "Epoch 31/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.4808 - categorical_accuracy: 0.6382 - top_3_accuracy: 0.8194\n",
      "\n",
      "Epoch 00031: top_3_accuracy improved from 0.81430 to 0.81937, saving model to ./CNN_3_dropout.model\n",
      "Epoch 32/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.4778 - categorical_accuracy: 0.6423 - top_3_accuracy: 0.8215\n",
      "\n",
      "Epoch 00032: top_3_accuracy improved from 0.81937 to 0.82152, saving model to ./CNN_3_dropout.model\n",
      "Epoch 33/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.4745 - categorical_accuracy: 0.6431 - top_3_accuracy: 0.8210\n",
      "\n",
      "Epoch 00033: top_3_accuracy did not improve from 0.82152\n",
      "Epoch 34/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.4702 - categorical_accuracy: 0.6449 - top_3_accuracy: 0.8220\n",
      "\n",
      "Epoch 00034: top_3_accuracy improved from 0.82152 to 0.82203, saving model to ./CNN_3_dropout.model\n",
      "Epoch 35/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.4483 - categorical_accuracy: 0.6461 - top_3_accuracy: 0.8248\n",
      "\n",
      "Epoch 00035: top_3_accuracy improved from 0.82203 to 0.82477, saving model to ./CNN_3_dropout.model\n",
      "Epoch 36/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.4584 - categorical_accuracy: 0.6463 - top_3_accuracy: 0.8230\n",
      "\n",
      "Epoch 00036: top_3_accuracy did not improve from 0.82477\n",
      "Epoch 37/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.4554 - categorical_accuracy: 0.6468 - top_3_accuracy: 0.8254\n",
      "\n",
      "Epoch 00037: top_3_accuracy improved from 0.82477 to 0.82545, saving model to ./CNN_3_dropout.model\n",
      "Epoch 38/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.4475 - categorical_accuracy: 0.6478 - top_3_accuracy: 0.8257\n",
      "\n",
      "Epoch 00038: top_3_accuracy improved from 0.82545 to 0.82566, saving model to ./CNN_3_dropout.model\n",
      "Epoch 39/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.4635 - categorical_accuracy: 0.6432 - top_3_accuracy: 0.8232\n",
      "\n",
      "Epoch 00039: top_3_accuracy did not improve from 0.82566\n",
      "Epoch 40/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.4305 - categorical_accuracy: 0.6496 - top_3_accuracy: 0.8277\n",
      "\n",
      "Epoch 00040: top_3_accuracy improved from 0.82566 to 0.82773, saving model to ./CNN_3_dropout.model\n",
      "Epoch 41/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.4010 - categorical_accuracy: 0.6596 - top_3_accuracy: 0.8318\n",
      "\n",
      "Epoch 00041: top_3_accuracy improved from 0.82773 to 0.83184, saving model to ./CNN_3_dropout.model\n",
      "Epoch 42/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.3822 - categorical_accuracy: 0.6637 - top_3_accuracy: 0.8340\n",
      "\n",
      "Epoch 00042: top_3_accuracy improved from 0.83184 to 0.83400, saving model to ./CNN_3_dropout.model\n",
      "Epoch 43/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.3698 - categorical_accuracy: 0.6651 - top_3_accuracy: 0.8369\n",
      "\n",
      "Epoch 00043: top_3_accuracy improved from 0.83400 to 0.83686, saving model to ./CNN_3_dropout.model\n",
      "Epoch 44/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.3647 - categorical_accuracy: 0.6689 - top_3_accuracy: 0.8385\n",
      "\n",
      "Epoch 00044: top_3_accuracy improved from 0.83686 to 0.83846, saving model to ./CNN_3_dropout.model\n",
      "Epoch 45/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.3793 - categorical_accuracy: 0.6678 - top_3_accuracy: 0.8368\n",
      "\n",
      "Epoch 00045: top_3_accuracy did not improve from 0.83846\n",
      "Epoch 46/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.3630 - categorical_accuracy: 0.6698 - top_3_accuracy: 0.8409\n",
      "\n",
      "Epoch 00046: top_3_accuracy improved from 0.83846 to 0.84086, saving model to ./CNN_3_dropout.model\n",
      "Epoch 47/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.3553 - categorical_accuracy: 0.6686 - top_3_accuracy: 0.8407\n",
      "\n",
      "Epoch 00047: top_3_accuracy did not improve from 0.84086\n",
      "Epoch 48/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.3430 - categorical_accuracy: 0.6720 - top_3_accuracy: 0.8417\n",
      "\n",
      "Epoch 00048: top_3_accuracy improved from 0.84086 to 0.84174, saving model to ./CNN_3_dropout.model\n",
      "Epoch 49/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.3180 - categorical_accuracy: 0.6773 - top_3_accuracy: 0.8459\n",
      "\n",
      "Epoch 00049: top_3_accuracy improved from 0.84174 to 0.84592, saving model to ./CNN_3_dropout.model\n",
      "Epoch 50/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.3225 - categorical_accuracy: 0.6786 - top_3_accuracy: 0.8452\n",
      "\n",
      "Epoch 00050: top_3_accuracy did not improve from 0.84592\n",
      "Epoch 51/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.3090 - categorical_accuracy: 0.6800 - top_3_accuracy: 0.8486\n",
      "\n",
      "Epoch 00051: top_3_accuracy improved from 0.84592 to 0.84863, saving model to ./CNN_3_dropout.model\n",
      "Epoch 52/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.3074 - categorical_accuracy: 0.6808 - top_3_accuracy: 0.8477\n",
      "\n",
      "Epoch 00052: top_3_accuracy did not improve from 0.84863\n",
      "Epoch 53/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.3083 - categorical_accuracy: 0.6803 - top_3_accuracy: 0.8464\n",
      "\n",
      "Epoch 00053: top_3_accuracy did not improve from 0.84863\n",
      "Epoch 54/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2808 - categorical_accuracy: 0.6859 - top_3_accuracy: 0.8504\n",
      "\n",
      "Epoch 00054: top_3_accuracy improved from 0.84863 to 0.85035, saving model to ./CNN_3_dropout.model\n",
      "Epoch 55/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2955 - categorical_accuracy: 0.6849 - top_3_accuracy: 0.8490\n",
      "\n",
      "Epoch 00055: top_3_accuracy did not improve from 0.85035\n",
      "Epoch 56/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2868 - categorical_accuracy: 0.6852 - top_3_accuracy: 0.8517\n",
      "\n",
      "Epoch 00056: top_3_accuracy improved from 0.85035 to 0.85166, saving model to ./CNN_3_dropout.model\n",
      "Epoch 57/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2837 - categorical_accuracy: 0.6881 - top_3_accuracy: 0.8512\n",
      "\n",
      "Epoch 00057: top_3_accuracy did not improve from 0.85166\n",
      "Epoch 58/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2751 - categorical_accuracy: 0.6906 - top_3_accuracy: 0.8518\n",
      "\n",
      "Epoch 00058: top_3_accuracy improved from 0.85166 to 0.85184, saving model to ./CNN_3_dropout.model\n",
      "Epoch 59/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2845 - categorical_accuracy: 0.6866 - top_3_accuracy: 0.8502\n",
      "\n",
      "Epoch 00059: top_3_accuracy did not improve from 0.85184\n",
      "Epoch 60/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2798 - categorical_accuracy: 0.6876 - top_3_accuracy: 0.8511\n",
      "\n",
      "Epoch 00060: top_3_accuracy did not improve from 0.85184\n",
      "Epoch 61/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2692 - categorical_accuracy: 0.6887 - top_3_accuracy: 0.8531\n",
      "\n",
      "Epoch 00061: top_3_accuracy improved from 0.85184 to 0.85309, saving model to ./CNN_3_dropout.model\n",
      "Epoch 62/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2716 - categorical_accuracy: 0.6891 - top_3_accuracy: 0.8524\n",
      "\n",
      "Epoch 00062: top_3_accuracy did not improve from 0.85309\n",
      "Epoch 63/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2664 - categorical_accuracy: 0.6905 - top_3_accuracy: 0.8532\n",
      "\n",
      "Epoch 00063: top_3_accuracy improved from 0.85309 to 0.85318, saving model to ./CNN_3_dropout.model\n",
      "Epoch 64/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2709 - categorical_accuracy: 0.6904 - top_3_accuracy: 0.8526\n",
      "\n",
      "Epoch 00064: top_3_accuracy did not improve from 0.85318\n",
      "Epoch 65/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2692 - categorical_accuracy: 0.6918 - top_3_accuracy: 0.8512\n",
      "\n",
      "Epoch 00065: top_3_accuracy did not improve from 0.85318\n",
      "Epoch 66/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2695 - categorical_accuracy: 0.6907 - top_3_accuracy: 0.8527\n",
      "\n",
      "Epoch 00066: top_3_accuracy did not improve from 0.85318\n",
      "Epoch 67/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2762 - categorical_accuracy: 0.6913 - top_3_accuracy: 0.8517\n",
      "\n",
      "Epoch 00067: top_3_accuracy did not improve from 0.85318\n",
      "Epoch 68/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2674 - categorical_accuracy: 0.6919 - top_3_accuracy: 0.8539\n",
      "\n",
      "Epoch 00068: top_3_accuracy improved from 0.85318 to 0.85393, saving model to ./CNN_3_dropout.model\n",
      "Epoch 69/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.2597 - categorical_accuracy: 0.6919 - top_3_accuracy: 0.8533\n",
      "\n",
      "Epoch 00069: top_3_accuracy did not improve from 0.85393\n",
      "Epoch 70/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2631 - categorical_accuracy: 0.6931 - top_3_accuracy: 0.8543\n",
      "\n",
      "Epoch 00070: top_3_accuracy improved from 0.85393 to 0.85432, saving model to ./CNN_3_dropout.model\n",
      "Epoch 71/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2511 - categorical_accuracy: 0.6965 - top_3_accuracy: 0.8557\n",
      "\n",
      "Epoch 00071: top_3_accuracy improved from 0.85432 to 0.85574, saving model to ./CNN_3_dropout.model\n",
      "Epoch 72/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.2558 - categorical_accuracy: 0.6926 - top_3_accuracy: 0.8549\n",
      "\n",
      "Epoch 00072: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 73/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2736 - categorical_accuracy: 0.6891 - top_3_accuracy: 0.8511\n",
      "\n",
      "Epoch 00073: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 74/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2739 - categorical_accuracy: 0.6913 - top_3_accuracy: 0.8522\n",
      "\n",
      "Epoch 00074: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 75/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2655 - categorical_accuracy: 0.6900 - top_3_accuracy: 0.8533\n",
      "\n",
      "Epoch 00075: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 76/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.2755 - categorical_accuracy: 0.6923 - top_3_accuracy: 0.8520\n",
      "\n",
      "Epoch 00076: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 77/250\n",
      "100/100 [==============================] - 36s 355ms/step - loss: 1.2503 - categorical_accuracy: 0.6937 - top_3_accuracy: 0.8551\n",
      "\n",
      "Epoch 00077: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 78/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2587 - categorical_accuracy: 0.6955 - top_3_accuracy: 0.8543\n",
      "\n",
      "Epoch 00078: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 79/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.2603 - categorical_accuracy: 0.6938 - top_3_accuracy: 0.8533\n",
      "\n",
      "Epoch 00079: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 80/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.2501 - categorical_accuracy: 0.6940 - top_3_accuracy: 0.8550\n",
      "\n",
      "Epoch 00080: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 81/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.2607 - categorical_accuracy: 0.6926 - top_3_accuracy: 0.8546\n",
      "\n",
      "Epoch 00081: top_3_accuracy did not improve from 0.85574\n",
      "Epoch 82/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2297 - categorical_accuracy: 0.6961 - top_3_accuracy: 0.8577\n",
      "\n",
      "Epoch 00082: top_3_accuracy improved from 0.85574 to 0.85768, saving model to ./CNN_3_dropout.model\n",
      "Epoch 83/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2554 - categorical_accuracy: 0.6942 - top_3_accuracy: 0.8545\n",
      "\n",
      "Epoch 00083: top_3_accuracy did not improve from 0.85768\n",
      "Epoch 84/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.2394 - categorical_accuracy: 0.6952 - top_3_accuracy: 0.8558\n",
      "\n",
      "Epoch 00084: top_3_accuracy did not improve from 0.85768\n",
      "Epoch 85/250\n",
      "100/100 [==============================] - 39s 390ms/step - loss: 1.2555 - categorical_accuracy: 0.6966 - top_3_accuracy: 0.8544\n",
      "\n",
      "Epoch 00085: top_3_accuracy did not improve from 0.85768\n",
      "Epoch 86/250\n",
      "100/100 [==============================] - 36s 362ms/step - loss: 1.2486 - categorical_accuracy: 0.6982 - top_3_accuracy: 0.8568\n",
      "\n",
      "Epoch 00086: top_3_accuracy did not improve from 0.85768\n",
      "Epoch 87/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2713 - categorical_accuracy: 0.6909 - top_3_accuracy: 0.8519\n",
      "\n",
      "Epoch 00087: top_3_accuracy did not improve from 0.85768\n",
      "Epoch 88/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2511 - categorical_accuracy: 0.6951 - top_3_accuracy: 0.8559\n",
      "\n",
      "Epoch 00088: top_3_accuracy did not improve from 0.85768\n",
      "Epoch 89/250\n",
      "100/100 [==============================] - 36s 360ms/step - loss: 1.2581 - categorical_accuracy: 0.6922 - top_3_accuracy: 0.8552\n",
      "\n",
      "Epoch 00089: top_3_accuracy did not improve from 0.85768\n",
      "Epoch 90/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2364 - categorical_accuracy: 0.6954 - top_3_accuracy: 0.8583\n",
      "\n",
      "Epoch 00090: top_3_accuracy improved from 0.85768 to 0.85830, saving model to ./CNN_3_dropout.model\n",
      "Epoch 91/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2558 - categorical_accuracy: 0.6929 - top_3_accuracy: 0.8551\n",
      "\n",
      "Epoch 00091: top_3_accuracy did not improve from 0.85830\n",
      "Epoch 92/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2482 - categorical_accuracy: 0.6942 - top_3_accuracy: 0.8561\n",
      "\n",
      "Epoch 00092: top_3_accuracy did not improve from 0.85830\n",
      "Epoch 93/250\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2557 - categorical_accuracy: 0.6951 - top_3_accuracy: 0.8549\n",
      "\n",
      "Epoch 00093: top_3_accuracy did not improve from 0.85830\n",
      "Epoch 94/250\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.2437 - categorical_accuracy: 0.6988 - top_3_accuracy: 0.8564\n",
      "\n",
      "Epoch 00094: top_3_accuracy did not improve from 0.85830\n",
      "Epoch 95/250\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.2482 - categorical_accuracy: 0.6934 - top_3_accuracy: 0.8566\n",
      "\n",
      "Epoch 00095: top_3_accuracy did not improve from 0.85830\n",
      "Epoch 96/250\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2362 - categorical_accuracy: 0.7002 - top_3_accuracy: 0.8577\n",
      "\n",
      "Epoch 00096: top_3_accuracy did not improve from 0.85830\n",
      "Epoch 97/250\n",
      "100/100 [==============================] - 35s 355ms/step - loss: 1.2564 - categorical_accuracy: 0.6950 - top_3_accuracy: 0.8559\n",
      "\n",
      "Epoch 00097: top_3_accuracy did not improve from 0.85830\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "CNN_4 = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "b80pQfVzj7i3",
    "outputId": "cb37ee21-2443-4045-edee-1dffbfa2b42d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAFMCAYAAADiN0l8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElSHRiqJEmS6sBQJUmSVAf/P/kWQvFGWfa9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca6b601990>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.legend(loc='best')\n",
    "plt.title('MAP@3')\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(CNN_4.history['top_3_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qd8GDm5Bll_9"
   },
   "source": [
    "Удалось получить 0.8 на kaggle  ссылка на скриншот https://drive.google.com/file/d/1WAmjYbXIDr03-qICirBZOjbQbPI0_z9B/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9bpHOHVqJgpf"
   },
   "source": [
    "**Вывод:**  Параметров обучалось меньше, чем на прошлом этапе, но из-за большого количества сверточных слоев, качество значительно улучшилось. \n",
    "\n",
    "**Про значения DropOut:** На последнем сверточном слое 0.2, на полносвязном 0.25. Так как на сверточных слоях следует использовать меньше, чтобы не потерять нужные фильтры при выключении нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usUID8Fwojf7"
   },
   "source": [
    "#Эксперимент №5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3c5FOJSFKHxJ"
   },
   "source": [
    "Цель проведения экспериментов 5 и 6: установить лучшую фукцию активации для этих данных. В эксперименте 4 удалось получить хорошее качества с активацией **relu**. В эксперименте 5 будет использоваться активация **elu** на той же модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EfXWwt5YopEX",
    "outputId": "66b041cb-2d1f-4047-95f3-24d7f3dc797a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdSsUZTgopTJ"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LEcRrnZZo0hf"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27gKMJ5io0wJ"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKVvDl8lo0-7"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j58ZNzoBo06a"
   },
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7GoTxlBvo02X",
    "outputId": "b6f1fa6f-f314-405c-bd5d-714bae46c466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYqcrtQ9o0r2"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "thO0ymNDo0nu",
    "outputId": "1cbfd597-fcf1-4049-8caa-55ce5636bdc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3C6MyNopopZC"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3),padding='same', activation='elu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same', activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3),padding='same', activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(4098, activation='elu'))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "2zFlloR4opgW",
    "outputId": "c92d2cb4-c010-49c9-ebae-d3a0d3fca41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4098)              8396802   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               1393660   \n",
      "=================================================================\n",
      "Total params: 9,896,862\n",
      "Trainable params: 9,896,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyqvMyc9opqQ"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9j1CLi12opy6"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 250 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKN__gifopmd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='top_3_accuracy', patience=15, min_delta=0.001, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n",
    "    ModelCheckpoint(\"./CNN_3_dropout.model\",monitor='top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzo-5gy2opPS"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0\n",
    "\n",
    "# you can continue from snapshot!!!\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 2\n",
    "# model = load_model(\"model_{}\".format(last_finished_epoch), \n",
    "#                    custom_objects={\"top_3_accuracy\": top_3_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6701
    },
    "colab_type": "code",
    "id": "UwjqTWdPopLU",
    "outputId": "acac2e7a-b36d-4965-918a-79ff54578f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "100/100 [==============================] - 38s 382ms/step - loss: 4.2604 - categorical_accuracy: 0.1651 - top_3_accuracy: 0.2894\n",
      "\n",
      "Epoch 00001: top_3_accuracy improved from -inf to 0.28936, saving model to ./CNN_3_dropout.model\n",
      "Epoch 2/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 3.1689 - categorical_accuracy: 0.3297 - top_3_accuracy: 0.5092\n",
      "\n",
      "Epoch 00002: top_3_accuracy improved from 0.28936 to 0.50924, saving model to ./CNN_3_dropout.model\n",
      "Epoch 3/250\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 2.8889 - categorical_accuracy: 0.3747 - top_3_accuracy: 0.5651\n",
      "\n",
      "Epoch 00003: top_3_accuracy improved from 0.50924 to 0.56508, saving model to ./CNN_3_dropout.model\n",
      "Epoch 4/250\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 2.7296 - categorical_accuracy: 0.4067 - top_3_accuracy: 0.5968\n",
      "\n",
      "Epoch 00004: top_3_accuracy improved from 0.56508 to 0.59678, saving model to ./CNN_3_dropout.model\n",
      "Epoch 5/250\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 2.5796 - categorical_accuracy: 0.4336 - top_3_accuracy: 0.6248\n",
      "\n",
      "Epoch 00005: top_3_accuracy improved from 0.59678 to 0.62482, saving model to ./CNN_3_dropout.model\n",
      "Epoch 6/250\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 2.5002 - categorical_accuracy: 0.4484 - top_3_accuracy: 0.6389\n",
      "\n",
      "Epoch 00006: top_3_accuracy improved from 0.62482 to 0.63889, saving model to ./CNN_3_dropout.model\n",
      "Epoch 7/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 2.4319 - categorical_accuracy: 0.4617 - top_3_accuracy: 0.6557\n",
      "\n",
      "Epoch 00007: top_3_accuracy improved from 0.63889 to 0.65568, saving model to ./CNN_3_dropout.model\n",
      "Epoch 8/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 2.3676 - categorical_accuracy: 0.4728 - top_3_accuracy: 0.6674\n",
      "\n",
      "Epoch 00008: top_3_accuracy improved from 0.65568 to 0.66738, saving model to ./CNN_3_dropout.model\n",
      "Epoch 9/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 2.3026 - categorical_accuracy: 0.4853 - top_3_accuracy: 0.6775\n",
      "\n",
      "Epoch 00009: top_3_accuracy improved from 0.66738 to 0.67754, saving model to ./CNN_3_dropout.model\n",
      "Epoch 10/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 2.2965 - categorical_accuracy: 0.4876 - top_3_accuracy: 0.6800\n",
      "\n",
      "Epoch 00010: top_3_accuracy improved from 0.67754 to 0.68004, saving model to ./CNN_3_dropout.model\n",
      "Epoch 11/250\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 2.2528 - categorical_accuracy: 0.4998 - top_3_accuracy: 0.6886\n",
      "\n",
      "Epoch 00011: top_3_accuracy improved from 0.68004 to 0.68855, saving model to ./CNN_3_dropout.model\n",
      "Epoch 12/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 2.2104 - categorical_accuracy: 0.5034 - top_3_accuracy: 0.6964\n",
      "\n",
      "Epoch 00012: top_3_accuracy improved from 0.68855 to 0.69641, saving model to ./CNN_3_dropout.model\n",
      "Epoch 13/250\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 2.2038 - categorical_accuracy: 0.5032 - top_3_accuracy: 0.6973\n",
      "\n",
      "Epoch 00013: top_3_accuracy improved from 0.69641 to 0.69734, saving model to ./CNN_3_dropout.model\n",
      "Epoch 14/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 2.1759 - categorical_accuracy: 0.5091 - top_3_accuracy: 0.7024\n",
      "\n",
      "Epoch 00014: top_3_accuracy improved from 0.69734 to 0.70240, saving model to ./CNN_3_dropout.model\n",
      "Epoch 15/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 2.1517 - categorical_accuracy: 0.5170 - top_3_accuracy: 0.7057\n",
      "\n",
      "Epoch 00015: top_3_accuracy improved from 0.70240 to 0.70566, saving model to ./CNN_3_dropout.model\n",
      "Epoch 16/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 2.1215 - categorical_accuracy: 0.5212 - top_3_accuracy: 0.7108\n",
      "\n",
      "Epoch 00016: top_3_accuracy improved from 0.70566 to 0.71076, saving model to ./CNN_3_dropout.model\n",
      "Epoch 17/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 2.1184 - categorical_accuracy: 0.5219 - top_3_accuracy: 0.7150\n",
      "\n",
      "Epoch 00017: top_3_accuracy improved from 0.71076 to 0.71498, saving model to ./CNN_3_dropout.model\n",
      "Epoch 18/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 2.0713 - categorical_accuracy: 0.5302 - top_3_accuracy: 0.7202\n",
      "\n",
      "Epoch 00018: top_3_accuracy improved from 0.71498 to 0.72018, saving model to ./CNN_3_dropout.model\n",
      "Epoch 19/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 2.0617 - categorical_accuracy: 0.5309 - top_3_accuracy: 0.7212\n",
      "\n",
      "Epoch 00019: top_3_accuracy improved from 0.72018 to 0.72115, saving model to ./CNN_3_dropout.model\n",
      "Epoch 20/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 2.0464 - categorical_accuracy: 0.5352 - top_3_accuracy: 0.7257\n",
      "\n",
      "Epoch 00020: top_3_accuracy improved from 0.72115 to 0.72572, saving model to ./CNN_3_dropout.model\n",
      "Epoch 21/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 2.0238 - categorical_accuracy: 0.5391 - top_3_accuracy: 0.7280\n",
      "\n",
      "Epoch 00021: top_3_accuracy improved from 0.72572 to 0.72797, saving model to ./CNN_3_dropout.model\n",
      "Epoch 22/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 2.0233 - categorical_accuracy: 0.5381 - top_3_accuracy: 0.7301\n",
      "\n",
      "Epoch 00022: top_3_accuracy improved from 0.72797 to 0.73008, saving model to ./CNN_3_dropout.model\n",
      "Epoch 23/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 2.0249 - categorical_accuracy: 0.5405 - top_3_accuracy: 0.7304\n",
      "\n",
      "Epoch 00023: top_3_accuracy improved from 0.73008 to 0.73043, saving model to ./CNN_3_dropout.model\n",
      "Epoch 24/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.9822 - categorical_accuracy: 0.5499 - top_3_accuracy: 0.7364\n",
      "\n",
      "Epoch 00024: top_3_accuracy improved from 0.73043 to 0.73641, saving model to ./CNN_3_dropout.model\n",
      "Epoch 25/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.9745 - categorical_accuracy: 0.5466 - top_3_accuracy: 0.7388\n",
      "\n",
      "Epoch 00025: top_3_accuracy improved from 0.73641 to 0.73885, saving model to ./CNN_3_dropout.model\n",
      "Epoch 26/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.9528 - categorical_accuracy: 0.5555 - top_3_accuracy: 0.7410\n",
      "\n",
      "Epoch 00026: top_3_accuracy improved from 0.73885 to 0.74104, saving model to ./CNN_3_dropout.model\n",
      "Epoch 27/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.9535 - categorical_accuracy: 0.5500 - top_3_accuracy: 0.7416\n",
      "\n",
      "Epoch 00027: top_3_accuracy improved from 0.74104 to 0.74162, saving model to ./CNN_3_dropout.model\n",
      "Epoch 28/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.9596 - categorical_accuracy: 0.5518 - top_3_accuracy: 0.7380\n",
      "\n",
      "Epoch 00028: top_3_accuracy did not improve from 0.74162\n",
      "Epoch 29/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.9453 - categorical_accuracy: 0.5531 - top_3_accuracy: 0.7433\n",
      "\n",
      "Epoch 00029: top_3_accuracy improved from 0.74162 to 0.74330, saving model to ./CNN_3_dropout.model\n",
      "Epoch 30/250\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 1.9186 - categorical_accuracy: 0.5579 - top_3_accuracy: 0.7463\n",
      "\n",
      "Epoch 00030: top_3_accuracy improved from 0.74330 to 0.74627, saving model to ./CNN_3_dropout.model\n",
      "Epoch 31/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.9198 - categorical_accuracy: 0.5596 - top_3_accuracy: 0.7478\n",
      "\n",
      "Epoch 00031: top_3_accuracy improved from 0.74627 to 0.74777, saving model to ./CNN_3_dropout.model\n",
      "Epoch 32/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.8890 - categorical_accuracy: 0.5688 - top_3_accuracy: 0.7537\n",
      "\n",
      "Epoch 00032: top_3_accuracy improved from 0.74777 to 0.75369, saving model to ./CNN_3_dropout.model\n",
      "Epoch 33/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.9037 - categorical_accuracy: 0.5632 - top_3_accuracy: 0.7485\n",
      "\n",
      "Epoch 00033: top_3_accuracy did not improve from 0.75369\n",
      "Epoch 34/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.8932 - categorical_accuracy: 0.5633 - top_3_accuracy: 0.7529\n",
      "\n",
      "Epoch 00034: top_3_accuracy did not improve from 0.75369\n",
      "Epoch 35/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.8806 - categorical_accuracy: 0.5684 - top_3_accuracy: 0.7547\n",
      "\n",
      "Epoch 00035: top_3_accuracy improved from 0.75369 to 0.75475, saving model to ./CNN_3_dropout.model\n",
      "Epoch 36/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.8869 - categorical_accuracy: 0.5646 - top_3_accuracy: 0.7540\n",
      "\n",
      "Epoch 00036: top_3_accuracy did not improve from 0.75475\n",
      "Epoch 37/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.8670 - categorical_accuracy: 0.5708 - top_3_accuracy: 0.7568\n",
      "\n",
      "Epoch 00037: top_3_accuracy improved from 0.75475 to 0.75680, saving model to ./CNN_3_dropout.model\n",
      "Epoch 38/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.8227 - categorical_accuracy: 0.5794 - top_3_accuracy: 0.7650\n",
      "\n",
      "Epoch 00038: top_3_accuracy improved from 0.75680 to 0.76496, saving model to ./CNN_3_dropout.model\n",
      "Epoch 39/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.8051 - categorical_accuracy: 0.5847 - top_3_accuracy: 0.7686\n",
      "\n",
      "Epoch 00039: top_3_accuracy improved from 0.76496 to 0.76859, saving model to ./CNN_3_dropout.model\n",
      "Epoch 40/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.7853 - categorical_accuracy: 0.5873 - top_3_accuracy: 0.7704\n",
      "\n",
      "Epoch 00040: top_3_accuracy improved from 0.76859 to 0.77041, saving model to ./CNN_3_dropout.model\n",
      "Epoch 41/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.7673 - categorical_accuracy: 0.5936 - top_3_accuracy: 0.7753\n",
      "\n",
      "Epoch 00041: top_3_accuracy improved from 0.77041 to 0.77525, saving model to ./CNN_3_dropout.model\n",
      "Epoch 42/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.7844 - categorical_accuracy: 0.5917 - top_3_accuracy: 0.7686\n",
      "\n",
      "Epoch 00042: top_3_accuracy did not improve from 0.77525\n",
      "Epoch 43/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.7678 - categorical_accuracy: 0.5921 - top_3_accuracy: 0.7740\n",
      "\n",
      "Epoch 00043: top_3_accuracy did not improve from 0.77525\n",
      "Epoch 44/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.7438 - categorical_accuracy: 0.5965 - top_3_accuracy: 0.7801\n",
      "\n",
      "Epoch 00044: top_3_accuracy improved from 0.77525 to 0.78008, saving model to ./CNN_3_dropout.model\n",
      "Epoch 45/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.7681 - categorical_accuracy: 0.5945 - top_3_accuracy: 0.7738\n",
      "\n",
      "Epoch 00045: top_3_accuracy did not improve from 0.78008\n",
      "Epoch 46/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.7386 - categorical_accuracy: 0.5968 - top_3_accuracy: 0.7790\n",
      "\n",
      "Epoch 00046: top_3_accuracy did not improve from 0.78008\n",
      "Epoch 47/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.7413 - categorical_accuracy: 0.5947 - top_3_accuracy: 0.7775\n",
      "\n",
      "Epoch 00047: top_3_accuracy did not improve from 0.78008\n",
      "Epoch 48/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.7116 - categorical_accuracy: 0.6022 - top_3_accuracy: 0.7821\n",
      "\n",
      "Epoch 00048: top_3_accuracy improved from 0.78008 to 0.78205, saving model to ./CNN_3_dropout.model\n",
      "Epoch 49/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.7290 - categorical_accuracy: 0.5964 - top_3_accuracy: 0.7796\n",
      "\n",
      "Epoch 00049: top_3_accuracy did not improve from 0.78205\n",
      "Epoch 50/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.6787 - categorical_accuracy: 0.6109 - top_3_accuracy: 0.7893\n",
      "\n",
      "Epoch 00050: top_3_accuracy improved from 0.78205 to 0.78930, saving model to ./CNN_3_dropout.model\n",
      "Epoch 51/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.6802 - categorical_accuracy: 0.6097 - top_3_accuracy: 0.7899\n",
      "\n",
      "Epoch 00051: top_3_accuracy improved from 0.78930 to 0.78992, saving model to ./CNN_3_dropout.model\n",
      "Epoch 52/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.6626 - categorical_accuracy: 0.6127 - top_3_accuracy: 0.7925\n",
      "\n",
      "Epoch 00052: top_3_accuracy improved from 0.78992 to 0.79246, saving model to ./CNN_3_dropout.model\n",
      "Epoch 53/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.6528 - categorical_accuracy: 0.6140 - top_3_accuracy: 0.7921\n",
      "\n",
      "Epoch 00053: top_3_accuracy did not improve from 0.79246\n",
      "Epoch 54/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.6572 - categorical_accuracy: 0.6151 - top_3_accuracy: 0.7936\n",
      "\n",
      "Epoch 00054: top_3_accuracy improved from 0.79246 to 0.79361, saving model to ./CNN_3_dropout.model\n",
      "Epoch 55/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.6404 - categorical_accuracy: 0.6157 - top_3_accuracy: 0.7958\n",
      "\n",
      "Epoch 00055: top_3_accuracy improved from 0.79361 to 0.79580, saving model to ./CNN_3_dropout.model\n",
      "Epoch 56/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.6415 - categorical_accuracy: 0.6193 - top_3_accuracy: 0.7951\n",
      "\n",
      "Epoch 00056: top_3_accuracy did not improve from 0.79580\n",
      "Epoch 57/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.6482 - categorical_accuracy: 0.6171 - top_3_accuracy: 0.7928\n",
      "\n",
      "Epoch 00057: top_3_accuracy did not improve from 0.79580\n",
      "Epoch 58/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.6351 - categorical_accuracy: 0.6170 - top_3_accuracy: 0.7945\n",
      "\n",
      "Epoch 00058: top_3_accuracy did not improve from 0.79580\n",
      "Epoch 59/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.6216 - categorical_accuracy: 0.6198 - top_3_accuracy: 0.7979\n",
      "\n",
      "Epoch 00059: top_3_accuracy improved from 0.79580 to 0.79785, saving model to ./CNN_3_dropout.model\n",
      "Epoch 60/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.6412 - categorical_accuracy: 0.6179 - top_3_accuracy: 0.7944\n",
      "\n",
      "Epoch 00060: top_3_accuracy did not improve from 0.79785\n",
      "Epoch 61/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.6026 - categorical_accuracy: 0.6246 - top_3_accuracy: 0.8012\n",
      "\n",
      "Epoch 00061: top_3_accuracy improved from 0.79785 to 0.80123, saving model to ./CNN_3_dropout.model\n",
      "Epoch 62/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.6010 - categorical_accuracy: 0.6245 - top_3_accuracy: 0.8015\n",
      "\n",
      "Epoch 00062: top_3_accuracy improved from 0.80123 to 0.80146, saving model to ./CNN_3_dropout.model\n",
      "Epoch 63/250\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 1.5911 - categorical_accuracy: 0.6270 - top_3_accuracy: 0.8029\n",
      "\n",
      "Epoch 00063: top_3_accuracy improved from 0.80146 to 0.80291, saving model to ./CNN_3_dropout.model\n",
      "Epoch 64/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5961 - categorical_accuracy: 0.6257 - top_3_accuracy: 0.8021\n",
      "\n",
      "Epoch 00064: top_3_accuracy did not improve from 0.80291\n",
      "Epoch 65/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.6098 - categorical_accuracy: 0.6274 - top_3_accuracy: 0.7999\n",
      "\n",
      "Epoch 00065: top_3_accuracy did not improve from 0.80291\n",
      "Epoch 66/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5984 - categorical_accuracy: 0.6292 - top_3_accuracy: 0.8024\n",
      "\n",
      "Epoch 00066: top_3_accuracy did not improve from 0.80291\n",
      "Epoch 67/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5895 - categorical_accuracy: 0.6287 - top_3_accuracy: 0.8017\n",
      "\n",
      "Epoch 00067: top_3_accuracy did not improve from 0.80291\n",
      "Epoch 68/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.6011 - categorical_accuracy: 0.6273 - top_3_accuracy: 0.8020\n",
      "\n",
      "Epoch 00068: top_3_accuracy did not improve from 0.80291\n",
      "Epoch 69/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5638 - categorical_accuracy: 0.6332 - top_3_accuracy: 0.8066\n",
      "\n",
      "Epoch 00069: top_3_accuracy improved from 0.80291 to 0.80664, saving model to ./CNN_3_dropout.model\n",
      "Epoch 70/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5795 - categorical_accuracy: 0.6333 - top_3_accuracy: 0.8058\n",
      "\n",
      "Epoch 00070: top_3_accuracy did not improve from 0.80664\n",
      "Epoch 71/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5775 - categorical_accuracy: 0.6318 - top_3_accuracy: 0.8047\n",
      "\n",
      "Epoch 00071: top_3_accuracy did not improve from 0.80664\n",
      "Epoch 72/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5694 - categorical_accuracy: 0.6356 - top_3_accuracy: 0.8059\n",
      "\n",
      "Epoch 00072: top_3_accuracy did not improve from 0.80664\n",
      "Epoch 73/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5900 - categorical_accuracy: 0.6320 - top_3_accuracy: 0.8040\n",
      "\n",
      "Epoch 00073: top_3_accuracy did not improve from 0.80664\n",
      "Epoch 74/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5980 - categorical_accuracy: 0.6293 - top_3_accuracy: 0.8011\n",
      "\n",
      "Epoch 00074: top_3_accuracy did not improve from 0.80664\n",
      "Epoch 75/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5788 - categorical_accuracy: 0.6325 - top_3_accuracy: 0.8055\n",
      "\n",
      "Epoch 00075: top_3_accuracy did not improve from 0.80664\n",
      "Epoch 76/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5629 - categorical_accuracy: 0.6349 - top_3_accuracy: 0.8070\n",
      "\n",
      "Epoch 00076: top_3_accuracy improved from 0.80664 to 0.80703, saving model to ./CNN_3_dropout.model\n",
      "Epoch 77/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5660 - categorical_accuracy: 0.6376 - top_3_accuracy: 0.8052\n",
      "\n",
      "Epoch 00077: top_3_accuracy did not improve from 0.80703\n",
      "Epoch 78/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5570 - categorical_accuracy: 0.6352 - top_3_accuracy: 0.8083\n",
      "\n",
      "Epoch 00078: top_3_accuracy improved from 0.80703 to 0.80828, saving model to ./CNN_3_dropout.model\n",
      "Epoch 79/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5519 - categorical_accuracy: 0.6362 - top_3_accuracy: 0.8102\n",
      "\n",
      "Epoch 00079: top_3_accuracy improved from 0.80828 to 0.81021, saving model to ./CNN_3_dropout.model\n",
      "Epoch 80/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5555 - categorical_accuracy: 0.6357 - top_3_accuracy: 0.8095\n",
      "\n",
      "Epoch 00080: top_3_accuracy did not improve from 0.81021\n",
      "Epoch 81/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5560 - categorical_accuracy: 0.6363 - top_3_accuracy: 0.8088\n",
      "\n",
      "Epoch 00081: top_3_accuracy did not improve from 0.81021\n",
      "Epoch 82/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5385 - categorical_accuracy: 0.6432 - top_3_accuracy: 0.8108\n",
      "\n",
      "Epoch 00082: top_3_accuracy improved from 0.81021 to 0.81080, saving model to ./CNN_3_dropout.model\n",
      "Epoch 83/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5303 - categorical_accuracy: 0.6407 - top_3_accuracy: 0.8130\n",
      "\n",
      "Epoch 00083: top_3_accuracy improved from 0.81080 to 0.81303, saving model to ./CNN_3_dropout.model\n",
      "Epoch 84/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5414 - categorical_accuracy: 0.6349 - top_3_accuracy: 0.8110\n",
      "\n",
      "Epoch 00084: top_3_accuracy did not improve from 0.81303\n",
      "Epoch 85/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5493 - categorical_accuracy: 0.6394 - top_3_accuracy: 0.8093\n",
      "\n",
      "Epoch 00085: top_3_accuracy did not improve from 0.81303\n",
      "Epoch 86/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5524 - categorical_accuracy: 0.6400 - top_3_accuracy: 0.8092\n",
      "\n",
      "Epoch 00086: top_3_accuracy did not improve from 0.81303\n",
      "Epoch 87/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5495 - categorical_accuracy: 0.6387 - top_3_accuracy: 0.8095\n",
      "\n",
      "Epoch 00087: top_3_accuracy did not improve from 0.81303\n",
      "Epoch 88/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5690 - categorical_accuracy: 0.6351 - top_3_accuracy: 0.8063\n",
      "\n",
      "Epoch 00088: top_3_accuracy did not improve from 0.81303\n",
      "Epoch 89/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5427 - categorical_accuracy: 0.6389 - top_3_accuracy: 0.8109\n",
      "\n",
      "Epoch 00089: top_3_accuracy did not improve from 0.81303\n",
      "Epoch 90/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5471 - categorical_accuracy: 0.6366 - top_3_accuracy: 0.8108\n",
      "\n",
      "Epoch 00090: top_3_accuracy did not improve from 0.81303\n",
      "Epoch 91/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5260 - categorical_accuracy: 0.6426 - top_3_accuracy: 0.8131\n",
      "\n",
      "Epoch 00091: top_3_accuracy improved from 0.81303 to 0.81314, saving model to ./CNN_3_dropout.model\n",
      "Epoch 92/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5458 - categorical_accuracy: 0.6384 - top_3_accuracy: 0.8094\n",
      "\n",
      "Epoch 00092: top_3_accuracy did not improve from 0.81314\n",
      "Epoch 93/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5541 - categorical_accuracy: 0.6373 - top_3_accuracy: 0.8091\n",
      "\n",
      "Epoch 00093: top_3_accuracy did not improve from 0.81314\n",
      "Epoch 94/250\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 1.5345 - categorical_accuracy: 0.6419 - top_3_accuracy: 0.8112\n",
      "\n",
      "Epoch 00094: top_3_accuracy did not improve from 0.81314\n",
      "Epoch 95/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5517 - categorical_accuracy: 0.6411 - top_3_accuracy: 0.8067\n",
      "\n",
      "Epoch 00095: top_3_accuracy did not improve from 0.81314\n",
      "Epoch 96/250\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 1.5386 - categorical_accuracy: 0.6413 - top_3_accuracy: 0.8101\n",
      "\n",
      "Epoch 00096: top_3_accuracy did not improve from 0.81314\n",
      "Epoch 97/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5463 - categorical_accuracy: 0.6396 - top_3_accuracy: 0.8097\n",
      "\n",
      "Epoch 00097: top_3_accuracy did not improve from 0.81314\n",
      "Epoch 98/250\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5310 - categorical_accuracy: 0.6409 - top_3_accuracy: 0.8132\n",
      "\n",
      "Epoch 00098: top_3_accuracy improved from 0.81314 to 0.81324, saving model to ./CNN_3_dropout.model\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "CNN_4 = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXMJirP1uySY"
   },
   "source": [
    " LB  = 0.756. \n",
    " \n",
    " **Вывод:**  Результаты с активацией elu хуже, чем с активацией relu. Поэтому активацию selu, как мне кажется, использовать не стоит, потому что она похожа на elu. На следующем эксперименте заменю relu на LeakyRelu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jqa0aagD5fqk"
   },
   "source": [
    "#Эксперимент №6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nvi2RMbuKzWs"
   },
   "source": [
    "Та же сеть, что и в эксперименте 4, только с активацией **LeakyReLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AFX98fGm5jy5",
    "outputId": "6006b820-0cff-41ce-ffda-7e89c8d77fe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-kOs2LC5kDW"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nq7j79EV5kSY"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EoR0IXyY5kqr"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bqy74LHY5k-h"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3T47ZBZA5lPV"
   },
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "_EauOR6X5lKp",
    "outputId": "b94e6488-54c1-4eba-dd84-71bb2a6a5e61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uf7Agy095lGG"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8Fgf9Gid5k6A",
    "outputId": "b85937a4-a287-458e-ad15-67941cffa7c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EciFIAyb5k1o"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3),padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3),padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "   \n",
    "\n",
    "    model.add(Dense(4098))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "  \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "7J56SsO88R-4",
    "outputId": "ebc917e7-7ed3-485b-c62b-5054431b8891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4098)              8396802   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               1393660   \n",
      "=================================================================\n",
      "Total params: 9,896,862\n",
      "Trainable params: 9,896,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Gvm9DwT5kxW"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4g1OoIdC5kmS"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 250 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7BpEr5T5kh4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='top_3_accuracy', patience=15, min_delta=0.001, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n",
    "    ModelCheckpoint(\"./CNN_6.model\",monitor='top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOWAKswI5kdi"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0\n",
    "\n",
    "# you can continue from snapshot!!!\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 2\n",
    "# model = load_model(\"model_{}\".format(last_finished_epoch), \n",
    "#                    custom_objects={\"top_3_accuracy\": top_3_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6497
    },
    "colab_type": "code",
    "id": "TtXCHDDa5kZO",
    "outputId": "19b0b937-1c51-450c-c7a2-07eb4771fe14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "100/100 [==============================] - 47s 473ms/step - loss: 4.4783 - categorical_accuracy: 0.1351 - top_3_accuracy: 0.2447\n",
      "\n",
      "Epoch 00001: top_3_accuracy improved from -inf to 0.24471, saving model to ./CNN_6.model\n",
      "Epoch 2/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 2.9743 - categorical_accuracy: 0.3474 - top_3_accuracy: 0.5386\n",
      "\n",
      "Epoch 00002: top_3_accuracy improved from 0.24471 to 0.53859, saving model to ./CNN_6.model\n",
      "Epoch 3/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 2.4918 - categorical_accuracy: 0.4344 - top_3_accuracy: 0.6354\n",
      "\n",
      "Epoch 00003: top_3_accuracy improved from 0.53859 to 0.63539, saving model to ./CNN_6.model\n",
      "Epoch 4/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 2.2756 - categorical_accuracy: 0.4786 - top_3_accuracy: 0.6760\n",
      "\n",
      "Epoch 00004: top_3_accuracy improved from 0.63539 to 0.67602, saving model to ./CNN_6.model\n",
      "Epoch 5/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 2.1066 - categorical_accuracy: 0.5120 - top_3_accuracy: 0.7092\n",
      "\n",
      "Epoch 00005: top_3_accuracy improved from 0.67602 to 0.70918, saving model to ./CNN_6.model\n",
      "Epoch 6/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 2.0001 - categorical_accuracy: 0.5340 - top_3_accuracy: 0.7280\n",
      "\n",
      "Epoch 00006: top_3_accuracy improved from 0.70918 to 0.72801, saving model to ./CNN_6.model\n",
      "Epoch 7/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.9419 - categorical_accuracy: 0.5485 - top_3_accuracy: 0.7402\n",
      "\n",
      "Epoch 00007: top_3_accuracy improved from 0.72801 to 0.74016, saving model to ./CNN_6.model\n",
      "Epoch 8/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.8469 - categorical_accuracy: 0.5662 - top_3_accuracy: 0.7589\n",
      "\n",
      "Epoch 00008: top_3_accuracy improved from 0.74016 to 0.75895, saving model to ./CNN_6.model\n",
      "Epoch 9/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.8068 - categorical_accuracy: 0.5705 - top_3_accuracy: 0.7657\n",
      "\n",
      "Epoch 00009: top_3_accuracy improved from 0.75895 to 0.76570, saving model to ./CNN_6.model\n",
      "Epoch 10/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.7761 - categorical_accuracy: 0.5778 - top_3_accuracy: 0.7691\n",
      "\n",
      "Epoch 00010: top_3_accuracy improved from 0.76570 to 0.76912, saving model to ./CNN_6.model\n",
      "Epoch 11/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.7414 - categorical_accuracy: 0.5879 - top_3_accuracy: 0.7759\n",
      "\n",
      "Epoch 00011: top_3_accuracy improved from 0.76912 to 0.77586, saving model to ./CNN_6.model\n",
      "Epoch 12/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.6939 - categorical_accuracy: 0.5988 - top_3_accuracy: 0.7837\n",
      "\n",
      "Epoch 00012: top_3_accuracy improved from 0.77586 to 0.78365, saving model to ./CNN_6.model\n",
      "Epoch 13/250\n",
      "100/100 [==============================] - 46s 464ms/step - loss: 1.6911 - categorical_accuracy: 0.5991 - top_3_accuracy: 0.7859\n",
      "\n",
      "Epoch 00013: top_3_accuracy improved from 0.78365 to 0.78592, saving model to ./CNN_6.model\n",
      "Epoch 14/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.6545 - categorical_accuracy: 0.6042 - top_3_accuracy: 0.7902\n",
      "\n",
      "Epoch 00014: top_3_accuracy improved from 0.78592 to 0.79021, saving model to ./CNN_6.model\n",
      "Epoch 15/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.6435 - categorical_accuracy: 0.6088 - top_3_accuracy: 0.7921\n",
      "\n",
      "Epoch 00015: top_3_accuracy improved from 0.79021 to 0.79211, saving model to ./CNN_6.model\n",
      "Epoch 16/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.6208 - categorical_accuracy: 0.6112 - top_3_accuracy: 0.7966\n",
      "\n",
      "Epoch 00016: top_3_accuracy improved from 0.79211 to 0.79660, saving model to ./CNN_6.model\n",
      "Epoch 17/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.5923 - categorical_accuracy: 0.6183 - top_3_accuracy: 0.8021\n",
      "\n",
      "Epoch 00017: top_3_accuracy improved from 0.79660 to 0.80211, saving model to ./CNN_6.model\n",
      "Epoch 18/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.5683 - categorical_accuracy: 0.6231 - top_3_accuracy: 0.8042\n",
      "\n",
      "Epoch 00018: top_3_accuracy improved from 0.80211 to 0.80424, saving model to ./CNN_6.model\n",
      "Epoch 19/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.5696 - categorical_accuracy: 0.6228 - top_3_accuracy: 0.8078\n",
      "\n",
      "Epoch 00019: top_3_accuracy improved from 0.80424 to 0.80783, saving model to ./CNN_6.model\n",
      "Epoch 20/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.5414 - categorical_accuracy: 0.6300 - top_3_accuracy: 0.8112\n",
      "\n",
      "Epoch 00020: top_3_accuracy improved from 0.80783 to 0.81121, saving model to ./CNN_6.model\n",
      "Epoch 21/250\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.5365 - categorical_accuracy: 0.6305 - top_3_accuracy: 0.8107\n",
      "\n",
      "Epoch 00021: top_3_accuracy did not improve from 0.81121\n",
      "Epoch 22/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.5233 - categorical_accuracy: 0.6321 - top_3_accuracy: 0.8097\n",
      "\n",
      "Epoch 00022: top_3_accuracy did not improve from 0.81121\n",
      "Epoch 23/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.5296 - categorical_accuracy: 0.6336 - top_3_accuracy: 0.8118\n",
      "\n",
      "Epoch 00023: top_3_accuracy improved from 0.81121 to 0.81184, saving model to ./CNN_6.model\n",
      "Epoch 24/250\n",
      "100/100 [==============================] - 46s 459ms/step - loss: 1.5032 - categorical_accuracy: 0.6401 - top_3_accuracy: 0.8153\n",
      "\n",
      "Epoch 00024: top_3_accuracy improved from 0.81184 to 0.81529, saving model to ./CNN_6.model\n",
      "Epoch 25/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.4832 - categorical_accuracy: 0.6419 - top_3_accuracy: 0.8184\n",
      "\n",
      "Epoch 00025: top_3_accuracy improved from 0.81529 to 0.81838, saving model to ./CNN_6.model\n",
      "Epoch 26/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.4766 - categorical_accuracy: 0.6429 - top_3_accuracy: 0.8215\n",
      "\n",
      "Epoch 00026: top_3_accuracy improved from 0.81838 to 0.82146, saving model to ./CNN_6.model\n",
      "Epoch 27/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.4657 - categorical_accuracy: 0.6427 - top_3_accuracy: 0.8223\n",
      "\n",
      "Epoch 00027: top_3_accuracy improved from 0.82146 to 0.82234, saving model to ./CNN_6.model\n",
      "Epoch 28/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.4683 - categorical_accuracy: 0.6428 - top_3_accuracy: 0.8221\n",
      "\n",
      "Epoch 00028: top_3_accuracy did not improve from 0.82234\n",
      "Epoch 29/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.4541 - categorical_accuracy: 0.6477 - top_3_accuracy: 0.8246\n",
      "\n",
      "Epoch 00029: top_3_accuracy improved from 0.82234 to 0.82463, saving model to ./CNN_6.model\n",
      "Epoch 30/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.4324 - categorical_accuracy: 0.6542 - top_3_accuracy: 0.8280\n",
      "\n",
      "Epoch 00030: top_3_accuracy improved from 0.82463 to 0.82801, saving model to ./CNN_6.model\n",
      "Epoch 31/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.4255 - categorical_accuracy: 0.6521 - top_3_accuracy: 0.8278\n",
      "\n",
      "Epoch 00031: top_3_accuracy did not improve from 0.82801\n",
      "Epoch 32/250\n",
      "100/100 [==============================] - 46s 457ms/step - loss: 1.4088 - categorical_accuracy: 0.6589 - top_3_accuracy: 0.8317\n",
      "\n",
      "Epoch 00032: top_3_accuracy improved from 0.82801 to 0.83166, saving model to ./CNN_6.model\n",
      "Epoch 33/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.4096 - categorical_accuracy: 0.6604 - top_3_accuracy: 0.8312\n",
      "\n",
      "Epoch 00033: top_3_accuracy did not improve from 0.83166\n",
      "Epoch 34/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.4155 - categorical_accuracy: 0.6565 - top_3_accuracy: 0.8305\n",
      "\n",
      "Epoch 00034: top_3_accuracy did not improve from 0.83166\n",
      "Epoch 35/250\n",
      "100/100 [==============================] - 46s 459ms/step - loss: 1.4142 - categorical_accuracy: 0.6575 - top_3_accuracy: 0.8309\n",
      "\n",
      "Epoch 00035: top_3_accuracy did not improve from 0.83166\n",
      "Epoch 36/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.3592 - categorical_accuracy: 0.6701 - top_3_accuracy: 0.8379\n",
      "\n",
      "Epoch 00036: top_3_accuracy improved from 0.83166 to 0.83793, saving model to ./CNN_6.model\n",
      "Epoch 37/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.3500 - categorical_accuracy: 0.6753 - top_3_accuracy: 0.8426\n",
      "\n",
      "Epoch 00037: top_3_accuracy improved from 0.83793 to 0.84256, saving model to ./CNN_6.model\n",
      "Epoch 38/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.3426 - categorical_accuracy: 0.6743 - top_3_accuracy: 0.8420\n",
      "\n",
      "Epoch 00038: top_3_accuracy did not improve from 0.84256\n",
      "Epoch 39/250\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.3322 - categorical_accuracy: 0.6780 - top_3_accuracy: 0.8455\n",
      "\n",
      "Epoch 00039: top_3_accuracy improved from 0.84256 to 0.84549, saving model to ./CNN_6.model\n",
      "Epoch 40/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.3266 - categorical_accuracy: 0.6767 - top_3_accuracy: 0.8449\n",
      "\n",
      "Epoch 00040: top_3_accuracy did not improve from 0.84549\n",
      "Epoch 41/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.3322 - categorical_accuracy: 0.6765 - top_3_accuracy: 0.8441\n",
      "\n",
      "Epoch 00041: top_3_accuracy did not improve from 0.84549\n",
      "Epoch 42/250\n",
      "100/100 [==============================] - 46s 459ms/step - loss: 1.3250 - categorical_accuracy: 0.6789 - top_3_accuracy: 0.8465\n",
      "\n",
      "Epoch 00042: top_3_accuracy improved from 0.84549 to 0.84646, saving model to ./CNN_6.model\n",
      "Epoch 43/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.3216 - categorical_accuracy: 0.6797 - top_3_accuracy: 0.8470\n",
      "\n",
      "Epoch 00043: top_3_accuracy improved from 0.84646 to 0.84695, saving model to ./CNN_6.model\n",
      "Epoch 44/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.3162 - categorical_accuracy: 0.6827 - top_3_accuracy: 0.8453\n",
      "\n",
      "Epoch 00044: top_3_accuracy did not improve from 0.84695\n",
      "Epoch 45/250\n",
      "100/100 [==============================] - 46s 459ms/step - loss: 1.3003 - categorical_accuracy: 0.6855 - top_3_accuracy: 0.8499\n",
      "\n",
      "Epoch 00045: top_3_accuracy improved from 0.84695 to 0.84986, saving model to ./CNN_6.model\n",
      "Epoch 46/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2794 - categorical_accuracy: 0.6903 - top_3_accuracy: 0.8517\n",
      "\n",
      "Epoch 00046: top_3_accuracy improved from 0.84986 to 0.85168, saving model to ./CNN_6.model\n",
      "Epoch 47/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2867 - categorical_accuracy: 0.6867 - top_3_accuracy: 0.8517\n",
      "\n",
      "Epoch 00047: top_3_accuracy did not improve from 0.85168\n",
      "Epoch 48/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2748 - categorical_accuracy: 0.6914 - top_3_accuracy: 0.8519\n",
      "\n",
      "Epoch 00048: top_3_accuracy improved from 0.85168 to 0.85186, saving model to ./CNN_6.model\n",
      "Epoch 49/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2599 - categorical_accuracy: 0.6962 - top_3_accuracy: 0.8551\n",
      "\n",
      "Epoch 00049: top_3_accuracy improved from 0.85186 to 0.85510, saving model to ./CNN_6.model\n",
      "Epoch 50/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2714 - categorical_accuracy: 0.6907 - top_3_accuracy: 0.8520\n",
      "\n",
      "Epoch 00050: top_3_accuracy did not improve from 0.85510\n",
      "Epoch 51/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.2499 - categorical_accuracy: 0.6947 - top_3_accuracy: 0.8567\n",
      "\n",
      "Epoch 00051: top_3_accuracy improved from 0.85510 to 0.85674, saving model to ./CNN_6.model\n",
      "Epoch 52/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2517 - categorical_accuracy: 0.6946 - top_3_accuracy: 0.8564\n",
      "\n",
      "Epoch 00052: top_3_accuracy did not improve from 0.85674\n",
      "Epoch 53/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2626 - categorical_accuracy: 0.6927 - top_3_accuracy: 0.8541\n",
      "\n",
      "Epoch 00053: top_3_accuracy did not improve from 0.85674\n",
      "Epoch 54/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2508 - categorical_accuracy: 0.6956 - top_3_accuracy: 0.8556\n",
      "\n",
      "Epoch 00054: top_3_accuracy did not improve from 0.85674\n",
      "Epoch 55/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2543 - categorical_accuracy: 0.6957 - top_3_accuracy: 0.8546\n",
      "\n",
      "Epoch 00055: top_3_accuracy did not improve from 0.85674\n",
      "Epoch 56/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2463 - categorical_accuracy: 0.6963 - top_3_accuracy: 0.8567\n",
      "\n",
      "Epoch 00056: top_3_accuracy did not improve from 0.85674\n",
      "Epoch 57/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2457 - categorical_accuracy: 0.6975 - top_3_accuracy: 0.8565\n",
      "\n",
      "Epoch 00057: top_3_accuracy did not improve from 0.85674\n",
      "Epoch 58/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2393 - categorical_accuracy: 0.6996 - top_3_accuracy: 0.8564\n",
      "\n",
      "Epoch 00058: top_3_accuracy did not improve from 0.85674\n",
      "Epoch 59/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2329 - categorical_accuracy: 0.7000 - top_3_accuracy: 0.8582\n",
      "\n",
      "Epoch 00059: top_3_accuracy improved from 0.85674 to 0.85818, saving model to ./CNN_6.model\n",
      "Epoch 60/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2248 - categorical_accuracy: 0.7019 - top_3_accuracy: 0.8603\n",
      "\n",
      "Epoch 00060: top_3_accuracy improved from 0.85818 to 0.86031, saving model to ./CNN_6.model\n",
      "Epoch 61/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2285 - categorical_accuracy: 0.6993 - top_3_accuracy: 0.8598\n",
      "\n",
      "Epoch 00061: top_3_accuracy did not improve from 0.86031\n",
      "Epoch 62/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2233 - categorical_accuracy: 0.7002 - top_3_accuracy: 0.8599\n",
      "\n",
      "Epoch 00062: top_3_accuracy did not improve from 0.86031\n",
      "Epoch 63/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2239 - categorical_accuracy: 0.7025 - top_3_accuracy: 0.8597\n",
      "\n",
      "Epoch 00063: top_3_accuracy did not improve from 0.86031\n",
      "Epoch 64/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2253 - categorical_accuracy: 0.7023 - top_3_accuracy: 0.8602\n",
      "\n",
      "Epoch 00064: top_3_accuracy did not improve from 0.86031\n",
      "Epoch 65/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2206 - categorical_accuracy: 0.7051 - top_3_accuracy: 0.8591\n",
      "\n",
      "Epoch 00065: top_3_accuracy did not improve from 0.86031\n",
      "Epoch 66/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2305 - categorical_accuracy: 0.7010 - top_3_accuracy: 0.8598\n",
      "\n",
      "Epoch 00066: top_3_accuracy did not improve from 0.86031\n",
      "Epoch 67/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2225 - categorical_accuracy: 0.7038 - top_3_accuracy: 0.8598\n",
      "\n",
      "Epoch 00067: top_3_accuracy did not improve from 0.86031\n",
      "Epoch 68/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2302 - categorical_accuracy: 0.6994 - top_3_accuracy: 0.8604\n",
      "\n",
      "Epoch 00068: top_3_accuracy improved from 0.86031 to 0.86045, saving model to ./CNN_6.model\n",
      "Epoch 69/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.2144 - categorical_accuracy: 0.7061 - top_3_accuracy: 0.8629\n",
      "\n",
      "Epoch 00069: top_3_accuracy improved from 0.86045 to 0.86287, saving model to ./CNN_6.model\n",
      "Epoch 70/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.2174 - categorical_accuracy: 0.7022 - top_3_accuracy: 0.8617\n",
      "\n",
      "Epoch 00070: top_3_accuracy did not improve from 0.86287\n",
      "Epoch 71/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2170 - categorical_accuracy: 0.7051 - top_3_accuracy: 0.8604\n",
      "\n",
      "Epoch 00071: top_3_accuracy did not improve from 0.86287\n",
      "Epoch 72/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2074 - categorical_accuracy: 0.7069 - top_3_accuracy: 0.8639\n",
      "\n",
      "Epoch 00072: top_3_accuracy improved from 0.86287 to 0.86387, saving model to ./CNN_6.model\n",
      "Epoch 73/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2318 - categorical_accuracy: 0.7029 - top_3_accuracy: 0.8587\n",
      "\n",
      "Epoch 00073: top_3_accuracy did not improve from 0.86387\n",
      "Epoch 74/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2209 - categorical_accuracy: 0.7037 - top_3_accuracy: 0.8599\n",
      "\n",
      "Epoch 00074: top_3_accuracy did not improve from 0.86387\n",
      "Epoch 75/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2295 - categorical_accuracy: 0.7017 - top_3_accuracy: 0.8598\n",
      "\n",
      "Epoch 00075: top_3_accuracy did not improve from 0.86387\n",
      "Epoch 76/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2040 - categorical_accuracy: 0.7068 - top_3_accuracy: 0.8623\n",
      "\n",
      "Epoch 00076: top_3_accuracy did not improve from 0.86387\n",
      "Epoch 77/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.2165 - categorical_accuracy: 0.7039 - top_3_accuracy: 0.8612\n",
      "\n",
      "Epoch 00077: top_3_accuracy did not improve from 0.86387\n",
      "Epoch 78/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.2031 - categorical_accuracy: 0.7076 - top_3_accuracy: 0.8624\n",
      "\n",
      "Epoch 00078: top_3_accuracy did not improve from 0.86387\n",
      "Epoch 79/250\n",
      "100/100 [==============================] - 46s 459ms/step - loss: 1.2032 - categorical_accuracy: 0.7120 - top_3_accuracy: 0.8625\n",
      "\n",
      "Epoch 00079: top_3_accuracy did not improve from 0.86387\n",
      "Epoch 80/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2025 - categorical_accuracy: 0.7063 - top_3_accuracy: 0.8650\n",
      "\n",
      "Epoch 00080: top_3_accuracy improved from 0.86387 to 0.86500, saving model to ./CNN_6.model\n",
      "Epoch 81/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.2106 - categorical_accuracy: 0.7044 - top_3_accuracy: 0.8616\n",
      "\n",
      "Epoch 00081: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 82/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.1876 - categorical_accuracy: 0.7086 - top_3_accuracy: 0.8649\n",
      "\n",
      "Epoch 00082: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 83/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.1961 - categorical_accuracy: 0.7081 - top_3_accuracy: 0.8650\n",
      "\n",
      "Epoch 00083: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 84/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.1840 - categorical_accuracy: 0.7125 - top_3_accuracy: 0.8649\n",
      "\n",
      "Epoch 00084: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 85/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.1940 - categorical_accuracy: 0.7090 - top_3_accuracy: 0.8633\n",
      "\n",
      "Epoch 00085: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 86/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2152 - categorical_accuracy: 0.7058 - top_3_accuracy: 0.8596\n",
      "\n",
      "Epoch 00086: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 87/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2118 - categorical_accuracy: 0.7066 - top_3_accuracy: 0.8603\n",
      "\n",
      "Epoch 00087: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 88/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.2137 - categorical_accuracy: 0.7074 - top_3_accuracy: 0.8614\n",
      "\n",
      "Epoch 00088: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 89/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.2108 - categorical_accuracy: 0.7029 - top_3_accuracy: 0.8637\n",
      "\n",
      "Epoch 00089: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 90/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.1939 - categorical_accuracy: 0.7074 - top_3_accuracy: 0.8622\n",
      "\n",
      "Epoch 00090: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 91/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2030 - categorical_accuracy: 0.7097 - top_3_accuracy: 0.8612\n",
      "\n",
      "Epoch 00091: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 92/250\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.1980 - categorical_accuracy: 0.7062 - top_3_accuracy: 0.8633\n",
      "\n",
      "Epoch 00092: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 93/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.2004 - categorical_accuracy: 0.7071 - top_3_accuracy: 0.8630\n",
      "\n",
      "Epoch 00093: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 94/250\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.1972 - categorical_accuracy: 0.7083 - top_3_accuracy: 0.8646\n",
      "\n",
      "Epoch 00094: top_3_accuracy did not improve from 0.86500\n",
      "Epoch 95/250\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.1889 - categorical_accuracy: 0.7110 - top_3_accuracy: 0.8636\n",
      "\n",
      "Epoch 00095: top_3_accuracy did not improve from 0.86500\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "CNN_6 = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pc0eZUOBN4oa"
   },
   "source": [
    "**Вывод:** LB=0.816 (с активацией relu было LB=0.808). Результат улучшился, но не намного"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmlzTn1SPLGt"
   },
   "source": [
    "#Эксперимент №7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jq72spt_LXOY"
   },
   "source": [
    "Еще одна попытка настроить регуляризацию. Пока удалось получить лучший результат только с использованием регуляризации DropOut. Добавлю после каждого слоя сверточного слоя и на полносвязном **BatchNormalization** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZmSJT69j5j-7",
    "outputId": "1da72498-8d96-4720-b417-5b0e387f2bb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbOME9oS5j6n"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlrZwZmvPjMz"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jb8zkO0RPjoi"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXqwD4iKPkNB"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycr-Q2s3PkXX"
   },
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "9aYBD1X5PkGE",
    "outputId": "38f1297b-a3cf-40a7-d597-f4252f268e32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MomsXqyPkAh"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "s7n8kmyfPj7Q",
    "outputId": "c11e990a-941a-42ff-8359-20b2fcb5d354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTb5nFKCPj1h"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3),padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "   \n",
    "\n",
    "    model.add(Dense(4098))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "  \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1091
    },
    "colab_type": "code",
    "id": "pyky5X6VPjwX",
    "outputId": "6c941b15-21ce-4eba-cec7-ccdebd1d520f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4098)              8396802   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4098)              16392     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               1393660   \n",
      "=================================================================\n",
      "Total params: 9,914,342\n",
      "Trainable params: 9,905,602\n",
      "Non-trainable params: 8,740\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception tensorflow.python.framework.errors_impl.CancelledError: CancelledError() in <bound method _Callable.__del__ of <tensorflow.python.client.session._Callable object at 0x7f9ec28a5f10>> ignored\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXBzaI7ePjjh"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZScekGQPjeg"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 100 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OhB846rPjZb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='top_3_accuracy', patience=8, min_delta=0.001, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n",
    "    ModelCheckpoint(\"./CNN_7.model\",monitor='top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pjMGPAEPjUY"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4729
    },
    "colab_type": "code",
    "id": "ZVo9NcnMQSdA",
    "outputId": "89b8865c-1068-4276-84e0-37e64386dda4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 68s 676ms/step - loss: 3.9216 - categorical_accuracy: 0.2304 - top_3_accuracy: 0.3785\n",
      "\n",
      "Epoch 00001: top_3_accuracy improved from -inf to 0.37848, saving model to ./CNN_7.model\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 66s 657ms/step - loss: 2.8939 - categorical_accuracy: 0.3722 - top_3_accuracy: 0.5632\n",
      "\n",
      "Epoch 00002: top_3_accuracy improved from 0.37848 to 0.56320, saving model to ./CNN_7.model\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 2.5447 - categorical_accuracy: 0.4344 - top_3_accuracy: 0.6303\n",
      "\n",
      "Epoch 00003: top_3_accuracy improved from 0.56320 to 0.63027, saving model to ./CNN_7.model\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 2.3663 - categorical_accuracy: 0.4672 - top_3_accuracy: 0.6629\n",
      "\n",
      "Epoch 00004: top_3_accuracy improved from 0.63027 to 0.66295, saving model to ./CNN_7.model\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 2.2110 - categorical_accuracy: 0.4985 - top_3_accuracy: 0.6930\n",
      "\n",
      "Epoch 00005: top_3_accuracy improved from 0.66295 to 0.69297, saving model to ./CNN_7.model\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 2.0985 - categorical_accuracy: 0.5165 - top_3_accuracy: 0.7128\n",
      "\n",
      "Epoch 00006: top_3_accuracy improved from 0.69297 to 0.71281, saving model to ./CNN_7.model\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 2.0440 - categorical_accuracy: 0.5285 - top_3_accuracy: 0.7258\n",
      "\n",
      "Epoch 00007: top_3_accuracy improved from 0.71281 to 0.72582, saving model to ./CNN_7.model\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.9385 - categorical_accuracy: 0.5491 - top_3_accuracy: 0.7437\n",
      "\n",
      "Epoch 00008: top_3_accuracy improved from 0.72582 to 0.74373, saving model to ./CNN_7.model\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.8770 - categorical_accuracy: 0.5623 - top_3_accuracy: 0.7523\n",
      "\n",
      "Epoch 00009: top_3_accuracy improved from 0.74373 to 0.75227, saving model to ./CNN_7.model\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.8499 - categorical_accuracy: 0.5657 - top_3_accuracy: 0.7585\n",
      "\n",
      "Epoch 00010: top_3_accuracy improved from 0.75227 to 0.75848, saving model to ./CNN_7.model\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 66s 656ms/step - loss: 1.7978 - categorical_accuracy: 0.5778 - top_3_accuracy: 0.7678\n",
      "\n",
      "Epoch 00011: top_3_accuracy improved from 0.75848 to 0.76779, saving model to ./CNN_7.model\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 66s 655ms/step - loss: 1.7674 - categorical_accuracy: 0.5819 - top_3_accuracy: 0.7718\n",
      "\n",
      "Epoch 00012: top_3_accuracy improved from 0.76779 to 0.77178, saving model to ./CNN_7.model\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.7385 - categorical_accuracy: 0.5886 - top_3_accuracy: 0.7781\n",
      "\n",
      "Epoch 00013: top_3_accuracy improved from 0.77178 to 0.77807, saving model to ./CNN_7.model\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.7122 - categorical_accuracy: 0.5947 - top_3_accuracy: 0.7814\n",
      "\n",
      "Epoch 00014: top_3_accuracy improved from 0.77807 to 0.78141, saving model to ./CNN_7.model\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.6694 - categorical_accuracy: 0.6047 - top_3_accuracy: 0.7881\n",
      "\n",
      "Epoch 00015: top_3_accuracy improved from 0.78141 to 0.78814, saving model to ./CNN_7.model\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.6505 - categorical_accuracy: 0.6072 - top_3_accuracy: 0.7921\n",
      "\n",
      "Epoch 00016: top_3_accuracy improved from 0.78814 to 0.79205, saving model to ./CNN_7.model\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.6441 - categorical_accuracy: 0.6114 - top_3_accuracy: 0.7933\n",
      "\n",
      "Epoch 00017: top_3_accuracy improved from 0.79205 to 0.79330, saving model to ./CNN_7.model\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.5968 - categorical_accuracy: 0.6195 - top_3_accuracy: 0.8001\n",
      "\n",
      "Epoch 00018: top_3_accuracy improved from 0.79330 to 0.80012, saving model to ./CNN_7.model\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.5854 - categorical_accuracy: 0.6213 - top_3_accuracy: 0.8034\n",
      "\n",
      "Epoch 00019: top_3_accuracy improved from 0.80012 to 0.80336, saving model to ./CNN_7.model\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.5695 - categorical_accuracy: 0.6246 - top_3_accuracy: 0.8064\n",
      "\n",
      "Epoch 00020: top_3_accuracy improved from 0.80336 to 0.80643, saving model to ./CNN_7.model\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.5364 - categorical_accuracy: 0.6295 - top_3_accuracy: 0.8102\n",
      "\n",
      "Epoch 00021: top_3_accuracy improved from 0.80643 to 0.81023, saving model to ./CNN_7.model\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 66s 655ms/step - loss: 1.5521 - categorical_accuracy: 0.6274 - top_3_accuracy: 0.8058\n",
      "\n",
      "Epoch 00022: top_3_accuracy did not improve from 0.81023\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.5373 - categorical_accuracy: 0.6332 - top_3_accuracy: 0.8096\n",
      "\n",
      "Epoch 00023: top_3_accuracy did not improve from 0.81023\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.5104 - categorical_accuracy: 0.6381 - top_3_accuracy: 0.8147\n",
      "\n",
      "Epoch 00024: top_3_accuracy improved from 0.81023 to 0.81467, saving model to ./CNN_7.model\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.4890 - categorical_accuracy: 0.6425 - top_3_accuracy: 0.8200\n",
      "\n",
      "Epoch 00025: top_3_accuracy improved from 0.81467 to 0.82000, saving model to ./CNN_7.model\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.4787 - categorical_accuracy: 0.6453 - top_3_accuracy: 0.8205\n",
      "\n",
      "Epoch 00026: top_3_accuracy improved from 0.82000 to 0.82055, saving model to ./CNN_7.model\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.4696 - categorical_accuracy: 0.6454 - top_3_accuracy: 0.8216\n",
      "\n",
      "Epoch 00027: top_3_accuracy improved from 0.82055 to 0.82156, saving model to ./CNN_7.model\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.4769 - categorical_accuracy: 0.6428 - top_3_accuracy: 0.8198\n",
      "\n",
      "Epoch 00028: top_3_accuracy did not improve from 0.82156\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 66s 656ms/step - loss: 1.4668 - categorical_accuracy: 0.6450 - top_3_accuracy: 0.8240\n",
      "\n",
      "Epoch 00029: top_3_accuracy improved from 0.82156 to 0.82400, saving model to ./CNN_7.model\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 66s 656ms/step - loss: 1.4351 - categorical_accuracy: 0.6521 - top_3_accuracy: 0.8262\n",
      "\n",
      "Epoch 00030: top_3_accuracy improved from 0.82400 to 0.82619, saving model to ./CNN_7.model\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 66s 655ms/step - loss: 1.4330 - categorical_accuracy: 0.6545 - top_3_accuracy: 0.8282\n",
      "\n",
      "Epoch 00031: top_3_accuracy improved from 0.82619 to 0.82816, saving model to ./CNN_7.model\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.4092 - categorical_accuracy: 0.6589 - top_3_accuracy: 0.8320\n",
      "\n",
      "Epoch 00032: top_3_accuracy improved from 0.82816 to 0.83203, saving model to ./CNN_7.model\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.4155 - categorical_accuracy: 0.6591 - top_3_accuracy: 0.8323\n",
      "\n",
      "Epoch 00033: top_3_accuracy improved from 0.83203 to 0.83230, saving model to ./CNN_7.model\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.4180 - categorical_accuracy: 0.6575 - top_3_accuracy: 0.8313\n",
      "\n",
      "Epoch 00034: top_3_accuracy did not improve from 0.83230\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.4017 - categorical_accuracy: 0.6584 - top_3_accuracy: 0.8320\n",
      "\n",
      "Epoch 00035: top_3_accuracy did not improve from 0.83230\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.4093 - categorical_accuracy: 0.6599 - top_3_accuracy: 0.8336\n",
      "\n",
      "Epoch 00036: top_3_accuracy improved from 0.83230 to 0.83363, saving model to ./CNN_7.model\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.4004 - categorical_accuracy: 0.6607 - top_3_accuracy: 0.8326\n",
      "\n",
      "Epoch 00037: top_3_accuracy did not improve from 0.83363\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.3630 - categorical_accuracy: 0.6730 - top_3_accuracy: 0.8402\n",
      "\n",
      "Epoch 00038: top_3_accuracy improved from 0.83363 to 0.84018, saving model to ./CNN_7.model\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.3353 - categorical_accuracy: 0.6765 - top_3_accuracy: 0.8437\n",
      "\n",
      "Epoch 00039: top_3_accuracy improved from 0.84018 to 0.84371, saving model to ./CNN_7.model\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.3191 - categorical_accuracy: 0.6827 - top_3_accuracy: 0.8462\n",
      "\n",
      "Epoch 00040: top_3_accuracy improved from 0.84371 to 0.84615, saving model to ./CNN_7.model\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 66s 655ms/step - loss: 1.3198 - categorical_accuracy: 0.6814 - top_3_accuracy: 0.8447\n",
      "\n",
      "Epoch 00041: top_3_accuracy did not improve from 0.84615\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.3097 - categorical_accuracy: 0.6832 - top_3_accuracy: 0.8486\n",
      "\n",
      "Epoch 00042: top_3_accuracy improved from 0.84615 to 0.84857, saving model to ./CNN_7.model\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.2975 - categorical_accuracy: 0.6841 - top_3_accuracy: 0.8493\n",
      "\n",
      "Epoch 00043: top_3_accuracy improved from 0.84857 to 0.84930, saving model to ./CNN_7.model\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.3125 - categorical_accuracy: 0.6841 - top_3_accuracy: 0.8460\n",
      "\n",
      "Epoch 00044: top_3_accuracy did not improve from 0.84930\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.3085 - categorical_accuracy: 0.6820 - top_3_accuracy: 0.8481\n",
      "\n",
      "Epoch 00045: top_3_accuracy did not improve from 0.84930\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.2918 - categorical_accuracy: 0.6863 - top_3_accuracy: 0.8514\n",
      "\n",
      "Epoch 00046: top_3_accuracy improved from 0.84930 to 0.85143, saving model to ./CNN_7.model\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.2640 - categorical_accuracy: 0.6915 - top_3_accuracy: 0.8534\n",
      "\n",
      "Epoch 00047: top_3_accuracy improved from 0.85143 to 0.85344, saving model to ./CNN_7.model\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2456 - categorical_accuracy: 0.6979 - top_3_accuracy: 0.8579\n",
      "\n",
      "Epoch 00048: top_3_accuracy improved from 0.85344 to 0.85793, saving model to ./CNN_7.model\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.2517 - categorical_accuracy: 0.6988 - top_3_accuracy: 0.8548\n",
      "\n",
      "Epoch 00049: top_3_accuracy did not improve from 0.85793\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.2470 - categorical_accuracy: 0.6978 - top_3_accuracy: 0.8585\n",
      "\n",
      "Epoch 00050: top_3_accuracy improved from 0.85793 to 0.85846, saving model to ./CNN_7.model\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2510 - categorical_accuracy: 0.6979 - top_3_accuracy: 0.8571\n",
      "\n",
      "Epoch 00051: top_3_accuracy did not improve from 0.85846\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2370 - categorical_accuracy: 0.6975 - top_3_accuracy: 0.8583\n",
      "\n",
      "Epoch 00052: top_3_accuracy did not improve from 0.85846\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2534 - categorical_accuracy: 0.6959 - top_3_accuracy: 0.8556\n",
      "\n",
      "Epoch 00053: top_3_accuracy did not improve from 0.85846\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2196 - categorical_accuracy: 0.7016 - top_3_accuracy: 0.8611\n",
      "\n",
      "Epoch 00054: top_3_accuracy improved from 0.85846 to 0.86113, saving model to ./CNN_7.model\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.2267 - categorical_accuracy: 0.7013 - top_3_accuracy: 0.8599\n",
      "\n",
      "Epoch 00055: top_3_accuracy did not improve from 0.86113\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2290 - categorical_accuracy: 0.7021 - top_3_accuracy: 0.8603\n",
      "\n",
      "Epoch 00056: top_3_accuracy did not improve from 0.86113\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2207 - categorical_accuracy: 0.7033 - top_3_accuracy: 0.8611\n",
      "\n",
      "Epoch 00057: top_3_accuracy did not improve from 0.86113\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 1.2106 - categorical_accuracy: 0.7057 - top_3_accuracy: 0.8626\n",
      "\n",
      "Epoch 00058: top_3_accuracy improved from 0.86113 to 0.86258, saving model to ./CNN_7.model\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2144 - categorical_accuracy: 0.7038 - top_3_accuracy: 0.8614\n",
      "\n",
      "Epoch 00059: top_3_accuracy did not improve from 0.86258\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2263 - categorical_accuracy: 0.7044 - top_3_accuracy: 0.8611\n",
      "\n",
      "Epoch 00060: top_3_accuracy did not improve from 0.86258\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.1941 - categorical_accuracy: 0.7055 - top_3_accuracy: 0.8653\n",
      "\n",
      "Epoch 00061: top_3_accuracy improved from 0.86258 to 0.86529, saving model to ./CNN_7.model\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2057 - categorical_accuracy: 0.7068 - top_3_accuracy: 0.8624\n",
      "\n",
      "Epoch 00062: top_3_accuracy did not improve from 0.86529\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.1956 - categorical_accuracy: 0.7073 - top_3_accuracy: 0.8660\n",
      "\n",
      "Epoch 00063: top_3_accuracy improved from 0.86529 to 0.86602, saving model to ./CNN_7.model\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.2002 - categorical_accuracy: 0.7077 - top_3_accuracy: 0.8632\n",
      "\n",
      "Epoch 00064: top_3_accuracy did not improve from 0.86602\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.2154 - categorical_accuracy: 0.7056 - top_3_accuracy: 0.8621\n",
      "\n",
      "Epoch 00065: top_3_accuracy did not improve from 0.86602\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2118 - categorical_accuracy: 0.7076 - top_3_accuracy: 0.8618\n",
      "\n",
      "Epoch 00066: top_3_accuracy did not improve from 0.86602\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2053 - categorical_accuracy: 0.7064 - top_3_accuracy: 0.8634\n",
      "\n",
      "Epoch 00067: top_3_accuracy did not improve from 0.86602\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.2070 - categorical_accuracy: 0.7077 - top_3_accuracy: 0.8629\n",
      "\n",
      "Epoch 00068: top_3_accuracy did not improve from 0.86602\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 1.1971 - categorical_accuracy: 0.7093 - top_3_accuracy: 0.8637\n",
      "\n",
      "Epoch 00069: top_3_accuracy did not improve from 0.86602\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "CNN_7 = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gv_buAgJNLSp"
   },
   "source": [
    "**Вывод:** На тестовых данных результат немного улучшился, но на kaggle остался такими же. Можно предположить, что BatchNormalization можно не использовать в данном обучении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Amc-46O56bEz"
   },
   "source": [
    "#Эксперимент №8 Аугментация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8wEI5r4PsJp"
   },
   "source": [
    "Использую лучшую модель CNN с LeakyReLU, только в генератор подаю измененные картинки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "id": "JuQ_iG_aC2PG",
    "outputId": "43610e4d-ba6d-44cf-faac-3b3a7b911002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "GOOGLE_DRIVE_MOUNT = \"/content/gdrive\"\n",
    "drive.mount(GOOGLE_DRIVE_MOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pzdR4aNaQSSW",
    "outputId": "0a5c3ad9-b58e-4f4a-e133-0d491490a47e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9xzShGu9ejP"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQfrLSy-9fCG"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUBcBsY29fhq"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tY99mhK_QCf-"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "PKU85xxkQFr3",
    "outputId": "d36d38d3-eb34-419f-f317-39ac502bd1c2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEHCAYAAABhvpAKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvxAtRcYvREuR8QvRUv4fFw60PFakQ+0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d9807de90>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = images_and_labels_generator(32).next()\n",
    "plt.imshow(b[0][10, :, :])\n",
    "plt.title(b[1][10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1272
    },
    "colab_type": "code",
    "id": "xNIOtjGxCHzF",
    "outputId": "bcb5701f-f88b-4509-d6c4-5af82cb14f3b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD7CAYAAAClmULcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlDhFO7+ixCna+RUlTvn/n2MKPKjh93UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d98143310>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD7CAYAAAClmULcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d970b3ad0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD7CAYAAAClmULcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxi8ICcr/B5ui/Ttd7KI/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d97b4de10>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD7CAYAAAClmULcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBxZ8NkLNqromAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0da1d54d50>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD7CAYAAAClmULcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH1bmKqBbm55dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d97d30e90>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=10, #случайная ротация\n",
    "    width_shift_range=0.2, #случайное отображение горизонтально или вертикально \n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2, #случайное приближение\n",
    "    horizontal_flip=True, #случайный переворот части изображения \n",
    "    fill_mode='constant', #заполнение новых пикселей, полученных в результате сдвигов или отражения \n",
    "    cval=255\n",
    ")\n",
    "\n",
    "image = b[0][10, :, :]\n",
    "\n",
    "# add 3 channels to image\n",
    "image = np.tile(np.expand_dims(image, axis=2), (1, 1, 3))\n",
    "\n",
    "# 5 random augmentations\n",
    "for _ in range(5):\n",
    "    plt.imshow(image_gen.random_transform(image)[:, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAjnd8mI9fbr"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator_foraug(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        batch_images = image_gen.random_transform(batch_images) #добавляю картинки \n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnpgzSTG9fWA"
   },
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "haiJPrNq--Mx",
    "outputId": "c5354d79-eeaa-4bc2-e73f-cf184f1a0399"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 135,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee1skGv3--VX"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator_foraug(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ABtbgm-e_Gwd",
    "outputId": "aac278fc-462a-4863-afb8-2c7c2decd9bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsFwwtKa_G_U"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3),padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3),padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "   \n",
    "\n",
    "    model.add(Dense(4098))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "  \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "Yx92pzCB_G5F",
    "outputId": "3545f17a-eb80-415d-a113-032c8246f258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4098)              8396802   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               1393660   \n",
      "=================================================================\n",
      "Total params: 9,896,862\n",
      "Trainable params: 9,896,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCS2VzXG9fQN"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajCqSryF9fKv"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 20 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1OaVC4IUmUW"
   },
   "outputs": [],
   "source": [
    "# for saving the model after every epoch\n",
    "from keras.models import save_model\n",
    "\n",
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_filename = self.file_name.format(epoch)\n",
    "        save_model(self.model, model_filename)\n",
    "        print(\"Model saved in {}\".format(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMc-06ev9e26"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Nk23iWZfC3Ea",
    "outputId": "f828f3fb-b213-4367-b04b-62a8acf15d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive\n",
      "/content/gdrive/My Drive/model{}_aug1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GOOGLE_DRIVE_ROOT = GOOGLE_DRIVE_MOUNT + \"/\" + filter(lambda x: x[0] != '.', os.listdir(GOOGLE_DRIVE_MOUNT))[0]\n",
    "print GOOGLE_DRIVE_ROOT\n",
    "\n",
    "# will save checkpoints to Google Drive\n",
    "CHECKPOINT_TEMPLATE = GOOGLE_DRIVE_ROOT + \"/model{}_aug1\"\n",
    "print CHECKPOINT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1057
    },
    "colab_type": "code",
    "id": "kj4na3VI9exS",
    "outputId": "322cfda8-88c6-4fb4-8aa9-29243e659cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 96s 962ms/step - loss: 5.8297 - categorical_accuracy: 0.0031 - top_3_accuracy: 0.0091\n",
      "Model saved in /content/gdrive/My Drive/model0_aug1\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 5.8294 - categorical_accuracy: 0.0033 - top_3_accuracy: 0.0093\n",
      "Model saved in /content/gdrive/My Drive/model1_aug1\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 104s 1s/step - loss: 5.8293 - categorical_accuracy: 0.0030 - top_3_accuracy: 0.0095\n",
      "Model saved in /content/gdrive/My Drive/model2_aug1\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 99s 992ms/step - loss: 5.8294 - categorical_accuracy: 0.0029 - top_3_accuracy: 0.0087\n",
      "Model saved in /content/gdrive/My Drive/model3_aug1\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 5.8295 - categorical_accuracy: 0.0031 - top_3_accuracy: 0.0087\n",
      "Model saved in /content/gdrive/My Drive/model4_aug1\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 97s 967ms/step - loss: 5.8297 - categorical_accuracy: 0.0031 - top_3_accuracy: 0.0088\n",
      "Model saved in /content/gdrive/My Drive/model5_aug1\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 5.8298 - categorical_accuracy: 0.0029 - top_3_accuracy: 0.0087\n",
      "Model saved in /content/gdrive/My Drive/model6_aug1\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 96s 962ms/step - loss: 5.8303 - categorical_accuracy: 0.0030 - top_3_accuracy: 0.0086\n",
      "Model saved in /content/gdrive/My Drive/model7_aug1\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 5.8306 - categorical_accuracy: 0.0029 - top_3_accuracy: 0.0084\n",
      "Model saved in /content/gdrive/My Drive/model8_aug1\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 97s 969ms/step - loss: 5.8318 - categorical_accuracy: 0.0027 - top_3_accuracy: 0.0079\n",
      "Model saved in /content/gdrive/My Drive/model9_aug1\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 96s 964ms/step - loss: 5.8311 - categorical_accuracy: 0.0026 - top_3_accuracy: 0.0074\n",
      "Model saved in /content/gdrive/My Drive/model10_aug1\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 97s 969ms/step - loss: 5.8303 - categorical_accuracy: 0.0030 - top_3_accuracy: 0.0098\n",
      "Model saved in /content/gdrive/My Drive/model11_aug1\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 5.8301 - categorical_accuracy: 0.0029 - top_3_accuracy: 0.0092\n",
      "Model saved in /content/gdrive/My Drive/model12_aug1\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 97s 967ms/step - loss: 5.8301 - categorical_accuracy: 0.0031 - top_3_accuracy: 0.0089\n",
      "Model saved in /content/gdrive/My Drive/model13_aug1\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 96s 964ms/step - loss: 5.8300 - categorical_accuracy: 0.0029 - top_3_accuracy: 0.0085\n",
      "Model saved in /content/gdrive/My Drive/model14_aug1\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 5.8303 - categorical_accuracy: 0.0031 - top_3_accuracy: 0.0091\n",
      "Model saved in /content/gdrive/My Drive/model15_aug1\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 5.8301 - categorical_accuracy: 0.0033 - top_3_accuracy: 0.0090\n",
      "Model saved in /content/gdrive/My Drive/model16_aug1\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 97s 974ms/step - loss: 5.8302 - categorical_accuracy: 0.0029 - top_3_accuracy: 0.0094\n",
      "Model saved in /content/gdrive/My Drive/model17_aug1\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 97s 969ms/step - loss: 5.8300 - categorical_accuracy: 0.0027 - top_3_accuracy: 0.0086\n",
      "Model saved in /content/gdrive/My Drive/model18_aug1\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 97s 971ms/step - loss: 5.8302 - categorical_accuracy: 0.0034 - top_3_accuracy: 0.0098\n",
      "Model saved in /content/gdrive/My Drive/model19_aug1\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "CNN8 = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(CHECKPOINT_TEMPLATE)],\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6LbBhHjoTIq"
   },
   "source": [
    "**Вывод:** Качество на тестовой выборке очень низкое, возможно аугментация слишком сильная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOZL9IvHUwYU"
   },
   "source": [
    "#Эксперимент №9 Аугментация "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9w2x8Rtof_J"
   },
   "source": [
    "Попробую аугментировать изображения с помощью библиотеки imgaug. Выбираю параметры для минимального измнения картинок: только свдиги, отражение и афинные преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qmjd8BwDbark",
    "outputId": "047d5f9c-af63-48c3-859b-a188e221f558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 146,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ts32l4fsbbE_"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUm6IF-4bclo"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ro9OdDdqbd7c"
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmsD6M8hbdzL"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "5J223-3nbdsd",
    "outputId": "6fb78184-5ab6-4dae-a785-9f1146a85933"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEHCAYAAABhvpAKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d970f8850>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = images_and_labels_generator(32).next()\n",
    "plt.imshow(b[0][10, :, :])\n",
    "plt.title(b[1][10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "colab_type": "code",
    "id": "IWa6T2mWbdlw",
    "outputId": "b7385dd2-634b-4c03-b293-86077980b4c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imgaug\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
      "\u001b[K    100% |████████████████████████████████| 634kB 6.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (from imgaug) (1.1.0)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python2.7/dist-packages (from imgaug) (0.13.1)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python2.7/dist-packages (from imgaug) (1.14.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from imgaug) (1.11.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image>=0.11.0->imgaug) (1.0.1)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python2.7/dist-packages (from scikit-image>=0.11.0->imgaug) (2.2)\n",
      "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image>=0.11.0->imgaug) (4.0.0)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python2.7/dist-packages (from scikit-image>=0.11.0->imgaug) (2.1.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python2.7/dist-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug) (4.3.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from pillow>=2.1.0->scikit-image>=0.11.0->imgaug) (0.46)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (0.10.0)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (1.5)\n",
      "Requirement already satisfied: subprocess32 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (3.5.3)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug) (2.3.0)\n",
      "Building wheels for collected packages: imgaug\n",
      "  Running setup.py bdist_wheel for imgaug ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
      "Successfully built imgaug\n",
      "Installing collected packages: imgaug\n",
      "Successfully installed imgaug-0.2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHlOmh29bdfF"
   },
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "image_gen = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)),  \n",
    "    iaa.Fliplr(0.5), \n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        rotate=(-25, 25),\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kllzerV4bdRu"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator_foraug(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        batch_images = image_gen.augment_images(batch_images) #добавляю картинки \n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldhFEJYabdLF"
   },
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "YwswahTobdEY",
    "outputId": "d446871d-76ad-4959-9490-980d8e1a80d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 163,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em7XPlPdbc6O"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator_foraug(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rrDMhjXRbcxC",
    "outputId": "ceb6f51b-49a7-43a0-c873-ce9ee1bc56e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "El6bv0X8bce8"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3),padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3),padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "   \n",
    "\n",
    "    model.add(Dense(4098))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "  \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "peJ_IJoEbcYA",
    "outputId": "7ed6950d-7e70-4326-856e-1cc8a82b2142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4098)              8396802   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               1393660   \n",
      "=================================================================\n",
      "Total params: 9,896,862\n",
      "Trainable params: 9,896,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wf4lkjJzbcRH"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zV-UYRAzbcKp"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 20 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_EoaTyMCbcEP"
   },
   "outputs": [],
   "source": [
    "# for saving the model after every epoch\n",
    "from keras.models import save_model\n",
    "\n",
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_filename = self.file_name.format(epoch)\n",
    "        save_model(self.model, model_filename)\n",
    "        print(\"Model saved in {}\".format(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpndv4zObb8q"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MVLEeAxfbb2L",
    "outputId": "0047b16c-4b15-45dd-f3c2-68c389c25967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive\n",
      "/content/gdrive/My Drive/model{}_aug2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GOOGLE_DRIVE_ROOT = GOOGLE_DRIVE_MOUNT + \"/\" + filter(lambda x: x[0] != '.', os.listdir(GOOGLE_DRIVE_MOUNT))[0]\n",
    "print GOOGLE_DRIVE_ROOT\n",
    "\n",
    "# will save checkpoints to Google Drive\n",
    "CHECKPOINT_TEMPLATE = GOOGLE_DRIVE_ROOT + \"/model{}_aug2\"\n",
    "print CHECKPOINT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "id": "0SFYwCXTmx0Z",
    "outputId": "3782a400-189c-4c85-8036-a5a3fe903cd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception tensorflow.python.framework.errors_impl.CancelledError: CancelledError() in <bound method _Callable.__del__ of <tensorflow.python.client.session._Callable object at 0x7f0d970e4f10>> ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 5.4472 - categorical_accuracy: 0.0222 - top_3_accuracy: 0.0548\n",
      "Model saved in /content/gdrive/My Drive/model0_aug2\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 4.6431 - categorical_accuracy: 0.0942 - top_3_accuracy: 0.1905\n",
      "Model saved in /content/gdrive/My Drive/model1_aug2\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 61s 611ms/step - loss: 4.0922 - categorical_accuracy: 0.1670 - top_3_accuracy: 0.3009\n",
      "Model saved in /content/gdrive/My Drive/model2_aug2\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 3.7280 - categorical_accuracy: 0.2184 - top_3_accuracy: 0.3795\n",
      "Model saved in /content/gdrive/My Drive/model3_aug2\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 3.4638 - categorical_accuracy: 0.2590 - top_3_accuracy: 0.4308\n",
      "Model saved in /content/gdrive/My Drive/model4_aug2\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 3.3029 - categorical_accuracy: 0.2879 - top_3_accuracy: 0.4669\n",
      "Model saved in /content/gdrive/My Drive/model5_aug2\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 61s 612ms/step - loss: 3.1446 - categorical_accuracy: 0.3119 - top_3_accuracy: 0.4960\n",
      "Model saved in /content/gdrive/My Drive/model6_aug2\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 3.0472 - categorical_accuracy: 0.3315 - top_3_accuracy: 0.5189\n",
      "Model saved in /content/gdrive/My Drive/model7_aug2\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 61s 612ms/step - loss: 2.9369 - categorical_accuracy: 0.3505 - top_3_accuracy: 0.5418\n",
      "Model saved in /content/gdrive/My Drive/model8_aug2\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 2.8596 - categorical_accuracy: 0.3628 - top_3_accuracy: 0.5560\n",
      "Model saved in /content/gdrive/My Drive/model9_aug2\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 2.8054 - categorical_accuracy: 0.3729 - top_3_accuracy: 0.5694\n",
      "Model saved in /content/gdrive/My Drive/model10_aug2\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 2.7109 - categorical_accuracy: 0.3916 - top_3_accuracy: 0.5886\n",
      "Model saved in /content/gdrive/My Drive/model11_aug2\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 2.7017 - categorical_accuracy: 0.3923 - top_3_accuracy: 0.5854\n",
      "Model saved in /content/gdrive/My Drive/model12_aug2\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 61s 611ms/step - loss: 2.6576 - categorical_accuracy: 0.4003 - top_3_accuracy: 0.5960\n",
      "Model saved in /content/gdrive/My Drive/model13_aug2\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 2.5975 - categorical_accuracy: 0.4137 - top_3_accuracy: 0.6098\n",
      "Model saved in /content/gdrive/My Drive/model14_aug2\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 62s 615ms/step - loss: 2.5775 - categorical_accuracy: 0.4137 - top_3_accuracy: 0.6124\n",
      "Model saved in /content/gdrive/My Drive/model15_aug2\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 61s 609ms/step - loss: 2.5466 - categorical_accuracy: 0.4213 - top_3_accuracy: 0.6185\n",
      "Model saved in /content/gdrive/My Drive/model16_aug2\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 61s 609ms/step - loss: 2.5084 - categorical_accuracy: 0.4264 - top_3_accuracy: 0.6255\n",
      "Model saved in /content/gdrive/My Drive/model17_aug2\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 61s 608ms/step - loss: 2.4850 - categorical_accuracy: 0.4316 - top_3_accuracy: 0.6304\n",
      "Model saved in /content/gdrive/My Drive/model18_aug2\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 61s 611ms/step - loss: 2.4437 - categorical_accuracy: 0.4400 - top_3_accuracy: 0.6400\n",
      "Model saved in /content/gdrive/My Drive/model19_aug2\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "CNN9 = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(CHECKPOINT_TEMPLATE)],\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mbQ-mkWxsTYz"
   },
   "source": [
    "Качество уже лучше, LB = 0.618; сравню с обучением на исходных картинках "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dAba5yQspXA"
   },
   "source": [
    "#Эксперимернт №10 Без аугментации. Для сравнения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ert86iTwbgFf"
   },
   "source": [
    "Та же сеть, что и в эксперименте 6, обученная на исходном датасете для сравнения качества. Обучаю всего 20 эпох, так как этого достаточно для того, чтобы определить, что лучше работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nQURJgLcbbpC",
    "outputId": "2e1bb22e-7d04-4ad2-bb28-b2609c860541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 181,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bm6gdUDHbbic"
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIpEO_LdbbcI"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZzRDipMbbPP"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    img = 255 * np.ones((256, 256), np.uint8)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 0, 3)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ud9eI7NLba-e"
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocOV2eBBba35"
   },
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "eUxLY2I8bnRQ",
    "outputId": "df948318-75e4-40f9-c2e5-a8841072826f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 187,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aJXO903bnq7"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        images = images/ 255 - 0.5\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JiJ6m0nvbn8y",
    "outputId": "86d28154-65a0-4000-fa6a-0f8c78cc8728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahiU0Ywtbnj1"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3),padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(Conv2D(32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3),padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3),padding='same'))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "   \n",
    "\n",
    "    model.add(Dense(4098))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "  \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "62Sm3j-xbncW",
    "outputId": "b07619d2-d0ea-46d4-9be6-4277b9b2c3da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4098)              8396802   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4098)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               1393660   \n",
      "=================================================================\n",
      "Total params: 9,896,862\n",
      "Trainable params: 9,896,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFi3IMV9bowR"
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJcYc85QqVIk"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 20 \n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIqxsjRlqVUv"
   },
   "outputs": [],
   "source": [
    "# for saving the model after every epoch\n",
    "from keras.models import save_model\n",
    "\n",
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_filename = self.file_name.format(epoch)\n",
    "        save_model(self.model, model_filename)\n",
    "        print(\"Model saved in {}\".format(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvXyudjpqpSZ"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XExrCHdUqqG6",
    "outputId": "f4e30f66-ee0a-4ec0-91f9-d397b28c01d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive\n",
      "/content/gdrive/My Drive/model{}_withoutaug\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GOOGLE_DRIVE_ROOT = GOOGLE_DRIVE_MOUNT + \"/\" + filter(lambda x: x[0] != '.', os.listdir(GOOGLE_DRIVE_MOUNT))[0]\n",
    "print GOOGLE_DRIVE_ROOT\n",
    "\n",
    "# will save checkpoints to Google Drive\n",
    "CHECKPOINT_TEMPLATE = GOOGLE_DRIVE_ROOT + \"/model{}_withoutaug\"\n",
    "print CHECKPOINT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1057
    },
    "colab_type": "code",
    "id": "vID8kvhKqo36",
    "outputId": "2fda40d1-1043-4981-98f5-7d2196488f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 47s 473ms/step - loss: 4.5370 - categorical_accuracy: 0.1285 - top_3_accuracy: 0.2342\n",
      "Model saved in /content/gdrive/My Drive/model0_withoutaug\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 3.0334 - categorical_accuracy: 0.3384 - top_3_accuracy: 0.5305\n",
      "Model saved in /content/gdrive/My Drive/model1_withoutaug\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 2.5260 - categorical_accuracy: 0.4324 - top_3_accuracy: 0.6292\n",
      "Model saved in /content/gdrive/My Drive/model2_withoutaug\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 2.2825 - categorical_accuracy: 0.4758 - top_3_accuracy: 0.6746\n",
      "Model saved in /content/gdrive/My Drive/model3_withoutaug\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 2.1210 - categorical_accuracy: 0.5082 - top_3_accuracy: 0.7056\n",
      "Model saved in /content/gdrive/My Drive/model4_withoutaug\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 2.0158 - categorical_accuracy: 0.5291 - top_3_accuracy: 0.7259\n",
      "Model saved in /content/gdrive/My Drive/model5_withoutaug\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.9314 - categorical_accuracy: 0.5486 - top_3_accuracy: 0.7419\n",
      "Model saved in /content/gdrive/My Drive/model6_withoutaug\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.8472 - categorical_accuracy: 0.5656 - top_3_accuracy: 0.7588\n",
      "Model saved in /content/gdrive/My Drive/model7_withoutaug\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.7920 - categorical_accuracy: 0.5739 - top_3_accuracy: 0.7660\n",
      "Model saved in /content/gdrive/My Drive/model8_withoutaug\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.7750 - categorical_accuracy: 0.5813 - top_3_accuracy: 0.7682\n",
      "Model saved in /content/gdrive/My Drive/model9_withoutaug\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.7413 - categorical_accuracy: 0.5885 - top_3_accuracy: 0.7758\n",
      "Model saved in /content/gdrive/My Drive/model10_withoutaug\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.7061 - categorical_accuracy: 0.5951 - top_3_accuracy: 0.7831\n",
      "Model saved in /content/gdrive/My Drive/model11_withoutaug\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.6920 - categorical_accuracy: 0.6002 - top_3_accuracy: 0.7856\n",
      "Model saved in /content/gdrive/My Drive/model12_withoutaug\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.6501 - categorical_accuracy: 0.6047 - top_3_accuracy: 0.7932\n",
      "Model saved in /content/gdrive/My Drive/model13_withoutaug\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 1.6460 - categorical_accuracy: 0.6068 - top_3_accuracy: 0.7918\n",
      "Model saved in /content/gdrive/My Drive/model14_withoutaug\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.6088 - categorical_accuracy: 0.6154 - top_3_accuracy: 0.7983\n",
      "Model saved in /content/gdrive/My Drive/model15_withoutaug\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.6069 - categorical_accuracy: 0.6158 - top_3_accuracy: 0.7996\n",
      "Model saved in /content/gdrive/My Drive/model16_withoutaug\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 1.5591 - categorical_accuracy: 0.6256 - top_3_accuracy: 0.8052\n",
      "Model saved in /content/gdrive/My Drive/model17_withoutaug\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.5668 - categorical_accuracy: 0.6227 - top_3_accuracy: 0.8073\n",
      "Model saved in /content/gdrive/My Drive/model18_withoutaug\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.5328 - categorical_accuracy: 0.6319 - top_3_accuracy: 0.8115\n",
      "Model saved in /content/gdrive/My Drive/model19_withoutaug\n"
     ]
    }
   ],
   "source": [
    "CNN10 = model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(CHECKPOINT_TEMPLATE)],\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JtlMg-wlxfVY"
   },
   "source": [
    "Модель на исходных данных обучается заметно лучше, чем на аугментированных. Даже при 20 эпохах, LB=0.744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sc-fm2subpEw"
   },
   "source": [
    "#Сравнение качества с аугментацией и без"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "CRuF4z6WbwgQ",
    "outputId": "8692a358-911d-4242-92d0-0e72f2fb5493"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsEAAAHvCAYAAAC1/wKvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neM7/D/LGElVu1fwxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d94187890>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.legend(loc='best')\n",
    "plt.title('MAP@3')\n",
    "plt.xlabel('Epochs')\n",
    "line1 = plt.plot(CNN10.history['top_3_accuracy'], label='without augmentation')\n",
    "line2 = plt.plot(CNN9.history['top_3_accuracy'],label = 'with augmentation')\n",
    "line3 = plt.plot(CNN8.history['top_3_accuracy'],label = 'with bad augmentation')\n",
    "plt.legend(loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wUa2c6z9Xsm"
   },
   "source": [
    "**Выводы по аугментации:** Даже минимальная аугментация только портит качество как на обучении, так и на тесте. Аугментация в данном случае не нужна, потому что датасет большой и состоит из разных картинок. Возможно аугментация на этом датасете поможет, когда качество будет более 0.9. Использую очень простую аугментацию, потому что картинки простые и маленькие, не надо использовать, например, размытие "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mYugvbbrtlgZ"
   },
   "source": [
    "#Выводы и результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlXcr7NB1fkt"
   },
   "source": [
    "\n",
    "\n",
    "*   Максимальный скор **LB=0.816**\n",
    "*   Получилось доказать, что лучшая регуляризация **LeakyReLU**\n",
    "*   Регуляризация **BatchNormalization** не изменила результат\n",
    "*   При использовании большого **размера батча** лучше качество\n",
    "*   **Dropout** убрал переобучение \n",
    "*   **EarlyStopping** позволил также избежать переобучения и вовремя останавливал модель, когда переставало расти качество\n",
    "*   **Аугментация** скорее всего не нужна в данном датасете\n",
    "*   Поняла, что надо сначала строить максимально простую CNN, а уже потом добавлять регуляризацию и дополнительные слои\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PRFPrg5RQ1r"
   },
   "source": [
    "# Score test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T12:18:38.307707Z",
     "start_time": "2018-11-07T12:18:34.929466Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "colab_type": "code",
    "id": "rvL9Y1gGRQ1s",
    "outputId": "967e3b51-1747-4b43-cfa2-14d43c5aa57e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_simplified.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# download test set\n",
    "! KAGGLE_USERNAME=adtsvetkova KAGGLE_KEY=711dab66e0f54e09951120830972f100 kaggle competitions download -c quickdraw-doodle-recognition -f test_simplified.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:25:30.169624Z",
     "start_time": "2018-11-07T16:25:30.148875Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aVvctxb-RQ1x"
   },
   "outputs": [],
   "source": [
    "def test_csv_iterator(batch_size):\n",
    "    with open(\"test_simplified.csv\", \"r\") as f:\n",
    "        batch_keys = []\n",
    "        batch_images = []\n",
    "        f.readline()  # skip header\n",
    "        for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "            batch_keys.append(line[0])\n",
    "            batch_images.append(draw_it(line[2]))\n",
    "            if len(batch_images) == batch_size:\n",
    "                batch_images = np.stack(batch_images, axis=0)\n",
    "                batch_images = np.expand_dims(batch_images, -1)\n",
    "                batch_images = batch_images.astype('float32')\n",
    "                batch_images = batch_images/ 255 - 0.5\n",
    "                yield batch_keys, batch_images\n",
    "                batch_keys = []\n",
    "                batch_images = []\n",
    "        if batch_images:  # last batch\n",
    "            batch_images = np.stack(batch_images, axis=0)\n",
    "            batch_images = np.expand_dims(batch_images, -1)\n",
    "            batch_images = batch_images.astype('float32')\n",
    "            batch_images = batch_images/ 255 - 0.5\n",
    "            yield batch_keys, batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:25:32.406415Z",
     "start_time": "2018-11-07T16:25:32.203842Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "colab_type": "code",
    "id": "tDQkSdo3RQ10",
    "outputId": "8fc63abc-68e2-487f-c318-3ac9e691c69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112200 test_simplified.csv\n"
     ]
    }
   ],
   "source": [
    "! wc -l test_simplified.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:26:30.259083Z",
     "start_time": "2018-11-07T16:25:32.579734Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_FFUiMNVRQ14",
    "outputId": "9f951ff9-154b-4916-d8de-a10ddb6d9305",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220.0 [01:32<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"submission.csv\", \"w\", buffering=1*1024*1024) as f:\n",
    "    f.write(\"key_id,word\\n\")\n",
    "    for batch_keys, batch_images in tqdm.tqdm(test_csv_iterator(BATCH_SIZE), total=np.ceil(112200./BATCH_SIZE)):\n",
    "        probas = model.predict_proba(batch_images, BATCH_SIZE)\n",
    "        top_3_classes = np.argsort(probas, axis=1)[:, [-1, -2, -3]]\n",
    "        labels = map(lambda x: \" \".join(\"_\".join(class_labels[idx].split()) for idx in x), top_3_classes)\n",
    "        for key, labels in zip(batch_keys, labels):\n",
    "            f.write(key + \",\" + labels + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:27:51.293010Z",
     "start_time": "2018-11-07T16:27:51.111607Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "colab_type": "code",
    "id": "4OQCVDcNRQ18",
    "outputId": "6fdcd76c-e6a8-4b8c-817d-5c0030f371fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112200 submission.csv\n"
     ]
    }
   ],
   "source": [
    "! wc -l submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T13:18:12.630549Z",
     "start_time": "2018-11-07T13:17:59.689315Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "colab_type": "code",
    "id": "5zgagBQgRQ2B",
    "outputId": "8716986d-6f88-4f92-a21e-e1412ee5e19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% 4.40M/4.40M [00:00<00:00, 15.3MB/s]\n",
      "Successfully submitted to Quick, Draw! Doodle Recognition Challenge"
     ]
    }
   ],
   "source": [
    "# submit to kaggle\n",
    "! KAGGLE_USERNAME=adtsvetkova KAGGLE_KEY=711dab66e0f54e09951120830972f100 kaggle competitions submit quickdraw-doodle-recognition -f submission.csv -m \"My precious\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqvT4Pw_rs4V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9DQguMI22X1d"
   ],
   "name": "Цветкова Алена Дмитриевна БВВ161_notebook.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
